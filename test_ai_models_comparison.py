"""
æµ‹è¯•å¤šä¸ªAIæœåŠ¡çš„å„ç§æ¨¡åž‹
ç»Ÿä¸€ä½¿ç”¨æœ¬åœ°OCRï¼Œç„¶åŽå°†OCRæ–‡å­—å‘é€ç»™å„AIæ¨¡åž‹æå–é¢˜ç›®å’Œé€‰é¡¹
æµ‹è¯•æŒ‡æ ‡ï¼šå‡†ç¡®çŽ‡ã€é€Ÿåº¦ã€è´¹ç”¨ã€tokenæ•°é‡
"""
import os
import json
import sys
import time
import re
from typing import Dict, List, Optional
from statistics import mean
from openai import OpenAI
import requests

# ä¿®å¤WindowsæŽ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# åŠ è½½çŽ¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# ==================== AIæœåŠ¡é…ç½® ====================

# é˜¿é‡Œäº‘ï¼ˆé€šä¹‰åƒé—®ï¼‰é…ç½®
ALIBABA_API_KEY = 'sk-52e5c7f48ecb429e9d4569ec19e47223'
ALIBABA_API_BASE = 'https://dashscope.aliyuncs.com/compatible-mode/v1'

# DeepSeeké…ç½®
DEEPSEEK_API_KEY = 'sk-7de12481a17045819fcf3a2838d884a1'
DEEPSEEK_API_BASE = 'https://api.deepseek.com/v1'

# ç«å±±å¼•æ“Žé…ç½®ï¼ˆéœ€è¦ä»ŽçŽ¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶èŽ·å–ï¼‰
VOLCENGINE_API_KEY = os.getenv('VOLCENGINE_API_KEY', 'bebcec52-ce96-4f6f-bb1e-9a1b49ad5cf8')
VOLCENGINE_API_BASE = 'https://ark.cn-beijing.volces.com/api/v3'

# ==================== æ¨¡åž‹åˆ—è¡¨ ====================

# é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¨¡åž‹åˆ—è¡¨
ALIBABA_MODELS = [
    'qwen-turbo',           # é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½Ž
    'qwen-plus',            # å¹³è¡¡ç‰ˆ
    'qwen-max',             # æœ€å¼ºæ€§èƒ½
    'qwen-max-longcontext', # é•¿æ–‡æœ¬ç‰ˆ
    'qwen-long',            # è¶…é•¿æ–‡æœ¬ç‰ˆï¼ˆæ”¯æŒåƒä¸‡å­—ï¼‰
]

# DeepSeekæ¨¡åž‹åˆ—è¡¨
DEEPSEEK_MODELS = [
    'deepseek-chat',        # æ ‡å‡†ç‰ˆ
    'deepseek-reasoner',    # æŽ¨ç†ç‰ˆï¼ˆä¸ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼‰
]

# ç«å±±å¼•æ“Žè±†åŒ…æ¨¡åž‹åˆ—è¡¨
# æ³¨æ„ï¼šç«å±±å¼•æ“Žæ–‡æœ¬æ¨¡åž‹éœ€è¦é€šè¿‡æŽ¥å…¥ç‚¹IDï¼ˆep-xxxxxxï¼‰è°ƒç”¨
# å¯ä»¥é€šè¿‡çŽ¯å¢ƒå˜é‡ VOLCENGINE_ENDPOINT_IDS é…ç½®ï¼Œç”¨é€—å·åˆ†éš”å¤šä¸ªæŽ¥å…¥ç‚¹ID
# ä¾‹å¦‚ï¼šVOLCENGINE_ENDPOINT_IDS=ep-20251207111153-rxbqb,ep-xxxxxx
# å¦‚æžœæ²¡æœ‰é…ç½®çŽ¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤çš„æŽ¥å…¥ç‚¹ID
volcengine_endpoint_ids = os.getenv('VOLCENGINE_ENDPOINT_IDS', '').strip()
if volcengine_endpoint_ids:
    VOLCENGINE_MODELS = [ep.strip() for ep in volcengine_endpoint_ids.split(',') if ep.strip().startswith('ep-')]
else:
    # é»˜è®¤æŽ¥å…¥ç‚¹IDï¼ˆç”¨æˆ·æä¾›çš„ç¤ºä¾‹ï¼‰
    VOLCENGINE_MODELS = ['ep-20251207111153-rxbqb']  # é»˜è®¤æŽ¥å…¥ç‚¹ï¼Œç”¨æˆ·å¯æ·»åŠ æ›´å¤š

# ==================== ä»·æ ¼é…ç½®ï¼ˆå…ƒ/åƒtokenï¼‰ ====================

PRICING = {
    'qwen-turbo': {'input': 0.0003, 'output': 0.0006},
    'qwen-plus': {'input': 0.0008, 'output': 0.002},
    'qwen-max': {'input': 0.02, 'output': 0.06},
    'qwen-max-longcontext': {'input': 0.0005, 'output': 0.002},
    'qwen-long': {'input': 0.0003, 'output': 0.0012},  # è¶…é•¿æ–‡æœ¬ç‰ˆ
    'deepseek-chat': {'input': 0.00014, 'output': 0.00056},
    'deepseek-reasoner': {'input': 0.00055, 'output': 0.002},
    # ç«å±±å¼•æ“Žæ¨¡åž‹ä»·æ ¼ï¼ˆæ ¹æ®æŽ¥å…¥ç‚¹IDå¯¹åº”çš„å®žé™…æ¨¡åž‹å®šä»·ï¼‰
    'ep-20251207111153-rxbqb': {'input': 0.001, 'output': 0.004},  # ç¤ºä¾‹ä»·æ ¼ï¼Œéœ€è¦æ ¹æ®å®žé™…æ¨¡åž‹ç¡®è®¤
}

# ==================== å·¥å…·å‡½æ•° ====================

def load_test_images(max_images=None):
    """åŠ è½½æµ‹è¯•å›¾ç‰‡"""
    ceshi_dir = 'uploads/ceshi'
    if not os.path.exists(ceshi_dir):
        print(f"âš ï¸  é”™è¯¯: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {ceshi_dir}")
        return []
    
    images = []
    for file in sorted(os.listdir(ceshi_dir)):
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            # è·³è¿‡é¢„å¤„ç†æ–‡ä»¶
            if '_preprocessed' not in file.lower():
                full_path = os.path.join(ceshi_dir, file)
                if os.path.exists(full_path):
                    images.append(full_path)
                    if max_images and len(images) >= max_images:
                        break
    
    return images

def preprocess_ocr_text(raw_text: str) -> str:
    """å¿«é€Ÿé¢„å¤„ç†OCRæ–‡æœ¬ï¼Œè¿‡æ»¤æ˜Žæ˜¾çš„ç•Œé¢å…ƒç´ """
    if not raw_text:
        return raw_text
    
    lines = raw_text.split('\n')
    filtered_lines = []
    
    # ä¸¥æ ¼çš„ç•Œé¢å…ƒç´ å…³é”®è¯
    strict_interface_keywords = [
        'KB/s', 'é¦–é¡µ', 'æœ‹å‹', 'æ¶ˆæ¯', 'æˆ‘', 'æ‹åŒ', 'ç‚¹å‡»æŽ¨è',
        'ç²‰ç¬”æ­£ç¡®çŽ‡', 'åŽå›¾æ­£ç¡®çŽ‡', 'ç­”æ¡ˆä¸€æ ·', 'è§£æžåœ¨ä½œå“', 'è§£æžåœ¨ä½œå“ç®€',
        'å±•å¼€', 'æ”¶èµ·', 'åˆ†äº«', 'ç‚¹èµž', 'æ”¶è—', 'è¯„è®º',
        '@å…¬è€ƒè¡Œæµ‹æ¯æ—¥ä¸€ç»ƒ', 'å…¬è€ƒè¡Œæµ‹æ¯æ—¥ä¸€ç»ƒçš„æ©±çª—',
        'æ©±çª—|', 'ç‚¹å‡»æŽ¨è', 'ç¥å„ä½å›½è€ƒ', 'è¡Œæµ‹80', 'ç”³è®º85',
        'Never give up'
    ]
    
    option_markers = ['A.', 'B.', 'C.', 'D.', 'E.', 'F.', 'A ', 'B ', 'C ', 'D ']
    question_keywords = ['è¿™æ®µæ–‡å­—', 'æ„åœ¨è¯´æ˜Ž', 'æ ¹æ®', 'ä»¥ä¸‹', 'é¢˜ç›®', 'é¢˜å¹²']
    
    for line in lines:
        line_stripped = line.strip()
        if not line_stripped:
            continue
        
        # è·³è¿‡æ˜Žç¡®çš„ç•Œé¢å…ƒç´ 
        is_interface = any(keyword in line_stripped for keyword in strict_interface_keywords)
        if is_interface:
            continue
        
        # ä¿ç•™é€‰é¡¹æ ‡è®°
        has_option_marker = any(line_stripped.startswith(marker) for marker in option_markers)
        if has_option_marker:
            filtered_lines.append(line_stripped)
            continue
        
        # ä¿ç•™é¢˜å¹²å…³é”®è¯
        has_question_keyword = any(keyword in line_stripped for keyword in question_keywords)
        if has_question_keyword:
            filtered_lines.append(line_stripped)
            continue
        
        # ä¿ç•™è¾ƒé•¿çš„æ–‡æœ¬è¡Œ
        if len(line_stripped) > 3:
            if len(line_stripped) > 10 or any(p in line_stripped for p in ['ã€‚', 'ï¼Œ', 'ã€', 'ï¼›', 'ï¼Ÿ', 'ï¼š']):
                filtered_lines.append(line_stripped)
    
    return '\n'.join(filtered_lines)

def get_ocr_text(image_path: str) -> Dict:
    """ç»Ÿä¸€ä½¿ç”¨æœ¬åœ°OCRèŽ·å–æ–‡å­—"""
    from ocr_service import get_ocr_service
    ocr_service = get_ocr_service()
    
    if not ocr_service.ocr_engine:
        return {'success': False, 'error': 'OCRä¸å¯ç”¨'}
    
    start = time.time()
    raw_text = ocr_service.extract_text(image_path)
    elapsed = time.time() - start
    
    if raw_text:
        return {
            'success': True,
            'raw_text': raw_text,
            'time': elapsed,
            'char_count': len(raw_text)
        }
    else:
        return {'success': False, 'error': 'OCRæœªè¯†åˆ«åˆ°æ–‡å­—', 'time': elapsed}

def call_ai_model(provider: str, model: str, ocr_text: str) -> Dict:
    """
    è°ƒç”¨AIæ¨¡åž‹æå–é¢˜ç›®å’Œé€‰é¡¹
    
    Args:
        provider: 'alibaba', 'deepseek', 'volcengine'
        model: æ¨¡åž‹åç§°
        ocr_text: OCRè¯†åˆ«çš„æ–‡å­—
    
    Returns:
        dict: {
            'success': bool,
            'question_text': str,
            'options': List[str],
            'time': float,
            'input_tokens': int,
            'output_tokens': int,
            'cost': float,
            'raw_response': str
        }
    """
    # é¢„å¤„ç†OCRæ–‡å­—
    preprocessed_text = preprocess_ocr_text(ocr_text)[:3000]  # é™åˆ¶é•¿åº¦
    
    # æž„å»ºæç¤ºè¯ï¼ˆç®€çŸ­ã€æ˜Žç¡®ã€å¿«é€Ÿï¼‰
    prompt = f"""ä»Žä»¥ä¸‹OCRè¯†åˆ«æ–‡å­—ä¸­æå–é¢˜ç›®å’Œé€‰é¡¹ï¼Œå¿½ç•¥æ‰€æœ‰ç•Œé¢å…ƒç´ ã€‚

OCRæ–‡å­—ï¼š
{preprocessed_text}

è¦æ±‚ï¼š
1. åªæå–é¢˜ç›®å†…å®¹å’Œé€‰é¡¹
2. é¢˜å¹²å¿…é¡»å®Œæ•´ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ®µè½å†…å®¹
3. é€‰é¡¹å¿…é¡»ä»¥"A. "ã€"B. "ã€"C. "ã€"D. "å¼€å¤´
4. ä¸è¦åŒ…å«ç•Œé¢å…ƒç´ 

è¿”å›žJSONæ ¼å¼ï¼ˆåªè¿”å›žJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
    "question_text": "å®Œæ•´çš„é¢˜å¹²å†…å®¹",
    "options": ["A. é€‰é¡¹A", "B. é€‰é¡¹B", "C. é€‰é¡¹C", "D. é€‰é¡¹D"]
}}"""
    
    start_time = time.time()
    
    try:
        if provider == 'alibaba':
            return _call_alibaba_api(model, prompt, start_time)
        elif provider == 'deepseek':
            return _call_deepseek_api(model, prompt, start_time)
        elif provider == 'volcengine':
            return _call_volcengine_api(model, prompt, start_time)
        else:
            return {'success': False, 'error': f'æœªçŸ¥æœåŠ¡: {provider}'}
    except Exception as e:
        elapsed = time.time() - start_time
        return {
            'success': False,
            'error': str(e)[:100],
            'time': elapsed
        }

def _call_alibaba_api(model: str, prompt: str, start_time: float) -> Dict:
    """è°ƒç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIï¼ˆç¦ç”¨æ€è€ƒæ¨¡å¼ï¼‰"""
    client = OpenAI(api_key=ALIBABA_API_KEY, base_url=ALIBABA_API_BASE)
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®æå–åŠ©æ‰‹ï¼Œæ“…é•¿ä»ŽOCRæ–‡å­—ä¸­å‡†ç¡®æå–å®Œæ•´çš„é¢˜ç›®å’Œé€‰é¡¹ã€‚åªè¿”å›žJSONæ ¼å¼ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1,
        max_tokens=1500,
        timeout=20,
        extra_body={"enable_thinking": False}  # ç¦ç”¨æ€è€ƒæ¨¡å¼
    )
    
    elapsed = time.time() - start_time
    content = response.choices[0].message.content.strip()
    
    # ç»Ÿè®¡token
    input_tokens = response.usage.prompt_tokens if hasattr(response, 'usage') else 0
    output_tokens = response.usage.completion_tokens if hasattr(response, 'usage') else 0
    
    # è®¡ç®—è´¹ç”¨
    pricing = PRICING.get(model, {'input': 0, 'output': 0})
    cost = (input_tokens / 1000 * pricing['input']) + (output_tokens / 1000 * pricing['output'])
    
    # è§£æžJSON
    json_match = re.search(r'\{[\s\S]*\}', content)
    if json_match:
        result = json.loads(json_match.group())
        question_text = result.get('question_text', '').strip()
        options = result.get('options', [])
        
        # æ ¼å¼åŒ–é€‰é¡¹
        formatted_options = []
        for i, opt in enumerate(options):
            opt_str = str(opt).strip()
            if not re.match(r'^[A-F]\.?\s', opt_str):
                opt_str = f"{chr(65+i)}. {opt_str}"
            formatted_options.append(opt_str)
        
        return {
            'success': True,
            'question_text': question_text,
            'options': formatted_options,
            'time': elapsed,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'total_tokens': input_tokens + output_tokens,
            'cost': cost,
            'raw_response': content
        }
    else:
        return {
            'success': False,
            'error': 'JSONè§£æžå¤±è´¥',
            'time': elapsed,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost': cost,
            'raw_response': content
        }

def _call_deepseek_api(model: str, prompt: str, start_time: float) -> Dict:
    """è°ƒç”¨DeepSeek APIï¼ˆç¦ç”¨æ€è€ƒæ¨¡å¼ï¼‰"""
    client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_API_BASE)
    
    # ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼ˆåŒ…æ‹¬deepseek-reasonerï¼‰
    extra_body = {"thinking": {"type": "disabled"}} if model == "deepseek-reasoner" else {}
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®æå–åŠ©æ‰‹ï¼Œæ“…é•¿ä»ŽOCRæ–‡å­—ä¸­å‡†ç¡®æå–å®Œæ•´çš„é¢˜ç›®å’Œé€‰é¡¹ã€‚åªè¿”å›žJSONæ ¼å¼ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1,
        max_tokens=1500,
        timeout=20,
        **({"extra_body": extra_body} if extra_body else {})  # ä»…å½“éœ€è¦æ—¶æ·»åŠ extra_body
    )
    
    elapsed = time.time() - start_time
    content = response.choices[0].message.content.strip()
    
    # ç»Ÿè®¡token
    input_tokens = response.usage.prompt_tokens if hasattr(response, 'usage') else 0
    output_tokens = response.usage.completion_tokens if hasattr(response, 'usage') else 0
    
    # è®¡ç®—è´¹ç”¨
    pricing = PRICING.get(model, {'input': 0, 'output': 0})
    cost = (input_tokens / 1000 * pricing['input']) + (output_tokens / 1000 * pricing['output'])
    
    # è§£æžJSON
    json_match = re.search(r'\{[\s\S]*\}', content)
    if json_match:
        result = json.loads(json_match.group())
        question_text = result.get('question_text', '').strip()
        options = result.get('options', [])
        
        # æ ¼å¼åŒ–é€‰é¡¹
        formatted_options = []
        for i, opt in enumerate(options):
            opt_str = str(opt).strip()
            if not re.match(r'^[A-F]\.?\s', opt_str):
                opt_str = f"{chr(65+i)}. {opt_str}"
            formatted_options.append(opt_str)
        
        return {
            'success': True,
            'question_text': question_text,
            'options': formatted_options,
            'time': elapsed,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'total_tokens': input_tokens + output_tokens,
            'cost': cost,
            'raw_response': content
        }
    else:
        return {
            'success': False,
            'error': 'JSONè§£æžå¤±è´¥',
            'time': elapsed,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost': cost,
            'raw_response': content
        }

def _call_volcengine_api(model: str, prompt: str, start_time: float) -> Dict:
    """è°ƒç”¨ç«å±±å¼•æ“Žè±†åŒ…APIï¼ˆä½¿ç”¨OpenAIå…¼å®¹çš„chat/completionsç«¯ç‚¹ï¼‰"""
    url = f"{VOLCENGINE_API_BASE}/chat/completions"
    
    # ä½¿ç”¨OpenAIå…¼å®¹çš„æ ¼å¼
    data = {
        "model": model,  # æŽ¥å…¥ç‚¹ID
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_tokens": 4096,
        "temperature": 0.3
        # ä¸ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼Œæ‰€ä»¥ä¸è®¾ç½® reasoning_effort å‚æ•°
    }
    
    headers = {
        'Authorization': f'Bearer {VOLCENGINE_API_KEY}',
        'Content-Type': 'application/json'
    }
    
    response = requests.post(url, json=data, headers=headers, timeout=30)
    elapsed = time.time() - start_time
    
    if response.status_code != 200:
        error_text = response.text[:200] if response.text else 'æœªçŸ¥é”™è¯¯'
        return {
            'success': False,
            'error': f'HTTP {response.status_code}: {error_text}',
            'time': elapsed
        }
    
    result = response.json()
    
    # æå–å†…å®¹ï¼ˆOpenAIå…¼å®¹æ ¼å¼ï¼‰
    content = ''
    if 'choices' in result and len(result['choices']) > 0:
        choice = result['choices'][0]
        if 'message' in choice and 'content' in choice['message']:
            content = choice['message']['content'].strip()
    
    # ç»Ÿè®¡token
    input_tokens = 0
    output_tokens = 0
    if 'usage' in result:
        usage = result['usage']
        input_tokens = usage.get('prompt_tokens', usage.get('input_tokens', 0))
        output_tokens = usage.get('completion_tokens', usage.get('output_tokens', 0))
    
    # è®¡ç®—è´¹ç”¨ï¼ˆç«å±±å¼•æ“Žä»·æ ¼éœ€è¦æ ¹æ®å®žé™…æ¨¡åž‹ç¡®å®šï¼‰
    pricing = PRICING.get(model, {'input': 0.001, 'output': 0.004})  # é»˜è®¤ä»·æ ¼
    cost = (input_tokens / 1000 * pricing['input']) + (output_tokens / 1000 * pricing['output'])
    
    # è§£æžJSON
    if content:
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                question_text = parsed.get('question_text', '').strip()
                options = parsed.get('options', [])
                
                # æ ¼å¼åŒ–é€‰é¡¹
                formatted_options = []
                for i, opt in enumerate(options):
                    opt_str = str(opt).strip()
                    if not re.match(r'^[A-F]\.?\s', opt_str):
                        opt_str = f"{chr(65+i)}. {opt_str}"
                    formatted_options.append(opt_str)
                
                return {
                    'success': True,
                    'question_text': question_text,
                    'options': formatted_options,
                    'time': elapsed,
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens,
                    'total_tokens': input_tokens + output_tokens,
                    'cost': cost,
                    'raw_response': content
                }
            except Exception as e:
                # å¦‚æžœJSONè§£æžå¤±è´¥ï¼Œå°è¯•ç›´æŽ¥æå–
                pass
    
    return {
        'success': False,
        'error': 'è§£æžå¤±è´¥',
        'time': elapsed,
        'input_tokens': input_tokens,
        'output_tokens': output_tokens,
        'cost': cost,
        'raw_response': content or str(result)[:500]
    }

def evaluate_result(result: Dict) -> Dict:
    """è¯„ä¼°æå–ç»“æžœçš„è´¨é‡"""
    if not result.get('success'):
        return {
            'has_question': False,
            'has_options': False,
            'options_count': 0,
            'score': 0.0
        }
    
    question_text = result.get('question_text', '').strip()
    options = result.get('options', [])
    
    has_question = len(question_text) > 10
    has_options = len(options) >= 2
    options_count = len(options)
    
    # è¯„åˆ†ï¼ˆ0-1ï¼‰
    score = 0.0
    if has_question:
        score += 0.5
    if has_options:
        score += 0.3
    if 2 <= options_count <= 6:
        score += 0.2
    
    return {
        'has_question': has_question,
        'has_options': has_options,
        'options_count': options_count,
        'score': score,
        'question_length': len(question_text)
    }

def main():
    print("="*70)
    print("ðŸš€ å¤šAIæœåŠ¡æ¨¡åž‹å¯¹æ¯”æµ‹è¯•")
    print("="*70)
    print("\næµ‹è¯•é…ç½®ï¼š")
    print("  1. ç»Ÿä¸€ä½¿ç”¨æœ¬åœ°OCRï¼ˆPaddleOCRï¼‰")
    print("  2. OCRæ–‡å­—å‘é€ç»™å„AIæ¨¡åž‹æå–é¢˜ç›®å’Œé€‰é¡¹")
    print("  3. æµ‹è¯•æŒ‡æ ‡ï¼šå‡†ç¡®çŽ‡ã€é€Ÿåº¦ã€è´¹ç”¨ã€tokenæ•°é‡")
    print("  4. ä¸ä½¿ç”¨æ€è€ƒæ¨¡å¼ï¼Œåªæå–é¢˜ç›®å’Œé€‰é¡¹\n")
    
    # åˆå§‹åŒ–OCR
    print("ðŸ“¦ æ­£åœ¨åˆå§‹åŒ–PaddleOCRæ¨¡åž‹...")
    try:
        from ocr_service import get_ocr_service
        load_start = time.time()
        ocr_service = get_ocr_service()
        load_time = time.time() - load_start
        
        if not ocr_service.ocr_engine:
            print("âŒ æœ¬åœ°OCRä¸å¯ç”¨ï¼ˆPaddleOCRæœªå®‰è£…ï¼‰")
            return
        else:
            print(f"âœ… OCRå·²å°±ç»ªï¼ŒåŠ è½½è€—æ—¶: {load_time:.2f}ç§’\n")
    except Exception as e:
        print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    test_images = load_test_images(max_images=None)
    if not test_images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    print(f"ðŸ“· æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡\n")
    
    # æ˜¾ç¤ºAIæœåŠ¡é…ç½®çŠ¶æ€
    print("ðŸ”§ AIæœåŠ¡é…ç½®çŠ¶æ€:")
    print(f"   âœ… é˜¿é‡Œäº‘: {len(ALIBABA_MODELS)} ä¸ªæ¨¡åž‹")
    print(f"   âœ… DeepSeek: {len(DEEPSEEK_MODELS)} ä¸ªæ¨¡åž‹")
    if VOLCENGINE_MODELS:
        print(f"   âœ… ç«å±±å¼•æ“Ž: {len(VOLCENGINE_MODELS)} ä¸ªæŽ¥å…¥ç‚¹")
    else:
        print(f"   âš ï¸  ç«å±±å¼•æ“Ž: æœªé…ç½®æŽ¥å…¥ç‚¹IDï¼ˆå°†åœ¨æµ‹è¯•æ—¶è·³è¿‡ï¼‰")
        print(f"      æç¤º: è®¾ç½®çŽ¯å¢ƒå˜é‡ VOLCENGINE_ENDPOINT_IDS=ep-xxxxxx ä»¥å¯ç”¨ç«å±±å¼•æ“Žæµ‹è¯•")
    print()
    
    # å®šä¹‰è¦æµ‹è¯•çš„æ¨¡åž‹é…ç½®
    test_configs = []
    
    # é˜¿é‡Œäº‘æ¨¡åž‹
    for model in ALIBABA_MODELS:
        test_configs.append({
            'provider': 'alibaba',
            'model': model,
            'name': f'é˜¿é‡Œäº‘-{model}'
        })
    
    # DeepSeekæ¨¡åž‹
    for model in DEEPSEEK_MODELS:
        test_configs.append({
            'provider': 'deepseek',
            'model': model,
            'name': f'DeepSeek-{model}'
        })
    
    # ç«å±±å¼•æ“Žæ¨¡åž‹
    for model in VOLCENGINE_MODELS:
        test_configs.append({
            'provider': 'volcengine',
            'model': model,
            'name': f'ç«å±±å¼•æ“Ž-{model}'
        })
    
    print(f"ðŸ“Š å°†æµ‹è¯• {len(test_configs)} ä¸ªAIæ¨¡åž‹é…ç½®\n")
    
    # å­˜å‚¨æ‰€æœ‰ç»“æžœ
    all_results = {}
    
    # å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•
    for img_idx, img_path in enumerate(test_images, 1):
        image_name = os.path.basename(img_path)
        print(f"\n{'='*70}")
        print(f"ðŸ“· å›¾ç‰‡ {img_idx}/{len(test_images)}: {image_name}")
        print(f"{'='*70}\n")
        
        # ç¬¬ä¸€æ­¥ï¼šOCRè¯†åˆ«ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
        print("â³ æ­¥éª¤1: OCRè¯†åˆ«ä¸­...")
        ocr_result = get_ocr_text(img_path)
        
        if not ocr_result.get('success'):
            print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {ocr_result.get('error')}\n")
            continue
        
        raw_text = ocr_result.get('raw_text', '')
        print(f"âœ… OCRè¯†åˆ«æˆåŠŸ - è€—æ—¶: {ocr_result['time']:.2f}ç§’")
        print(f"ðŸ“Š OCRè¯†åˆ«å­—ç¬¦æ•°: {len(raw_text)} å­—ç¬¦\n")
        
        # æ˜¾ç¤ºOCRå†…å®¹ï¼ˆç®€è¦ï¼‰
        print("ðŸ“ OCRè¯†åˆ«å†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰:")
        print(f"{raw_text[:200]}...\n")
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨å„ä¸ªAIæ¨¡åž‹æå–
        for config_idx, config in enumerate(test_configs, 1):
            provider = config['provider']
            model = config['model']
            config_name = config['name']
            
            print(f"  [{config_idx}/{len(test_configs)}] æµ‹è¯• {config_name}...", end=' ', flush=True)
            
            try:
                ai_result = call_ai_model(provider, model, raw_text)
                
                if ai_result.get('success'):
                    eval_result = evaluate_result(ai_result)
                    print(f"âœ… æˆåŠŸ")
                    print(f"     è€—æ—¶: {ai_result['time']:.2f}ç§’")
                    print(f"     é¢˜ç›®é•¿åº¦: {eval_result['question_length']} å­—ç¬¦")
                    print(f"     é€‰é¡¹æ•°: {eval_result['options_count']}")
                    print(f"     è¯„åˆ†: {eval_result['score']:.2f}")
                    print(f"     Token: {ai_result.get('total_tokens', 0)} (è¾“å…¥:{ai_result.get('input_tokens', 0)}, è¾“å‡º:{ai_result.get('output_tokens', 0)})")
                    print(f"     è´¹ç”¨: Â¥{ai_result.get('cost', 0):.6f}")
                    print(f"\n     ðŸ“ è¯†åˆ«ç»“æžœ:")
                    question_text = ai_result.get('question_text', '').strip()
                    if question_text:
                        print(f"     é¢˜ç›®: {question_text}")
                    options = ai_result.get('options', [])
                    if options:
                        print(f"     é€‰é¡¹:")
                        for opt in options:
                            print(f"       {opt}")
                    
                    # ä¿å­˜ç»“æžœ
                    key = f"{image_name}|{config_name}"
                    all_results[key] = {
                        'image_name': image_name,
                        'provider': provider,
                        'model': model,
                        'config_name': config_name,
                        'ocr_time': ocr_result['time'],
                        'ai_time': ai_result['time'],
                        'total_time': ocr_result['time'] + ai_result['time'],
                        'question_text': ai_result.get('question_text', ''),
                        'options': ai_result.get('options', []),
                        'options_count': eval_result['options_count'],
                        'score': eval_result['score'],
                        'input_tokens': ai_result.get('input_tokens', 0),
                        'output_tokens': ai_result.get('output_tokens', 0),
                        'total_tokens': ai_result.get('total_tokens', 0),
                        'cost': ai_result.get('cost', 0),
                        'success': True
                    }
                else:
                    print(f"âŒ å¤±è´¥: {ai_result.get('error', 'unknown')}")
                    key = f"{image_name}|{config_name}"
                    all_results[key] = {
                        'image_name': image_name,
                        'provider': provider,
                        'model': model,
                        'config_name': config_name,
                        'ocr_time': ocr_result['time'],
                        'ai_time': ai_result.get('time', 0),
                        'total_time': ocr_result['time'] + ai_result.get('time', 0),
                        'error': ai_result.get('error', 'unknown'),
                        'success': False
                    }
            except Exception as e:
                print(f"âŒ å¼‚å¸¸: {str(e)[:50]}")
                key = f"{image_name}|{config_name}"
                all_results[key] = {
                    'image_name': image_name,
                    'provider': provider,
                    'model': model,
                    'config_name': config_name,
                    'error': str(e)[:100],
                    'success': False
                }
            
            print()  # ç©ºè¡Œåˆ†éš”
    
    # æ‰“å°ç»Ÿè®¡æ€»ç»“
    print(f"\n{'='*70}")
    print("ðŸ“Š æµ‹è¯•ç»“æžœç»Ÿè®¡æ€»ç»“")
    print(f"{'='*70}\n")
    
    # æŒ‰æ¨¡åž‹åˆ†ç»„ç»Ÿè®¡
    model_stats = {}
    for key, result in all_results.items():
        config_name = result['config_name']
        if config_name not in model_stats:
            model_stats[config_name] = {
                'results': [],
                'provider': result.get('provider', 'unknown'),
                'model': result.get('model', 'unknown')
            }
        model_stats[config_name]['results'].append(result)
    
    # æ‰“å°æ¯ä¸ªæ¨¡åž‹çš„ç»Ÿè®¡
    print("å„æ¨¡åž‹æµ‹è¯•ç»“æžœ:\n")
    
    for config_name in sorted(model_stats.keys()):
        stats = model_stats[config_name]
        results = stats['results']
        success_results = [r for r in results if r.get('success')]
        
        if not success_results:
            print(f"âŒ {config_name}: å…¨éƒ¨å¤±è´¥")
            continue
        
        success_rate = len(success_results) / len(results) * 100
        avg_time = mean([r['total_time'] for r in success_results])
        avg_score = mean([r.get('score', 0) for r in success_results])
        avg_tokens = mean([r.get('total_tokens', 0) for r in success_results])
        total_cost = sum([r.get('cost', 0) for r in success_results])
        avg_cost = total_cost / len(success_results) if success_results else 0
        
        print(f"ðŸ“Š {config_name}:")
        print(f"   æˆåŠŸçŽ‡: {success_rate:.1f}% ({len(success_results)}/{len(results)})")
        print(f"   å¹³å‡è€—æ—¶: {avg_time:.2f}ç§’")
        print(f"   å¹³å‡è¯„åˆ†: {avg_score:.2f}")
        print(f"   å¹³å‡Token: {avg_tokens:.0f}")
        print(f"   å¹³å‡è´¹ç”¨: Â¥{avg_cost:.6f}/æ¬¡")
        print()
    
    # æ‰“å°è¯¦ç»†çš„è¯†åˆ«å†…å®¹å¯¹æ¯”
    print(f"\n{'='*70}")
    print("ðŸ“ å„æ¨¡åž‹è¯†åˆ«å†…å®¹è¯¦ç»†å¯¹æ¯”")
    print(f"{'='*70}\n")
    
    for img_idx, img_path in enumerate(test_images, 1):
        image_name = os.path.basename(img_path)
        print(f"\nðŸ“· å›¾ç‰‡ {img_idx}/{len(test_images)}: {image_name}")
        print("="*70)
        
        # æŒ‰æ¨¡åž‹åˆ†ç»„æ˜¾ç¤ºç»“æžœ
        for config in test_configs:
            config_name = config['name']
            key = f"{image_name}|{config_name}"
            result = all_results.get(key)
            
            if not result:
                continue
                
            if result.get('success'):
                print(f"\nã€{config_name}ã€‘")
                question_text = result.get('question_text', '').strip()
                if question_text:
                    print(f"é¢˜ç›®: {question_text}")
                options = result.get('options', [])
                if options:
                    print("é€‰é¡¹:")
                    for opt in options:
                        print(f"  {opt}")
                print(f"è€—æ—¶: {result.get('ai_time', 0):.2f}ç§’ | Token: {result.get('total_tokens', 0)} | è´¹ç”¨: Â¥{result.get('cost', 0):.6f}")
            else:
                print(f"\nã€{config_name}ã€‘âŒ å¤±è´¥: {result.get('error', 'unknown')}")
        
        print("\n" + "-"*70)
    
    print(f"\n{'='*70}")
    print("âœ… æµ‹è¯•å®Œæˆ")
    print(f"{'='*70}\n")

if __name__ == '__main__':
    main()
