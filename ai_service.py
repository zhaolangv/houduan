"""
AIè§£ææœåŠ¡ï¼šå¤„ç†AIè°ƒç”¨å’Œç¼“å­˜é€»è¾‘
"""
import os
import sys
import logging
from openai import OpenAI
from models_v2 import db, Question, AnswerVersion
from image_utils import calculate_all_features, find_similar_image
from embedding_service import get_embedding_service
from ocr_service import get_ocr_service
from image_description_service import get_image_description_service
import imagehash

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class AIService:
    """AIè§£ææœåŠ¡ç±»"""
    
    def __init__(self):
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ˆæ”¯æŒOpenAIå’ŒDeepSeekï¼‰
        api_key = os.getenv('AI_API_KEY', os.getenv('OPENAI_API_KEY', ''))
        api_base = os.getenv('AI_API_BASE', os.getenv('OPENAI_API_BASE', ''))
        ai_provider = os.getenv('AI_PROVIDER', 'deepseek').lower()  # deepseek æˆ– openai
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not api_key:
            logger.warning("[AI] æœªé…ç½®AI_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            self.client = None
        else:
            # æ ¹æ®providerè®¾ç½®é»˜è®¤å€¼
            if ai_provider == 'deepseek':
                if not api_base:
                    api_base = 'https://api.deepseek.com/v1'
                if not api_key.startswith('sk-'):
                    logger.warning("[AI] DeepSeek API keyæ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
                try:
                    self.client = OpenAI(api_key=api_key, base_url=api_base)
                    self.default_model = os.getenv('AI_MODEL', 'deepseek-chat')
                    logger.info(f"[AI] ä½¿ç”¨DeepSeek API: {api_base}, model={self.default_model}")
                except Exception as e:
                    logger.error(f"[AI] DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.client = None
            else:  # openai
                if not api_base:
                    api_base = 'https://api.openai.com/v1'
                try:
                    self.client = OpenAI(api_key=api_key, base_url=api_base)
                    self.default_model = os.getenv('AI_MODEL', 'gpt-4')
                    logger.info(f"[AI] ä½¿ç”¨OpenAI API: {api_base}, model={self.default_model}")
                except Exception as e:
                    logger.error(f"[AI] OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.client = None
        
        self.ai_provider = ai_provider
    
    def analyze_question(self, question_type, question_content=None, image_url=None, question_id=None):
        """
        è§£æé¢˜ç›®ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼‰
        
        Args:
            question_type: é¢˜ç›®ç±»å‹ï¼ˆå¦‚ï¼šå›¾æ¨ã€è¨€è¯­ã€åˆ¤æ–­ç­‰ï¼‰
            question_content: é¢˜ç›®æ–‡æœ¬å†…å®¹
            image_url: å›¾ç‰‡URLï¼ˆå›¾æ¨é¢˜ï¼‰
            question_id: é¢˜ç›®å”¯ä¸€IDï¼ˆå¦‚æœæœ‰ï¼‰
            
        Returns:
            dict: {
                'analysis': AIè§£æå†…å®¹,
                'from_cache': æ˜¯å¦æ¥è‡ªç¼“å­˜,
                'question_id': é¢˜ç›®ID
            }
        """
        # 1. å°è¯•æŸ¥æ‰¾å·²å­˜åœ¨çš„é¢˜ç›®
        existing_question = None
        
        if question_id:
            # å¦‚æœæœ‰é¢˜ç›®IDï¼Œç›´æ¥ç”¨IDæŸ¥æ‰¾
            try:
                existing_question = Question.query.filter_by(id=question_id).first()
            except:
                existing_question = None
        
        if not existing_question and image_url:
            # å¯¹äºå›¾æ¨é¢˜ï¼Œä½¿ç”¨å¤šç§æ–¹æ³•æŸ¥æ‰¾
            logger.info(f"[AI] å¼€å§‹è®¡ç®—å›¾ç‰‡ç‰¹å¾: {image_url[:80]}...")
            # 1. å…ˆè®¡ç®—æ‰€æœ‰ç‰¹å¾ï¼ˆMD5ã€æ„ŸçŸ¥å“ˆå¸Œã€Embeddingï¼‰
            try:
                features = calculate_all_features(image_url)
                md5_hash = features['md5_hash']
                phash = features['phash']
                embedding = features['embedding']
                logger.info(f"[AI] ç‰¹å¾è®¡ç®—å®Œæˆ: md5={md5_hash[:16]}..., phash={phash}, embedding={'å­˜åœ¨' if embedding is not None else 'None'}")
            except Exception as e:
                logger.error(f"[AI] ç‰¹å¾è®¡ç®—å‡ºé”™: {e}", exc_info=True)
                raise
            
            # 2. å…ˆå°è¯•ç”¨MD5å“ˆå¸Œç²¾ç¡®åŒ¹é…ï¼ˆæœ€å¿«ï¼‰
            existing_question = Question.query.filter_by(image_hash=md5_hash).first()
            
            # 3. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨Perceptual Hashå’ŒEmbeddingç»¼åˆæŸ¥æ‰¾
            if not existing_question:
                # å°†embeddingè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                embedding_array = None
                logger.debug(f"[AI] æ£€æŸ¥embedding: type={type(embedding)}, is None={embedding is None}")
                if embedding is not None:  # ä¿®å¤ï¼šä¸èƒ½ç›´æ¥ç”¨if embeddingåˆ¤æ–­æ•°ç»„
                    logger.info(f"[AI] embeddingå­˜åœ¨ï¼Œå¼€å§‹è½¬æ¢: {type(embedding)}")
                    embedding_service = get_embedding_service()
                    embedding_array = embedding_service.list_to_embedding(embedding)
                    logger.info(f"[AI] embeddingè½¬æ¢å®Œæˆ: type={type(embedding_array)}, shape={embedding_array.shape if hasattr(embedding_array, 'shape') else 'N/A'}")
                else:
                    logger.debug("[AI] embeddingä¸ºNoneï¼Œè·³è¿‡EmbeddingæŸ¥æ‰¾")
                
                existing_question = find_similar_image(
                    phash=phash,
                    embedding=embedding_array,
                    phash_threshold=5,
                    embedding_threshold=0.85,  # 85%ç›¸ä¼¼åº¦é˜ˆå€¼
                    db_session=db.session,
                    Question=Question,
                    use_both=True  # åŒæ—¶ä½¿ç”¨ä¸¤ç§æ–¹æ³•
                )
        
        # æ³¨æ„ï¼šæ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œæ–°çš„æ¶æ„ä½¿ç”¨ question_service_v2.py
        # ä¿ç•™æ­¤æ–¹æ³•ä»…ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†ä¿å­˜åˆ°æ•°æ®åº“
        logger.warning("[AI] analyze_questionæ–¹æ³•å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨question_service_v2.QuestionService")
        
        # 2. å¦‚æœæ‰¾åˆ°å·²å­˜åœ¨çš„é¢˜ç›®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç­”æ¡ˆç‰ˆæœ¬
        if existing_question and existing_question.answer_versions.count() > 0:
            # è·å–ç¬¬ä¸€ä¸ªç­”æ¡ˆç‰ˆæœ¬çš„è§£æ
            first_answer = existing_question.answer_versions.first()
            return {
                'analysis': first_answer.explanation or '',
                'from_cache': True,
                'question_id': existing_question.id
            }
        
        # 3. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè°ƒç”¨AIè§£æ
        ai_response = self._call_ai(question_type, question_content, image_url)
        
        # æ³¨æ„ï¼šä¸å†ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ–°çš„æ¶æ„ç”±question_service_v2å¤„ç†
        logger.warning("[AI] ä¸å†ä¿å­˜AIè§£æåˆ°æ•°æ®åº“ï¼Œè¯·ä½¿ç”¨question_service_v2")
        
        return {
            'analysis': ai_response,
            'from_cache': False,
            'question_id': None  # ä¸å†åˆ›å»ºé¢˜ç›®è®°å½•
        }
    
    def _call_ai(self, question_type, question_content=None, image_url=None):
        """
        è°ƒç”¨AIæ¥å£è§£æé¢˜ç›®
        
        Args:
            question_type: é¢˜ç›®ç±»å‹
            question_content: é¢˜ç›®æ–‡æœ¬å†…å®¹
            image_url: å›¾ç‰‡URL
            
        Returns:
            str: AIè§£æå†…å®¹
        """
        if not self.client:
            # å¦‚æœæ²¡æœ‰é…ç½®AIå®¢æˆ·ç«¯ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            return f"è¿™æ˜¯{question_type}é¢˜çš„AIè§£æï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰ã€‚å®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®AI APIã€‚"
        
        # æ„å»ºæç¤ºè¯
        if question_content and len(question_content) > 500:
            # å¦‚æœquestion_contentå¾ˆé•¿ï¼Œè¯´æ˜æ˜¯å®Œæ•´çš„æç¤ºè¯ï¼ˆåŒ…å«å›¾ç‰‡æè¿°ç­‰ï¼‰
            prompt = question_content
        else:
            # å¦åˆ™ä½¿ç”¨åŸæ¥çš„æ–¹å¼
            prompt = f"è¯·è¯¦ç»†è§£æè¿™é“{question_type}é¢˜ï¼ŒåŒ…æ‹¬ï¼š\n1. é¢˜ç›®ç±»å‹å’Œè€ƒç‚¹\n2. è§£é¢˜æ€è·¯\n3. è¯¦ç»†è§£ç­”è¿‡ç¨‹\n4. æ³¨æ„äº‹é¡¹"
            if question_content:
                prompt += f"\n\né¢˜ç›®å†…å®¹ï¼š{question_content}"
        
        # å¤„ç†å›¾ç‰‡ï¼šDeepSeekä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œéœ€è¦è½¬æ¢ä¸ºæ–‡å­—
        image_text_info = ""
        if image_url:
            logger.info(f"[AI] æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œå¼€å§‹åˆ†æå›¾ç‰‡ç±»å‹: {image_url[:50]}...")
            
            # æ­¥éª¤1: åˆ†æå›¾ç‰‡ç±»å‹ï¼ˆå›¾æ¨é¢˜ vs æ–‡å­—é¢˜ï¼‰
            ocr_service = get_ocr_service()
            image_analysis = None
            if ocr_service.ocr_engine:
                logger.info("[AI] å¼€å§‹åˆ†æå›¾ç‰‡ç±»å‹...")
                image_analysis = ocr_service.analyze_image_type(image_url)
                logger.info(f"[AI] å›¾ç‰‡ç±»å‹åˆ†æç»“æœ: {image_analysis['type']} (ç½®ä¿¡åº¦: {image_analysis['confidence']:.2f})")
            
            # æ­¥éª¤2: æ ¹æ®å›¾ç‰‡ç±»å‹æå–ä¿¡æ¯
            is_graph_question = image_analysis and image_analysis['type'] == 'graph'
            
            if is_graph_question:
                # å›¾æ¨é¢˜ï¼šä¼˜å…ˆä½¿ç”¨å›¾ç‰‡æè¿°ï¼ŒOCRæ–‡å­—ä½œä¸ºè¡¥å……
                logger.info("[AI] åˆ¤æ–­ä¸ºå›¾æ¨é¢˜ï¼Œä½¿ç”¨å›¾ç‰‡æè¿° + OCRæ–‡å­—")
                
                # å…ˆå°è¯•å›¾ç‰‡æè¿°ï¼ˆæè¿°å›¾å½¢ç‰¹å¾ï¼‰
                desc_service = get_image_description_service()
                if desc_service.model:
                    description = desc_service.describe_image(image_url)
                    image_text_info += f"\n\nã€å›¾ç‰‡æè¿°ã€‘ï¼ˆå›¾æ¨é¢˜ï¼‰\n{description}"
                
                # OCRæ–‡å­—ä½œä¸ºè¡¥å……ï¼ˆå¦‚æœæœ‰ï¼‰
                if image_analysis and image_analysis['text']:
                    image_text_info += f"\n\nã€å›¾ç‰‡ä¸­çš„æ–‡å­—ã€‘ï¼ˆè¡¥å……ä¿¡æ¯ï¼‰\n{image_analysis['text']}"
                
                # æ·»åŠ å›¾æ¨é¢˜ä¸“ç”¨æç¤º
                image_text_info += f"\n\nè¿™æ˜¯ä¸€é“å›¾å½¢æ¨ç†é¢˜ã€‚è¯·é‡ç‚¹åˆ†æï¼š\n1. å›¾å½¢çš„è§„å¾‹å’Œæ¨¡å¼\n2. ä½ç½®ã€æ•°é‡ã€å½¢çŠ¶ã€é¢œè‰²ç­‰å˜åŒ–\n3. å¯¹ç§°ã€æ—‹è½¬ã€å åŠ ç­‰å…³ç³»\n4. æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆé€‰æ‹©"
            else:
                # æ–‡å­—é¢˜ï¼šä¼˜å…ˆä½¿ç”¨OCRæ–‡å­—
                logger.info("[AI] åˆ¤æ–­ä¸ºæ–‡å­—é¢˜ï¼Œä½¿ç”¨OCRæ–‡å­—")
                
                if image_analysis and image_analysis['text']:
                    image_text_info += f"\n\nã€å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ã€‘\n{image_analysis['text']}"
                    image_text_info += f"\n\nè¿™æ˜¯ä¸€é“æ–‡å­—ç±»é¢˜ç›®ã€‚è¯·é‡ç‚¹åˆ†æï¼š\n1. æ–‡å­—å†…å®¹çš„è¯­ä¹‰ç†è§£\n2. é¢˜ç›®è¦æ±‚å’Œé€‰é¡¹åˆ†æ\n3. é€»è¾‘å…³ç³»å’Œæ¨ç†è¿‡ç¨‹"
                else:
                    # å¦‚æœOCRå¤±è´¥ï¼Œå°è¯•å›¾ç‰‡æè¿°
                    logger.info("[AI] OCRæœªæå–åˆ°æ–‡å­—ï¼Œå°è¯•ç”Ÿæˆå›¾ç‰‡æè¿°...")
                    desc_service = get_image_description_service()
                    if desc_service.model:
                        description = desc_service.describe_image(image_url)
                        image_text_info += f"\n\nã€å›¾ç‰‡æè¿°ã€‘\n{description}"
                    else:
                        image_text_info += f"\n\nè¿™æ˜¯ä¸€é“åŒ…å«å›¾ç‰‡çš„{question_type}é¢˜ã€‚ç”±äºå½“å‰AIæ¨¡å‹ä¸æ”¯æŒç›´æ¥æŸ¥çœ‹å›¾ç‰‡ï¼Œè¯·æ ¹æ®{question_type}é¢˜çš„å¸¸è§è€ƒç‚¹å’Œè§£é¢˜æ€è·¯è¿›è¡Œåˆ†æã€‚"
            
            prompt += image_text_info
        
        import time
        ai_start_time = time.time()
        
        # è®°å½•APIåŸºç¡€ä¿¡æ¯
        api_base_url = getattr(self.client._client, 'base_url', 'unknown') if self.client else 'unknown'
        logger.info(f"[AI] ğŸ¤– å‡†å¤‡è°ƒç”¨AI API")
        logger.info(f"[AI] ğŸ“‹ APIä¿¡æ¯: provider={self.ai_provider}, model={self.default_model}, base_url={api_base_url}")
        logger.info(f"[AI] ğŸ“ Promptä¿¡æ¯: é•¿åº¦={len(prompt)}å­—ç¬¦, é¢˜ç›®ç±»å‹={question_type}, åŒ…å«å›¾ç‰‡={'æ˜¯' if image_url else 'å¦'}")
        if len(prompt) > 0:
            logger.debug(f"[AI] ğŸ’¬ Promptå†…å®¹é¢„è§ˆï¼ˆå‰300å­—ç¬¦ï¼‰:\n{prompt[:300]}...")
        
        try:
            # DeepSeekä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œåªèƒ½ä½¿ç”¨æ–‡æœ¬æ¨¡å¼
            if image_url and self.ai_provider == 'deepseek':
                logger.info(f"[AI] ğŸš€ å¼€å§‹è°ƒç”¨DeepSeek API (æ¨¡å‹: {self.default_model})")
                logger.info(f"[AI] ğŸ“¤ è¯·æ±‚å‚æ•°: model={self.default_model}, max_tokens=2000, temperature=0.7")
                
                request_start = time.time()
                try:
                    response = self.client.chat.completions.create(
                        model=self.default_model,
                        messages=[
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=2000
                    )
                except Exception as api_error:
                    request_time = time.time() - request_start
                    total_time = time.time() - ai_start_time
                    error_type = type(api_error).__name__
                    logger.error(f"[AI] âŒ DeepSeek APIè¯·æ±‚å¤±è´¥: {error_type}: {str(api_error)}, è¯·æ±‚è€—æ—¶={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                    raise
                
                request_time = time.time() - request_start
                
                # è§£æå“åº”
                response_content = response.choices[0].message.content if response.choices else None
                response_length = len(response_content) if response_content else 0
                
                # æå–tokenä½¿ç”¨ä¿¡æ¯
                prompt_tokens = 0
                completion_tokens = 0
                total_tokens = 0
                if hasattr(response, 'usage') and response.usage:
                    usage = response.usage
                    prompt_tokens = getattr(usage, 'prompt_tokens', 0)
                    completion_tokens = getattr(usage, 'completion_tokens', 0)
                    total_tokens = getattr(usage, 'total_tokens', 0)
                
                # è®¡ç®—è´¹ç”¨ï¼ˆDeepSeekå®šä»·ï¼Œç¤ºä¾‹ï¼‰
                # æ³¨æ„ï¼šå®é™…å®šä»·å¯èƒ½ä¸åŒï¼Œè¿™é‡Œä»…ä½œå‚è€ƒ
                cost = 0.0
                if total_tokens > 0:
                    # DeepSeek Chatå®šä»·ç¤ºä¾‹ï¼ˆéœ€è¦æ ¹æ®å®é™…å®šä»·è°ƒæ•´ï¼‰
                    # å‡è®¾: è¾“å…¥ $0.14/1M tokens, è¾“å‡º $0.28/1M tokens
                    cost = (prompt_tokens / 1_000_000 * 0.14) + (completion_tokens / 1_000_000 * 0.28)
                
                total_time = time.time() - ai_start_time
                logger.info(f"[AI] âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ")
                logger.info(f"[AI] â±ï¸  è€—æ—¶ç»Ÿè®¡: APIè¯·æ±‚={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                logger.info(f"[AI] ğŸ“Š å“åº”ç»Ÿè®¡: å†…å®¹é•¿åº¦={response_length}å­—ç¬¦, prompt_tokens={prompt_tokens}, completion_tokens={completion_tokens}, total_tokens={total_tokens}")
                if cost > 0:
                    logger.info(f"[AI] ğŸ’° è´¹ç”¨ä¼°ç®—: Â¥{cost:.6f} (ä»…ä¾›å‚è€ƒï¼Œå®é™…è´¹ç”¨ä»¥DeepSeekå®šä»·ä¸ºå‡†)")
                logger.debug(f"[AI] ğŸ“ å“åº”å†…å®¹é¢„è§ˆï¼ˆå‰300å­—ç¬¦ï¼‰:\n{response_content[:300] if response_content else 'None'}...")
                
                return response_content
            # OpenAIæ”¯æŒå›¾ç‰‡ï¼ˆéœ€è¦visionæ¨¡å‹ï¼‰
            elif image_url and self.ai_provider == 'openai':
                logger.info(f"[AI] ğŸš€ å¼€å§‹è°ƒç”¨OpenAI API (æ¨¡å‹: {self.default_model})")
                logger.info(f"[AI] ğŸ“¤ è¯·æ±‚å‚æ•°: model={self.default_model}, åŒ…å«å›¾ç‰‡, max_tokens=2000, temperature=0.7")
                
                request_start = time.time()
                try:
                    response = self.client.chat.completions.create(
                        model=self.default_model,
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {"type": "image_url", "image_url": {"url": image_url}}
                                ]
                            }
                        ]
                    )
                except Exception as api_error:
                    request_time = time.time() - request_start
                    total_time = time.time() - ai_start_time
                    error_type = type(api_error).__name__
                    logger.error(f"[AI] âŒ OpenAI APIè¯·æ±‚å¤±è´¥: {error_type}: {str(api_error)}, è¯·æ±‚è€—æ—¶={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                    raise
                
                request_time = time.time() - request_start
                response_content = response.choices[0].message.content if response.choices else None
                response_length = len(response_content) if response_content else 0
                
                # æå–tokenä½¿ç”¨ä¿¡æ¯
                prompt_tokens = getattr(response.usage, 'prompt_tokens', 0) if hasattr(response, 'usage') and response.usage else 0
                completion_tokens = getattr(response.usage, 'completion_tokens', 0) if hasattr(response, 'usage') and response.usage else 0
                total_tokens = getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') and response.usage else 0
                
                total_time = time.time() - ai_start_time
                logger.info(f"[AI] âœ… OpenAI APIè°ƒç”¨æˆåŠŸ")
                logger.info(f"[AI] â±ï¸  è€—æ—¶ç»Ÿè®¡: APIè¯·æ±‚={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                logger.info(f"[AI] ğŸ“Š å“åº”ç»Ÿè®¡: å†…å®¹é•¿åº¦={response_length}å­—ç¬¦, total_tokens={total_tokens}")
                logger.debug(f"[AI] ğŸ“ å“åº”å†…å®¹é¢„è§ˆï¼ˆå‰300å­—ç¬¦ï¼‰:\n{response_content[:300] if response_content else 'None'}...")
                
                return response_content
            else:
                # çº¯æ–‡æœ¬é¢˜ç›®
                logger.info(f"[AI] ğŸš€ å¼€å§‹è°ƒç”¨AI API (provider: {self.ai_provider}, model: {self.default_model})")
                logger.info(f"[AI] ğŸ“¤ è¯·æ±‚å‚æ•°: model={self.default_model}, max_tokens=2000, temperature=0.7")
                
                request_start = time.time()
                try:
                    response = self.client.chat.completions.create(
                        model=self.default_model,
                        messages=[
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=2000
                    )
                except Exception as api_error:
                    request_time = time.time() - request_start
                    total_time = time.time() - ai_start_time
                    error_type = type(api_error).__name__
                    logger.error(f"[AI] âŒ AI APIè¯·æ±‚å¤±è´¥: {error_type}: {str(api_error)}, è¯·æ±‚è€—æ—¶={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                    raise
                
                request_time = time.time() - request_start
                response_content = response.choices[0].message.content if response.choices else None
                response_length = len(response_content) if response_content else 0
                
                total_time = time.time() - ai_start_time
                logger.info(f"[AI] âœ… AI APIè°ƒç”¨æˆåŠŸ")
                logger.info(f"[AI] â±ï¸  è€—æ—¶ç»Ÿè®¡: APIè¯·æ±‚={request_time:.2f}ç§’, æ€»è®¡={total_time:.2f}ç§’")
                logger.info(f"[AI] ğŸ“Š å“åº”ç»Ÿè®¡: å†…å®¹é•¿åº¦={response_length}å­—ç¬¦")
                logger.debug(f"[AI] ğŸ“ å“åº”å†…å®¹é¢„è§ˆï¼ˆå‰300å­—ç¬¦ï¼‰:\n{response_content[:300] if response_content else 'None'}...")
                
                return response_content
            
        except Exception as e:
            total_time = time.time() - ai_start_time
            error_type = type(e).__name__
            error_msg = str(e)
            logger.error(f"[AI] âŒ AI APIè°ƒç”¨å¤±è´¥: {error_type}: {error_msg}, è€—æ—¶={total_time:.2f}ç§’", exc_info=True)
            return f"AIè§£æå‡ºé”™ï¼š{str(e)}"

