"""
æ•°æ®åº“è¿ç§»è„šæœ¬ï¼šä» SQLite è¿ç§»åˆ° PostgreSQL/MySQL

ä½¿ç”¨æ–¹æ³•ï¼š
1. é…ç½®ç›®æ ‡æ•°æ®åº“ï¼ˆ.env æ–‡ä»¶ä¸­çš„ DATABASE_URLï¼‰
2. è¿è¡Œè„šæœ¬ï¼špython migrate_database.py
"""
import os
import sys
from datetime import datetime
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from sqlalchemy import create_engine, inspect, text
from sqlalchemy.orm import sessionmaker, scoped_session
import json


def get_sqlite_url():
    """è·å– SQLite æ•°æ®åº“ URL"""
    sqlite_path = os.getenv('SQLITE_DB_PATH', 'gongkao_test.db')
    if not os.path.exists(sqlite_path):
        logger.warning(f"âš ï¸ SQLite æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {sqlite_path}")
        logger.info("ğŸ’¡ æç¤º: å¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ SQLITE_DB_PATH æŒ‡å®š SQLite æ•°æ®åº“è·¯å¾„")
        return None
    return f'sqlite:///{sqlite_path}'


def get_target_db_url():
    """è·å–ç›®æ ‡æ•°æ®åº“ URL"""
    db_url = os.getenv('DATABASE_URL')
    if not db_url:
        logger.error("âŒ æœªé…ç½® DATABASE_URL ç¯å¢ƒå˜é‡")
        logger.info("ğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ç›®æ ‡æ•°æ®åº“è¿æ¥ï¼Œä¾‹å¦‚ï¼š")
        logger.info("   PostgreSQL: postgresql://user:password@host:port/database")
        logger.info("   MySQL: mysql+pymysql://user:password@host:port/database")
        return None
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ SQLiteï¼ˆä¸åº”è¯¥ä½œä¸ºç›®æ ‡ï¼‰
    if db_url.startswith('sqlite'):
        logger.error("âŒ ç›®æ ‡æ•°æ®åº“ä¸èƒ½æ˜¯ SQLiteï¼Œè¯·é…ç½® PostgreSQL æˆ– MySQL")
        return None
    
    return db_url


def check_database_connection(engine, db_name):
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        logger.info(f"âœ… {db_name} æ•°æ®åº“è¿æ¥æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ {db_name} æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False


def get_table_row_count(engine, table_name):
    """è·å–è¡¨çš„è¡Œæ•°"""
    try:
        with engine.connect() as conn:
            result = conn.execute(text(f"SELECT COUNT(*) FROM {table_name}"))
            count = result.scalar()
            return count
    except Exception as e:
        logger.warning(f"âš ï¸ æ— æ³•è·å–è¡¨ {table_name} çš„è¡Œæ•°: {e}")
        return 0


def migrate_questions(sqlite_session, target_session, Question):
    """è¿ç§»é¢˜ç›®è¡¨"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ“¦ å¼€å§‹è¿ç§» questions è¡¨...")
    
    # è·å–æ‰€æœ‰é¢˜ç›®
    questions = sqlite_session.query(Question).all()
    total_count = len(questions)
    
    if total_count == 0:
        logger.info("â„¹ï¸ SQLite ä¸­æ²¡æœ‰é¢˜ç›®æ•°æ®ï¼Œè·³è¿‡è¿ç§»")
        return 0
    
    logger.info(f"ğŸ“Š æ‰¾åˆ° {total_count} æ¡é¢˜ç›®è®°å½•")
    
    migrated = 0
    skipped = 0
    errors = 0
    
    for i, question in enumerate(questions, 1):
        try:
            # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            existing = target_session.query(Question).filter_by(id=question.id).first()
            
            if existing:
                logger.debug(f"â­ï¸  é¢˜ç›® {i}/{total_count} (ID: {question.id}) å·²å­˜åœ¨ï¼Œè·³è¿‡")
                skipped += 1
                continue
            
            # å¤„ç† JSON å­—æ®µ
            options = question.options
            if isinstance(options, str):
                try:
                    options = json.loads(options) if options else None
                except:
                    options = None
            
            tags = question.tags
            if isinstance(tags, str):
                try:
                    tags = json.loads(tags) if tags else None
                except:
                    tags = None
            
            knowledge_points = question.knowledge_points
            if isinstance(knowledge_points, str):
                try:
                    knowledge_points = json.loads(knowledge_points) if knowledge_points else None
                except:
                    knowledge_points = None
            
            similar_questions = question.similar_questions
            if isinstance(similar_questions, str):
                try:
                    similar_questions = json.loads(similar_questions) if similar_questions else None
                except:
                    similar_questions = None
            
            # åˆ›å»ºæ–°é¢˜ç›®è®°å½•
            new_question = Question(
                id=question.id,
                screenshot=question.screenshot,
                raw_text=question.raw_text,
                question_text=question.question_text,
                question_type=question.question_type or 'TEXT',
                options=options,
                correct_answer=question.correct_answer,
                explanation=question.explanation,
                tags=tags,
                knowledge_points=knowledge_points,
                source=question.source,
                source_url=question.source_url,
                encountered_date=question.encountered_date,
                difficulty=question.difficulty,
                priority=question.priority,
                ocr_confidence=question.ocr_confidence,
                similar_questions=similar_questions,
                question_hash=question.question_hash,
                created_at=question.created_at or datetime.utcnow(),
                updated_at=question.updated_at or datetime.utcnow()
            )
            
            target_session.add(new_question)
            
            if i % 10 == 0 or i == total_count:
                target_session.commit()
                logger.info(f"âœ… å·²è¿ç§» {i}/{total_count} æ¡é¢˜ç›®è®°å½• (æˆåŠŸ: {i - skipped - errors}, è·³è¿‡: {skipped}, é”™è¯¯: {errors})")
            
            migrated += 1
            
        except Exception as e:
            errors += 1
            logger.error(f"âŒ è¿ç§»é¢˜ç›® {i}/{total_count} (ID: {question.id}) å¤±è´¥: {e}")
            target_session.rollback()
            continue
    
    # æœ€ç»ˆæäº¤
    try:
        target_session.commit()
        logger.info(f"âœ… questions è¡¨è¿ç§»å®Œæˆ!")
        logger.info(f"   æˆåŠŸ: {migrated}, è·³è¿‡: {skipped}, é”™è¯¯: {errors}")
    except Exception as e:
        logger.error(f"âŒ æäº¤å¤±è´¥: {e}")
        target_session.rollback()
    
    return migrated


def migrate_answer_versions(sqlite_session, target_session, AnswerVersion):
    """è¿ç§»ç­”æ¡ˆç‰ˆæœ¬è¡¨"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ“¦ å¼€å§‹è¿ç§» answer_versions è¡¨...")
    
    # è·å–æ‰€æœ‰ç­”æ¡ˆç‰ˆæœ¬
    answer_versions = sqlite_session.query(AnswerVersion).all()
    total_count = len(answer_versions)
    
    if total_count == 0:
        logger.info("â„¹ï¸ SQLite ä¸­æ²¡æœ‰ç­”æ¡ˆç‰ˆæœ¬æ•°æ®ï¼Œè·³è¿‡è¿ç§»")
        return 0
    
    logger.info(f"ğŸ“Š æ‰¾åˆ° {total_count} æ¡ç­”æ¡ˆç‰ˆæœ¬è®°å½•")
    
    migrated = 0
    skipped = 0
    errors = 0
    
    for i, answer_version in enumerate(answer_versions, 1):
        try:
            # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨
            existing = target_session.query(AnswerVersion).filter_by(id=answer_version.id).first()
            
            if existing:
                logger.debug(f"â­ï¸  ç­”æ¡ˆç‰ˆæœ¬ {i}/{total_count} (ID: {answer_version.id}) å·²å­˜åœ¨ï¼Œè·³è¿‡")
                skipped += 1
                continue
            
            # åˆ›å»ºæ–°ç­”æ¡ˆç‰ˆæœ¬è®°å½•
            new_answer_version = AnswerVersion(
                id=answer_version.id,
                question_id=answer_version.question_id,
                source_name=answer_version.source_name,
                source_type=answer_version.source_type,
                answer=answer_version.answer,
                explanation=answer_version.explanation,
                confidence=answer_version.confidence,
                is_user_preferred=answer_version.is_user_preferred or False,
                created_at=answer_version.created_at or datetime.utcnow(),
                updated_at=answer_version.updated_at or datetime.utcnow()
            )
            
            target_session.add(new_answer_version)
            
            if i % 50 == 0 or i == total_count:
                target_session.commit()
                logger.info(f"âœ… å·²è¿ç§» {i}/{total_count} æ¡ç­”æ¡ˆç‰ˆæœ¬è®°å½• (æˆåŠŸ: {i - skipped - errors}, è·³è¿‡: {skipped}, é”™è¯¯: {errors})")
            
            migrated += 1
            
        except Exception as e:
            errors += 1
            logger.error(f"âŒ è¿ç§»ç­”æ¡ˆç‰ˆæœ¬ {i}/{total_count} (ID: {answer_version.id}) å¤±è´¥: {e}")
            target_session.rollback()
            continue
    
    # æœ€ç»ˆæäº¤
    try:
        target_session.commit()
        logger.info(f"âœ… answer_versions è¡¨è¿ç§»å®Œæˆ!")
        logger.info(f"   æˆåŠŸ: {migrated}, è·³è¿‡: {skipped}, é”™è¯¯: {errors}")
    except Exception as e:
        logger.error(f"âŒ æäº¤å¤±è´¥: {e}")
        target_session.rollback()
    
    return migrated


def create_tables_if_not_exist(target_engine):
    """åœ¨ç›®æ ‡æ•°æ®åº“ä¸­åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    logger.info("\n" + "="*70)
    logger.info("ğŸ“‹ æ£€æŸ¥ç›®æ ‡æ•°æ®åº“è¡¨ç»“æ„...")
    
    # åˆ›å»º Flask åº”ç”¨ä¸Šä¸‹æ–‡æ¥åˆå§‹åŒ–è¡¨
    from flask import Flask
    from models_v2 import db, Question, AnswerVersion
    
    app = Flask(__name__)
    app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL')
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    
    # æ ¹æ®æ•°æ®åº“ç±»å‹é…ç½®è¿æ¥æ± 
    if 'postgresql' in os.getenv('DATABASE_URL', '').lower():
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 10,
            'max_overflow': 10,
        }
    elif 'mysql' in os.getenv('DATABASE_URL', '').lower():
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 10,
            'max_overflow': 10,
        }
    
    db.init_app(app)
    
    with app.app_context():
        inspector = inspect(target_engine)
        existing_tables = inspector.get_table_names()
        
        if 'questions' in existing_tables and 'answer_versions' in existing_tables:
            logger.info("âœ… ç›®æ ‡æ•°æ®åº“è¡¨å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
        else:
            logger.info("ğŸ“ åˆ›å»ºæ•°æ®åº“è¡¨...")
            db.create_all()
            logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("="*70)
    logger.info("ğŸš€ æ•°æ®åº“è¿ç§»å·¥å…·")
    logger.info("="*70)
    
    # 1. è·å– SQLite æ•°æ®åº“è·¯å¾„
    sqlite_url = get_sqlite_url()
    if not sqlite_url:
        logger.error("âŒ æ— æ³•æ‰¾åˆ° SQLite æ•°æ®åº“ï¼Œè¿ç§»ç»ˆæ­¢")
        return
    
    # 2. è·å–ç›®æ ‡æ•°æ®åº“ URL
    target_db_url = get_target_db_url()
    if not target_db_url:
        logger.error("âŒ ç›®æ ‡æ•°æ®åº“é…ç½®é”™è¯¯ï¼Œè¿ç§»ç»ˆæ­¢")
        return
    
    logger.info(f"\nğŸ“‚ SQLite æ•°æ®åº“: {sqlite_url.replace('sqlite:///', '')}")
    logger.info(f"ğŸ¯ ç›®æ ‡æ•°æ®åº“: {target_db_url.split('@')[-1] if '@' in target_db_url else target_db_url}")
    
    # 3. åˆ›å»ºæ•°æ®åº“å¼•æ“
    try:
        sqlite_engine = create_engine(sqlite_url, echo=False)
        target_engine = create_engine(target_db_url, echo=False)
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“å¼•æ“å¤±è´¥: {e}")
        return
    
    # 4. æ£€æŸ¥è¿æ¥
    if not check_database_connection(sqlite_engine, "SQLite"):
        return
    
    if not check_database_connection(target_engine, "ç›®æ ‡æ•°æ®åº“"):
        return
    
    # 5. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    sqlite_inspector = inspect(sqlite_engine)
    sqlite_tables = sqlite_inspector.get_table_names()
    
    if 'questions' not in sqlite_tables:
        logger.warning("âš ï¸ SQLite æ•°æ®åº“ä¸­ä¸å­˜åœ¨ questions è¡¨")
        logger.info("ğŸ’¡ å¯èƒ½æ˜¯æ–°æ•°æ®åº“ï¼Œæ— éœ€è¿ç§»")
        return
    
    # 6. åˆ›å»º Flask åº”ç”¨å’Œæ•°æ®åº“ä¼šè¯
    from flask import Flask
    from models_v2 import db, Question, AnswerVersion
    
    # SQLite åº”ç”¨
    sqlite_app = Flask(__name__)
    sqlite_app.config['SQLALCHEMY_DATABASE_URI'] = sqlite_url
    sqlite_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    db.init_app(sqlite_app)
    
    # ç›®æ ‡æ•°æ®åº“åº”ç”¨
    target_app = Flask(__name__)
    target_app.config['SQLALCHEMY_DATABASE_URI'] = target_db_url
    target_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    
    # æ ¹æ®æ•°æ®åº“ç±»å‹é…ç½®è¿æ¥æ± 
    if 'postgresql' in target_db_url.lower():
        target_app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 10,
            'max_overflow': 10,
        }
    elif 'mysql' in target_db_url.lower():
        target_app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 10,
            'max_overflow': 10,
        }
    
    db.init_app(target_app)
    
    # 7. åœ¨ç›®æ ‡æ•°æ®åº“ä¸­åˆ›å»ºè¡¨
    with target_app.app_context():
        create_tables_if_not_exist(target_engine)
    
    # 8. æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡")
    logger.info("="*70)
    
    with sqlite_app.app_context():
        sqlite_session = db.session
        questions_count = get_table_row_count(sqlite_engine, 'questions')
        answer_versions_count = get_table_row_count(sqlite_engine, 'answer_versions')
        
        logger.info(f"SQLite questions: {questions_count} æ¡")
        logger.info(f"SQLite answer_versions: {answer_versions_count} æ¡")
    
    with target_app.app_context():
        target_session = db.session
        target_questions_count = get_table_row_count(target_engine, 'questions')
        target_answer_versions_count = get_table_row_count(target_engine, 'answer_versions')
        
        logger.info(f"ç›®æ ‡æ•°æ®åº“ questions: {target_questions_count} æ¡")
        logger.info(f"ç›®æ ‡æ•°æ®åº“ answer_versions: {target_answer_versions_count} æ¡")
    
    # 9. ç¡®è®¤è¿ç§»
    logger.info("\n" + "="*70)
    if questions_count == 0 and answer_versions_count == 0:
        logger.info("â„¹ï¸ SQLite æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ— éœ€è¿ç§»")
        return
    
    logger.info("âš ï¸  å‡†å¤‡å¼€å§‹è¿ç§»ï¼Œè¿™å°†å¤åˆ¶ SQLite æ•°æ®åˆ°ç›®æ ‡æ•°æ®åº“")
    logger.info("   å·²å­˜åœ¨çš„è®°å½•å°†è¢«è·³è¿‡ï¼ˆåŸºäº IDï¼‰")
    
    confirm = input("\næ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ").strip().lower()
    if confirm not in ['yes', 'y', 'æ˜¯']:
        logger.info("âŒ ç”¨æˆ·å–æ¶ˆè¿ç§»")
        return
    
    # 10. å¼€å§‹è¿ç§»
    logger.info("\n" + "="*70)
    logger.info("ğŸš€ å¼€å§‹è¿ç§»æ•°æ®...")
    logger.info("="*70)
    
    start_time = datetime.now()
    
    with sqlite_app.app_context():
        sqlite_session = db.session
        with target_app.app_context():
            target_session = db.session
            
            # è¿ç§»é¢˜ç›®
            questions_migrated = migrate_questions(sqlite_session, target_session, Question)
            
            # è¿ç§»ç­”æ¡ˆç‰ˆæœ¬
            answer_versions_migrated = migrate_answer_versions(
                sqlite_session, target_session, AnswerVersion
            )
    
    end_time = datetime.now()
    elapsed = (end_time - start_time).total_seconds()
    
    # 11. æ˜¾ç¤ºè¿ç§»ç»“æœ
    logger.info("\n" + "="*70)
    logger.info("âœ… è¿ç§»å®Œæˆ!")
    logger.info("="*70)
    logger.info(f"ğŸ“¦ è¿ç§»é¢˜ç›®: {questions_migrated} æ¡")
    logger.info(f"ğŸ“¦ è¿ç§»ç­”æ¡ˆç‰ˆæœ¬: {answer_versions_migrated} æ¡")
    logger.info(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f} ç§’")
    
    # 12. éªŒè¯è¿ç§»ç»“æœ
    logger.info("\n" + "="*70)
    logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
    logger.info("="*70)
    
    with target_app.app_context():
        final_questions_count = get_table_row_count(target_engine, 'questions')
        final_answer_versions_count = get_table_row_count(target_engine, 'answer_versions')
        
        logger.info(f"ç›®æ ‡æ•°æ®åº“ questions: {final_questions_count} æ¡")
        logger.info(f"ç›®æ ‡æ•°æ®åº“ answer_versions: {final_answer_versions_count} æ¡")
    
    logger.info("\nâœ… è¿ç§»å®Œæˆï¼ç°åœ¨å¯ä»¥æ›´æ–° .env æ–‡ä»¶ä¸­çš„ DATABASE_URL å¹¶é‡å¯åº”ç”¨")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\n\nâŒ ç”¨æˆ·ä¸­æ–­è¿ç§»")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nâŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        sys.exit(1)
