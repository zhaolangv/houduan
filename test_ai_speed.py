"""
AIå¤„ç†é€Ÿåº¦æµ‹è¯•è„šæœ¬ - ä¸“é—¨æµ‹è¯•ä¼˜åŒ–åçš„OCRé€Ÿåº¦
é‡ç‚¹æµ‹è¯•ç«å±±å¼•æ“OCRï¼ˆå·²ç¦ç”¨æ€è€ƒæ¨¡å¼ï¼‰çš„å¤„ç†é€Ÿåº¦
"""
import requests
import json
import base64
import sys
import os
import time
from statistics import mean, median, stdev
from datetime import datetime

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# APIåŸºç¡€URL
BASE_URL = 'http://localhost:5000'

def load_test_images(count=5):
    """åŠ è½½æµ‹è¯•å›¾ç‰‡"""
    test_images = []
    ceshi_dir = 'uploads/ceshi'
    
    if not os.path.exists(ceshi_dir):
        print(f"âŒ æµ‹è¯•å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {ceshi_dir}")
        return []
    
    for file in os.listdir(ceshi_dir):
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            test_images.append(os.path.join(ceshi_dir, file))
            if len(test_images) >= count:
                break
    
    return test_images

def test_single_ocr_speed(image_path, rounds=5):
    """æµ‹è¯•å•å¼ å›¾ç‰‡OCRå¤„ç†é€Ÿåº¦ï¼ˆå¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼ï¼‰"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š å•å¼ å›¾ç‰‡OCRé€Ÿåº¦æµ‹è¯•")
    print(f"{'='*70}")
    print(f"å›¾ç‰‡: {os.path.basename(image_path)}")
    print(f"æµ‹è¯•è½®æ•°: {rounds}æ¬¡")
    print(f"å¼ºåˆ¶é‡æ–°åˆ†æ: æ˜¯ï¼ˆæµ‹è¯•å®Œæ•´OCRæµç¨‹ï¼‰")
    print(f"{'-'*70}")
    
    # è¯»å–å›¾ç‰‡å¹¶ç¼–ç ä¸ºbase64
    with open(image_path, 'rb') as f:
        image_data = f.read()
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        image_size_mb = len(image_data) / (1024 * 1024)
    
    print(f"å›¾ç‰‡å¤§å°: {image_size_mb:.2f} MB")
    print(f"Base64é•¿åº¦: {len(image_base64)} å­—ç¬¦\n")
    
    data = {
        'questions': [{
            'image': image_base64,
            'question_type': 'TEXT',
            'force_reanalyze': True  # å¼ºåˆ¶é‡æ–°åˆ†æï¼Œç¡®ä¿æ¯æ¬¡éƒ½è°ƒç”¨OCR
        }]
    }
    
    times = []
    success_count = 0
    
    for i in range(rounds):
        print(f"ç¬¬ {i+1}/{rounds} æ¬¡æµ‹è¯•...", end=' ', flush=True)
        start_time = time.time()
        
        try:
            response = requests.post(
                f'{BASE_URL}/api/questions/analyze/batch',
                json=data,
                headers={'Content-Type': 'application/json'},
                timeout=60
            )
            end_time = time.time()
            elapsed = end_time - start_time
            times.append(elapsed)
            
            if response.status_code == 200:
                result = response.json()
                success = result.get('success_count', 0) > 0
                if success:
                    success_count += 1
                    question = result.get('results', [{}])[0].get('question', {})
                    has_text = bool(question.get('question_text'))
                    print(f"âœ… {elapsed:.2f}ç§’ - æˆåŠŸ" + (" (æœ‰å†…å®¹)" if has_text else " (æ— å†…å®¹)"))
                else:
                    print(f"âŒ {elapsed:.2f}ç§’ - å¤„ç†å¤±è´¥")
            else:
                print(f"âŒ {elapsed:.2f}ç§’ - HTTP {response.status_code}")
        except requests.exceptions.Timeout:
            elapsed = time.time() - start_time
            times.append(elapsed)
            print(f"â±ï¸ {elapsed:.2f}ç§’ - è¶…æ—¶")
        except Exception as e:
            elapsed = time.time() - start_time
            times.append(elapsed)
            print(f"âŒ {elapsed:.2f}ç§’ - é”™è¯¯: {str(e)[:40]}")
    
    # ç»Ÿè®¡ç»“æœ
    if times:
        avg_time = mean(times)
        median_time = median(times)
        min_time = min(times)
        max_time = max(times)
        std_dev = stdev(times) if len(times) > 1 else 0
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
        print(f"{'='*70}")
        print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}ç§’")
        print(f"  ä¸­ä½æ•°:   {median_time:.2f}ç§’")
        print(f"  æœ€å¿«:     {min_time:.2f}ç§’")
        print(f"  æœ€æ…¢:     {max_time:.2f}ç§’")
        print(f"  æ ‡å‡†å·®:   {std_dev:.2f}ç§’")
        print(f"  æˆåŠŸç‡:   {success_count}/{rounds} ({success_count/rounds*100:.1f}%)")
        print(f"{'='*70}\n")
        
        return {
            'avg': avg_time,
            'median': median_time,
            'min': min_time,
            'max': max_time,
            'std': std_dev,
            'success_rate': success_count / rounds
        }
    return None

def test_batch_ocr_speed(image_paths, batch_sizes=[1, 3, 5]):
    """æµ‹è¯•æ‰¹é‡OCRå¤„ç†é€Ÿåº¦"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ‰¹é‡OCRå¤„ç†é€Ÿåº¦æµ‹è¯•")
    print(f"{'='*70}")
    print(f"æµ‹è¯•å›¾ç‰‡æ•°: {len(image_paths)}")
    print(f"æ‰¹é‡å¤§å°: {batch_sizes}")
    print(f"å¼ºåˆ¶é‡æ–°åˆ†æ: å¦ï¼ˆåˆ©ç”¨ç¼“å­˜ï¼‰")
    print(f"{'-'*70}\n")
    
    # å‡†å¤‡æ‰€æœ‰å›¾ç‰‡çš„base64æ•°æ®
    images_base64 = []
    total_size_mb = 0
    
    for img_path in image_paths:
        with open(img_path, 'rb') as f:
            image_data = f.read()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            images_base64.append(image_base64)
            total_size_mb += len(image_data) / (1024 * 1024)
    
    print(f"æ€»å›¾ç‰‡å¤§å°: {total_size_mb:.2f} MB\n")
    
    results = {}
    
    for batch_size in batch_sizes:
        if batch_size > len(images_base64):
            continue
        
        print(f"{'='*70}")
        print(f"ğŸ“¦ æ‰¹é‡å¤§å°: {batch_size}")
        print(f"{'='*70}")
        
        # å‡†å¤‡æ‰¹é‡æ•°æ®
        questions = [
            {
                'image': img_base64,
                'question_type': 'TEXT',
                'force_reanalyze': False  # ä¸å¼ºåˆ¶ï¼Œæµ‹è¯•ç¼“å­˜å’Œå¹¶è¡Œæ•ˆæœ
            }
            for img_base64 in images_base64[:batch_size]
        ]
        
        data = {'questions': questions}
        
        # æµ‹è¯•3æ¬¡å–å¹³å‡å€¼
        times = []
        success_counts = []
        
        for i in range(3):
            print(f"ç¬¬ {i+1}/3 æ¬¡æµ‹è¯•...", end=' ', flush=True)
            start_time = time.time()
            
            try:
                response = requests.post(
                    f'{BASE_URL}/api/questions/analyze/batch',
                    json=data,
                    headers={'Content-Type': 'application/json'},
                    timeout=120
                )
                end_time = time.time()
                elapsed = end_time - start_time
                times.append(elapsed)
                
                if response.status_code == 200:
                    result = response.json()
                    total = result.get('total', 0)
                    success = result.get('success_count', 0)
                    failed = result.get('failed_count', 0)
                    success_counts.append(success)
                    print(f"âœ… {elapsed:.2f}ç§’ - æˆåŠŸ: {success}/{total}, å¤±è´¥: {failed}")
                else:
                    print(f"âŒ {elapsed:.2f}ç§’ - HTTP {response.status_code}")
            except requests.exceptions.Timeout:
                elapsed = time.time() - start_time
                times.append(elapsed)
                print(f"â±ï¸ {elapsed:.2f}ç§’ - è¶…æ—¶")
            except Exception as e:
                elapsed = time.time() - start_time
                times.append(elapsed)
                print(f"âŒ {elapsed:.2f}ç§’ - é”™è¯¯: {str(e)[:40]}")
        
        if times:
            avg_time = mean(times)
            avg_success = mean(success_counts) if success_counts else 0
            avg_per_image = avg_time / batch_size
            
            results[batch_size] = {
                'total_time': avg_time,
                'per_image': avg_per_image,
                'success_rate': avg_success / batch_size if batch_size > 0 else 0
            }
            
            print(f"\nğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
            print(f"  å¹³å‡æ€»æ—¶é—´: {avg_time:.2f}ç§’")
            print(f"  å¹³å‡æ¯å¼ :   {avg_per_image:.2f}ç§’")
            print(f"  æˆåŠŸç‡:     {avg_success/batch_size*100:.1f}%")
            print()
    
    return results

def compare_sequential_vs_parallel(image_paths, count=5):
    """å¯¹æ¯”é¡ºåºå¤„ç† vs å¹¶è¡Œå¤„ç†çš„æ•ˆç‡"""
    if len(image_paths) < count:
        print(f"âš ï¸ å›¾ç‰‡æ•°é‡ä¸è¶³ï¼ˆéœ€è¦{count}å¼ ï¼Œå®é™…{len(image_paths)}å¼ ï¼‰ï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
        return
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š é¡ºåºå¤„ç† vs å¹¶è¡Œå¤„ç†æ•ˆç‡å¯¹æ¯”")
    print(f"{'='*70}")
    print(f"æµ‹è¯•å›¾ç‰‡æ•°: {count}")
    print(f"{'-'*70}\n")
    
    # å‡†å¤‡å›¾ç‰‡æ•°æ®
    images_base64 = []
    for img_path in image_paths[:count]:
        with open(img_path, 'rb') as f:
            image_data = f.read()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            images_base64.append(image_base64)
    
    # é¡ºåºå¤„ç†ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("ğŸ”„ é¡ºåºå¤„ç†æµ‹è¯•ï¼ˆé€ä¸ªå¤„ç†ï¼‰...")
    sequential_times = []
    
    for i, img_base64 in enumerate(images_base64):
        data = {
            'questions': [{
                'image': img_base64,
                'question_type': 'TEXT',
                'force_reanalyze': False
            }]
        }
        start_time = time.time()
        try:
            response = requests.post(
                f'{BASE_URL}/api/questions/analyze/batch',
                json=data,
                headers={'Content-Type': 'application/json'},
                timeout=60
            )
            elapsed = time.time() - start_time
            sequential_times.append(elapsed)
            status = "âœ…" if response.status_code == 200 else "âŒ"
            print(f"  å›¾ç‰‡{i+1}: {elapsed:.2f}ç§’ {status}")
        except Exception as e:
            elapsed = time.time() - start_time
            sequential_times.append(elapsed)
            print(f"  å›¾ç‰‡{i+1}: {elapsed:.2f}ç§’ âŒ")
    
    sequential_total = sum(sequential_times)
    sequential_avg = mean(sequential_times) if sequential_times else 0
    
    print(f"\nğŸ“ˆ é¡ºåºå¤„ç†ç»Ÿè®¡:")
    print(f"  æ€»æ—¶é—´: {sequential_total:.2f}ç§’")
    print(f"  å¹³å‡æ¯å¼ : {sequential_avg:.2f}ç§’")
    
    # å¹¶è¡Œå¤„ç†
    print(f"\nâš¡ å¹¶è¡Œå¤„ç†æµ‹è¯•ï¼ˆæ‰¹é‡å¤„ç†ï¼‰...")
    questions = [
        {
            'image': img_base64,
            'question_type': 'TEXT',
            'force_reanalyze': False
        }
        for img_base64 in images_base64
    ]
    data = {'questions': questions}
    
    parallel_times = []
    for i in range(3):
        print(f"  ç¬¬{i+1}/3æ¬¡...", end=' ', flush=True)
        start_time = time.time()
        try:
            response = requests.post(
                f'{BASE_URL}/api/questions/analyze/batch',
                json=data,
                headers={'Content-Type': 'application/json'},
                timeout=120
            )
            elapsed = time.time() - start_time
            parallel_times.append(elapsed)
            if response.status_code == 200:
                result = response.json()
                success = result.get('success_count', 0)
                print(f"âœ… {elapsed:.2f}ç§’ - æˆåŠŸ: {success}/{count}")
            else:
                print(f"âŒ {elapsed:.2f}ç§’ - HTTP {response.status_code}")
        except Exception as e:
            elapsed = time.time() - start_time
            parallel_times.append(elapsed)
            print(f"âŒ {elapsed:.2f}ç§’ - é”™è¯¯")
    
    if parallel_times:
        parallel_avg = mean(parallel_times)
        parallel_per_image = parallel_avg / count
        speedup = sequential_total / parallel_avg if parallel_avg > 0 else 0
        efficiency = (speedup / count * 100) if speedup > 0 else 0
        
        print(f"\nğŸ“ˆ å¹¶è¡Œå¤„ç†ç»Ÿè®¡:")
        print(f"  å¹³å‡æ€»æ—¶é—´: {parallel_avg:.2f}ç§’")
        print(f"  å¹³å‡æ¯å¼ :   {parallel_per_image:.2f}ç§’")
        
        print(f"\nğŸ“Š æ•ˆç‡å¯¹æ¯”:")
        print(f"  é¡ºåºæ€»æ—¶é—´: {sequential_total:.2f}ç§’")
        print(f"  å¹¶è¡Œæ€»æ—¶é—´: {parallel_avg:.2f}ç§’")
        print(f"  åŠ é€Ÿæ¯”:     {speedup:.2f}x")
        print(f"  å¹¶è¡Œæ•ˆç‡:   {efficiency:.1f}%")
        print(f"  æ—¶é—´èŠ‚çœ:   {sequential_total - parallel_avg:.2f}ç§’ ({((sequential_total - parallel_avg) / sequential_total * 100):.1f}%)")

def generate_summary_report(single_result, batch_results):
    """ç”Ÿæˆæµ‹è¯•æ€»ç»“æŠ¥å‘Š"""
    print(f"\n{'='*70}")
    print(f"ğŸ“‹ æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print(f"{'='*70}")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"APIåœ°å€: {BASE_URL}")
    
    if single_result:
        print(f"\nğŸ“Š å•å¼ å›¾ç‰‡OCRæ€§èƒ½:")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {single_result['avg']:.2f}ç§’")
        print(f"  æœ€å¿«å¤„ç†æ—¶é—´: {single_result['min']:.2f}ç§’")
        print(f"  æˆåŠŸç‡: {single_result['success_rate']*100:.1f}%")
    
    if batch_results:
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†æ€§èƒ½:")
        print(f"{'æ‰¹é‡å¤§å°':<10} {'æ€»æ—¶é—´(ç§’)':<15} {'æ¯å¼ (ç§’)':<15} {'æˆåŠŸç‡':<10}")
        print(f"{'-'*60}")
        for batch_size in sorted(batch_results.keys()):
            data = batch_results[batch_size]
            print(f"{batch_size:<10} {data['total_time']:<15.2f} {data['per_image']:<15.2f} {data['success_rate']*100:<10.1f}%")
    
    print(f"\n{'='*70}")
    print(f"âœ… æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*70}\n")

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("ğŸš€ AIå¤„ç†é€Ÿåº¦æµ‹è¯• - ç«å±±å¼•æ“OCRä¼˜åŒ–ç‰ˆ")
    print("="*70)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"APIåœ°å€: {BASE_URL}")
    print()
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    try:
        response = requests.get(f'{BASE_URL}/api/test', timeout=5)
        if response.status_code == 200:
            print("âœ… æœåŠ¡è¿è¡Œæ­£å¸¸\n")
        else:
            print("âš ï¸ æœåŠ¡å“åº”å¼‚å¸¸\n")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        print("è¯·ç¡®ä¿FlaskæœåŠ¡æ­£åœ¨è¿è¡Œ: python app.py")
        return
    
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    print("ğŸ“· åŠ è½½æµ‹è¯•å›¾ç‰‡...")
    test_images = load_test_images(10)
    if not test_images:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡\n")
    
    # è¿è¡Œæµ‹è¯•
    single_result = None
    batch_results = {}
    
    # æµ‹è¯•1ï¼šå•å¼ å›¾ç‰‡OCRé€Ÿåº¦
    if test_images:
        single_result = test_single_ocr_speed(test_images[0], rounds=5)
    
    # æµ‹è¯•2ï¼šæ‰¹é‡å¤„ç†é€Ÿåº¦
    if len(test_images) >= 5:
        batch_results = test_batch_ocr_speed(test_images, batch_sizes=[1, 3, 5])
    
    # æµ‹è¯•3ï¼šé¡ºåº vs å¹¶è¡Œå¯¹æ¯”
    if len(test_images) >= 5:
        compare_sequential_vs_parallel(test_images, count=5)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(single_result, batch_results)

if __name__ == '__main__':
    main()

