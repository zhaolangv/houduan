"""
é¢˜ç›®æœåŠ¡ V2ï¼šåªæ¥æ”¶å›¾ç‰‡ï¼ŒAIè‡ªåŠ¨æå–æ‰€æœ‰ä¿¡æ¯
"""
import os
import hashlib
import json
import logging
import base64
from datetime import datetime, date
from models_v2 import db, Question, AnswerVersion
import re
from ai_service import AIService
import uuid
from supabase_storage_service import get_supabase_storage_service
from difflib import SequenceMatcher
import imagehash
from PIL import Image
import io

logger = logging.getLogger(__name__)


class QuestionService:
    """é¢˜ç›®æœåŠ¡ç±»"""
    
    def __init__(self):
        self.ai_service = AIService()
        # ç®€å•çš„å†…å­˜ç¼“å­˜ï¼ˆLRUï¼Œæœ€å¤š100æ¡ï¼‰
        self._cache = {}
        self._cache_max_size = 100
    
    def calculate_question_hash(self, question_text, options):
        """
        è®¡ç®—é¢˜ç›®å“ˆå¸Œå€¼ï¼ˆç”¨äºå»é‡ï¼‰
        
        Args:
            question_text: é¢˜å¹²
            options: é€‰é¡¹åˆ—è¡¨
            
        Returns:
            str: å“ˆå¸Œå€¼
        """
        # æ ‡å‡†åŒ–é¢˜ç›®æ–‡æœ¬ï¼ˆå»é™¤ç©ºæ ¼ã€æ¢è¡Œç­‰ï¼‰
        normalized_text = question_text.strip().replace('\n', '').replace('\r', '').replace(' ', '')
        
        # æ ‡å‡†åŒ–é€‰é¡¹
        normalized_options = []
        if isinstance(options, list):
            for opt in options:
                if isinstance(opt, str):
                    normalized_options.append(opt.strip())
        elif isinstance(options, str):
            # å¦‚æœæ˜¯JSONå­—ç¬¦ä¸²ï¼Œè§£æ
            try:
                options_list = json.loads(options)
                normalized_options = [str(opt).strip() for opt in options_list]
            except:
                normalized_options = [options.strip()]
        
        # ç»„åˆæ–‡æœ¬
        combined = normalized_text + '|' + '|'.join(sorted(normalized_options))
        
        # è®¡ç®—MD5å“ˆå¸Œ
        return hashlib.md5(combined.encode('utf-8')).hexdigest()
    
    def find_duplicate_question(self, question_hash):
        """
        æŸ¥æ‰¾é‡å¤é¢˜ç›®ï¼ˆåŸºäºå®Œæ•´é¢˜å¹²å“ˆå¸Œï¼‰
        
        Args:
            question_hash: é¢˜ç›®å“ˆå¸Œå€¼
            
        Returns:
            Questionå¯¹è±¡æˆ–None
        """
        return Question.query.filter_by(question_hash=question_hash).first()
    
    def find_duplicate_by_text_similarity(self, partial_text, threshold=0.85):
        """
        åŸºäºæ–‡å­—ç›¸ä¼¼åº¦æŸ¥æ‰¾é‡å¤é¢˜ç›®ï¼ˆç”¨äºå‰ç«¯OCRä¸å®Œæ•´çš„æƒ…å†µï¼‰
        
        Args:
            partial_text: éƒ¨åˆ†æ–‡å­—ï¼ˆå‰ç«¯OCRç»“æœï¼‰
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤0.85
            
        Returns:
            tuple: (Questionå¯¹è±¡, ç›¸ä¼¼åº¦åˆ†æ•°) æˆ– (None, 0.0)
        """
        if not partial_text or len(partial_text.strip()) < 10:
            return None, 0.0
        
        # æ ‡å‡†åŒ–è¾“å…¥æ–‡æœ¬
        normalized_input = self._normalize_text(partial_text)
        
        # è·å–æ‰€æœ‰é¢˜ç›®çš„raw_textï¼ˆä¼˜åŒ–ï¼šé™åˆ¶æŸ¥è¯¢æ•°é‡ï¼Œé¿å…æŸ¥è¯¢è¿‡å¤šæ•°æ®ï¼‰
        # åªæŸ¥è¯¢æœ€è¿‘1000æ¡ï¼Œæé«˜æŸ¥è¯¢é€Ÿåº¦
        questions = Question.query.filter(
            Question.raw_text.isnot(None),
            Question.raw_text != ''
        ).order_by(Question.created_at.desc()).limit(1000).all()
        
        best_match = None
        best_similarity = 0.0
        
        for question in questions:
            if not question.raw_text:
                continue
            
            # æ ‡å‡†åŒ–é¢˜ç›®æ–‡æœ¬
            normalized_question = self._normalize_text(question.raw_text)
            
            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨SequenceMatcherï¼‰
            similarity = SequenceMatcher(None, normalized_input, normalized_question).ratio()
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = question
            
            # å¦‚æœæ‰¾åˆ°é«˜ç›¸ä¼¼åº¦åŒ¹é…ï¼Œæå‰è¿”å›
            if similarity >= threshold:
                logger.info(f"[QuestionService] æ–‡å­—ç›¸ä¼¼åº¦åŒ¹é…: {similarity:.3f} >= {threshold}")
                return question, similarity
        
        if best_similarity >= threshold:
            logger.info(f"[QuestionService] æ–‡å­—ç›¸ä¼¼åº¦åŒ¹é…: {best_similarity:.3f} >= {threshold}")
            return best_match, best_similarity
        
        return None, 0.0
    
    def find_duplicate_by_image_hash(self, image_file):
        """
        åŸºäºå›¾ç‰‡å“ˆå¸ŒæŸ¥æ‰¾é‡å¤é¢˜ç›®
        
        æ³¨æ„ï¼šå½“å‰å®ç°ç®€åŒ–ï¼Œä¸»è¦ä¾èµ–æ–‡å­—ç›¸ä¼¼åº¦å’Œå®Œæ•´é¢˜å¹²å“ˆå¸Œ
        å›¾ç‰‡å“ˆå¸Œæ£€æŸ¥å¯ä»¥åç»­æ‰©å±•ï¼ˆéœ€è¦æ·»åŠ image_hashå­—æ®µåˆ°æ•°æ®åº“ï¼‰
        
        Args:
            image_file: å›¾ç‰‡æ–‡ä»¶å¯¹è±¡
            
        Returns:
            Questionå¯¹è±¡æˆ–None
        """
        # TODO: å®ç°å›¾ç‰‡å“ˆå¸Œæ£€æŸ¥
        # éœ€è¦ï¼š
        # 1. åœ¨Questionæ¨¡å‹ä¸­æ·»åŠ image_hashå­—æ®µï¼ˆMD5ï¼‰
        # 2. åœ¨Questionæ¨¡å‹ä¸­æ·»åŠ image_phashå­—æ®µï¼ˆæ„ŸçŸ¥å“ˆå¸Œï¼‰
        # 3. ä¿å­˜é¢˜ç›®æ—¶è®¡ç®—å¹¶å­˜å‚¨è¿™äº›å“ˆå¸Œå€¼
        # 4. åœ¨è¿™é‡ŒæŸ¥è¯¢åŒ¹é…çš„é¢˜ç›®
        
        # å½“å‰ç®€åŒ–å®ç°ï¼šè¿”å›Noneï¼Œä¾èµ–å…¶ä»–æ£€æŸ¥æ–¹æ³•
        return None
    
    def _normalize_text(self, text):
        """
        æ ‡å‡†åŒ–æ–‡æœ¬ï¼ˆç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            str: æ ‡å‡†åŒ–åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # å»é™¤ç©ºæ ¼ã€æ¢è¡Œã€æ ‡ç‚¹ç¬¦å·
        normalized = text.strip().replace('\n', '').replace('\r', '').replace(' ', '')
        # åªä¿ç•™ä¸­æ–‡å­—ç¬¦ã€æ•°å­—ã€å­—æ¯
        normalized = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', '', normalized)
        return normalized.lower()
    
    def save_image(self, image_file, upload_folder='uploads'):
        """
        ä¿å­˜å›¾ç‰‡æ–‡ä»¶
        ä¼˜å…ˆä½¿ç”¨Supabase Storageï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä¿å­˜åˆ°æœ¬åœ°
        
        Args:
            image_file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
            upload_folder: æœ¬åœ°ä¸Šä¼ ç›®å½•ï¼ˆSupabaseä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
            
        Returns:
            str: å›¾ç‰‡è·¯å¾„æˆ–URL
                - å¦‚æœä½¿ç”¨Supabase: è¿”å›å…¬å¼€URL
                - å¦‚æœä½¿ç”¨æœ¬åœ°: è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚ /uploads/2025/12/04/q1234.pngï¼‰
        """
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨Supabase Storage
        from supabase_storage_service import get_supabase_storage_service
        storage_service = get_supabase_storage_service()
        
        if storage_service.is_available():
            logger.info("[QuestionService] ä½¿ç”¨Supabase Storageä¸Šä¼ å›¾ç‰‡...")
            success, file_path, public_url = storage_service.upload_image(image_file)
            
            if success and public_url:
                logger.info(f"[QuestionService] âœ… å›¾ç‰‡å·²ä¸Šä¼ åˆ°Supabase: {public_url}")
                return public_url
            else:
                logger.warning("[QuestionService] Supabaseä¸Šä¼ å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°å­˜å‚¨")
        
        # é™çº§åˆ°æœ¬åœ°å­˜å‚¨
        logger.info("[QuestionService] ä½¿ç”¨æœ¬åœ°å­˜å‚¨ä¿å­˜å›¾ç‰‡...")
        # åˆ›å»ºæ—¥æœŸç›®å½•
        today = datetime.now()
        date_folder = os.path.join(upload_folder, str(today.year), f"{today.month:02d}", f"{today.day:02d}")
        os.makedirs(date_folder, exist_ok=True)
        
        # è·å–æ–‡ä»¶åå’Œæ‰©å±•åï¼ˆå…¼å®¹BytesIOå¯¹è±¡ï¼‰
        image_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        image_data = image_file.read()
        image_file.seek(0)  # å†æ¬¡é‡ç½®ï¼Œä¾›åç»­ä½¿ç”¨
        
        # å°è¯•ä»filenameæˆ–nameå±æ€§è·å–æ‰©å±•å
        filename_for_ext = None
        if hasattr(image_file, 'filename') and image_file.filename:
            filename_for_ext = image_file.filename
        elif hasattr(image_file, 'name') and image_file.name:
            filename_for_ext = image_file.name
        
        # ä»æ–‡ä»¶åæˆ–æ–‡ä»¶å†…å®¹æ£€æµ‹æ‰©å±•å
        if filename_for_ext:
            ext = os.path.splitext(filename_for_ext)[1]
        else:
            ext = None
        
        # å¦‚æœæ— æ³•ä»æ–‡ä»¶åè·å–ï¼Œä»æ–‡ä»¶å†…å®¹æ£€æµ‹
        if not ext:
            if image_data[:2] == b'\xff\xd8':
                ext = '.jpg'
            elif image_data[:8] == b'\x89PNG\r\n\x1a\n':
                ext = '.png'
            elif image_data[:6] in (b'GIF87a', b'GIF89a'):
                ext = '.gif'
            elif image_data[:2] == b'BM':
                ext = '.bmp'
            else:
                ext = '.png'  # é»˜è®¤ä½¿ç”¨PNG
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename = f"q{uuid.uuid4().hex[:8]}{ext}"
        filepath = os.path.join(date_folder, filename)
        
        # ä¿å­˜æ–‡ä»¶ï¼ˆå…¼å®¹BytesIOå’ŒFileStorageå¯¹è±¡ï¼‰
        image_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        if hasattr(image_file, 'save'):
            # Flask FileStorageå¯¹è±¡ï¼Œä½¿ç”¨saveæ–¹æ³•
            image_file.save(filepath)
        else:
            # BytesIOå¯¹è±¡æˆ–å…¶ä»–ï¼Œä½¿ç”¨æ–‡ä»¶å†™å…¥
            with open(filepath, 'wb') as f:
                f.write(image_data)
        
        # è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆç”¨äºURLï¼‰
        return f"/{filepath.replace(os.sep, '/')}"
    
    def image_to_base64(self, image_file, return_format='data_uri'):
        """
        å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç 
        
        Args:
            image_file: æ–‡ä»¶å¯¹è±¡
            return_format: è¿”å›æ ¼å¼
                - 'data_uri': è¿”å›å®Œæ•´çš„æ•°æ®URI (data:image/jpeg;base64,xxx)
                - 'base64_only': åªè¿”å›base64å­—ç¬¦ä¸²ï¼ˆä¸å«å‰ç¼€ï¼‰
            
        Returns:
            str: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        image_file.seek(0)  # ç¡®ä¿ä»æ–‡ä»¶å¼€å¤´è¯»å–
        image_data = image_file.read()
        base64_data = base64.b64encode(image_data).decode('utf-8')
        
        if return_format == 'base64_only':
            return base64_data
        
        # æ£€æµ‹å›¾ç‰‡æ ¼å¼
        if image_data[:2] == b'\xff\xd8':
            mime_type = 'image/jpeg'
        elif image_data[:8] == b'\x89PNG\r\n\x1a\n':
            mime_type = 'image/png'
        else:
            mime_type = 'image/jpeg'  # é»˜è®¤
        
        return f"data:{mime_type};base64,{base64_data}"
    
    def _get_cache_key(self, question_hash=None, raw_text=None, question_text=None):
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            question_hash: é¢˜ç›®å“ˆå¸Œå€¼
            raw_text: åŸå§‹æ–‡æœ¬
            question_text: é¢˜å¹²æ–‡æœ¬
            
        Returns:
            str: ç¼“å­˜é”®
        """
        if question_hash:
            return f"hash:{question_hash}"
        elif question_text:
            normalized = self._normalize_text(question_text)
            return f"text:{hashlib.md5(normalized.encode('utf-8')).hexdigest()}"
        elif raw_text:
            normalized = self._normalize_text(raw_text)
            return f"raw:{hashlib.md5(normalized.encode('utf-8')).hexdigest()}"
        return None
    
    def _get_from_cache(self, cache_key):
        """
        ä»ç¼“å­˜è·å–æ•°æ®
        
        Args:
            cache_key: ç¼“å­˜é”®
            
        Returns:
            dictæˆ–None
        """
        if cache_key and cache_key in self._cache:
            logger.info(f"[QuestionService] ğŸ’¾ ä»ç¼“å­˜è·å–: {cache_key}")
            return self._cache[cache_key]
        return None
    
    def _set_to_cache(self, cache_key, data):
        """
        å­˜å…¥ç¼“å­˜
        
        Args:
            cache_key: ç¼“å­˜é”®
            data: æ•°æ®
        """
        if not cache_key:
            return
        
        # LRUç­–ç•¥ï¼šå¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„
        if len(self._cache) >= self._cache_max_size:
            # åˆ é™¤ç¬¬ä¸€ä¸ªï¼ˆæœ€æ—§çš„ï¼‰
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
            logger.debug(f"[QuestionService] ğŸ—‘ï¸ ç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§é¡¹: {oldest_key}")
        
        self._cache[cache_key] = data
        logger.info(f"[QuestionService] ğŸ’¾ å­˜å…¥ç¼“å­˜: {cache_key}")
    
    def analyze_question_from_image(self, image_file, frontend_raw_text=None,
                                     frontend_question_text=None, frontend_options=None,
                                     question_type='TEXT', force_reanalyze=False):
        """
        ä»å›¾ç‰‡åˆ†æé¢˜ç›®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        æµç¨‹ï¼š
        1. åˆ©ç”¨å‰ç«¯æä¾›çš„æ•°æ®è®¡ç®—å“ˆå¸Œï¼Œæ£€æŸ¥ç¼“å­˜å’Œæ•°æ®åº“
        2. å¦‚æœæ‰¾åˆ°é‡å¤é¢˜ä¸”ä¸å¼ºåˆ¶é‡æ–°åˆ†æï¼Œè¿”å›ç¼“å­˜ï¼ˆä¸è°ƒç”¨AIï¼‰
        3. å¦åˆ™è°ƒç”¨AIåˆ†æï¼Œå­˜å…¥æ•°æ®åº“å’Œç¼“å­˜
        
        Args:
            image_file: å›¾ç‰‡æ–‡ä»¶
            frontend_raw_text: å‰ç«¯OCRåŸå§‹æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            frontend_question_text: å‰ç«¯æå–çš„é¢˜å¹²ï¼ˆå¯é€‰ï¼Œå¯èƒ½ä¸å‡†ç¡®ï¼‰
            frontend_options: å‰ç«¯æå–çš„é€‰é¡¹ï¼ˆå¯é€‰ï¼Œåˆ—è¡¨ï¼‰
            question_type: é¢˜ç›®ç±»å‹ï¼ˆé»˜è®¤"TEXT"ï¼‰
            force_reanalyze: æ˜¯å¦å¼ºåˆ¶é‡æ–°AIåˆ†æï¼ˆé»˜è®¤Falseï¼‰
            
        Returns:
            dict: å®Œæ•´çš„é¢˜ç›®æ•°æ®ï¼ŒåŒ…å«ï¼š
            - from_cache: æ˜¯å¦æ¥è‡ªç¼“å­˜
            - is_duplicate: æ˜¯å¦æ˜¯é‡å¤é¢˜
            - saved_to_db: æ˜¯å¦å­˜å…¥æ•°æ®åº“
            - similarity_score: ç›¸ä¼¼åº¦åˆ†æ•°
        """
        logger.info("")
        logger.info("[QuestionService] ========== å¼€å§‹ä»å›¾ç‰‡åˆ†æé¢˜ç›® ==========")
        
        if frontend_raw_text:
            logger.info(f"[QuestionService] ğŸ“ æ”¶åˆ°å‰ç«¯OCRåŸå§‹æ–‡æœ¬: {frontend_raw_text[:100]}...")
        if frontend_question_text:
            logger.info(f"[QuestionService] ğŸ“ æ”¶åˆ°å‰ç«¯æå–é¢˜å¹²: {frontend_question_text[:100]}...")
        if frontend_options:
            logger.info(f"[QuestionService] ğŸ“ æ”¶åˆ°å‰ç«¯æå–é€‰é¡¹: {len(frontend_options)}ä¸ª")
        
        if force_reanalyze:
            logger.info("[QuestionService] ğŸ”„ å¼ºåˆ¶é‡æ–°AIåˆ†æï¼ˆç”¨æˆ·è¦æ±‚ï¼‰")
        
        # ========== ç¬¬ä¸€æ­¥ï¼šåˆ©ç”¨å‰ç«¯æ•°æ®å¿«é€Ÿå»é‡æ£€æŸ¥ ==========
        existing_question = None
        similarity_score = 0.0
        cache_key = None
        
        # 1.1 å¦‚æœå‰ç«¯æä¾›äº†é¢˜å¹²å’Œé€‰é¡¹ï¼Œè®¡ç®—å“ˆå¸Œå¹¶æ£€æŸ¥ç¼“å­˜/æ•°æ®åº“
        if frontend_question_text and frontend_options and not force_reanalyze:
            logger.info("[QuestionService] ğŸ” ç¬¬ä¸€æ­¥ï¼šåˆ©ç”¨å‰ç«¯æ•°æ®æ£€æŸ¥...")
            
            # è®¡ç®—é¢˜ç›®å“ˆå¸Œ
            question_hash = self.calculate_question_hash(frontend_question_text, frontend_options)
            logger.info(f"[QuestionService]    - é¢˜ç›®å“ˆå¸Œå€¼: {question_hash}")
            
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = self._get_cache_key(question_hash=question_hash)
            
            # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
            cached_data = self._get_from_cache(cache_key)
            if cached_data:
                logger.info(f"[QuestionService] âœ… ä»ç¼“å­˜è·å–æ•°æ®")
                cached_data['from_cache'] = True
                cached_data['saved_to_db'] = False
                return cached_data
            
            # æ£€æŸ¥æ•°æ®åº“ï¼ˆå®Œæ•´é¢˜å¹²å“ˆå¸ŒåŒ¹é…ï¼‰
            existing_question = self.find_duplicate_question(question_hash)
            if existing_question:
                logger.info(f"[QuestionService] âœ… æ•°æ®åº“ä¸­æ‰¾åˆ°é‡å¤é¢˜ç›®ï¼ˆå®Œæ•´é¢˜å¹²åŒ¹é…ï¼‰")
                logger.info(f"[QuestionService]    - é¢˜ç›®ID: {existing_question.id}")
                similarity_score = 1.0  # å®Œå…¨åŒ¹é…
        
        # 1.2 å¦‚æœå‰ç«¯åªæä¾›äº†åŸå§‹æ–‡æœ¬ï¼Œä½¿ç”¨æ–‡å­—ç›¸ä¼¼åº¦æ£€æŸ¥
        elif frontend_raw_text and not force_reanalyze:
            logger.info("[QuestionService] ğŸ” ç¬¬ä¸€æ­¥ï¼šæ–‡å­—ç›¸ä¼¼åº¦æ£€æŸ¥...")
            existing_question, similarity_score = self.find_duplicate_by_text_similarity(
                frontend_raw_text,
                threshold=0.85
            )
            if existing_question:
                logger.info(f"[QuestionService] âœ… æ–‡å­—ç›¸ä¼¼åº¦åŒ¹é…æˆåŠŸ: {similarity_score:.3f}")
                logger.info(f"[QuestionService]    - é¢˜ç›®ID: {existing_question.id}")
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = self._get_cache_key(raw_text=frontend_raw_text)
        
        # ========== ç¬¬äºŒæ­¥ï¼šå¦‚æœæ‰¾åˆ°é‡å¤é¢˜ä¸”ä¸å¼ºåˆ¶é‡æ–°åˆ†æï¼Œè¿”å›ç¼“å­˜ ==========
        if existing_question and not force_reanalyze:
            logger.info(f"[QuestionService] âœ… æ‰¾åˆ°é‡å¤é¢˜ç›®ï¼Œè¿”å›ç¼“å­˜ç»“æœï¼ˆä¸è°ƒç”¨OCRï¼‰")
            response = self._format_question_content_response(existing_question)
            response['from_cache'] = True
            response['is_duplicate'] = True
            response['saved_to_db'] = False  # æ¥è‡ªæ•°æ®åº“ï¼Œä¸æ˜¯æ–°å­˜å…¥
            response['similarity_score'] = similarity_score if similarity_score > 0 else 1.0
            response['matched_question_id'] = str(existing_question.id)  # åŒ¹é…çš„é¢˜ç›®ID
            
            # å­˜å…¥å†…å­˜ç¼“å­˜ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if cache_key:
                self._set_to_cache(cache_key, response)
            
            return response
        
        # ========== ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨AIåˆ†æï¼ˆæ–°é¢˜æˆ–å¼ºåˆ¶é‡æ–°åˆ†æï¼‰==========
        logger.info("[QuestionService] ğŸ¤– è°ƒç”¨AIåˆ†æå›¾ç‰‡ï¼ˆæå–é¢˜å¹²ã€é€‰é¡¹ã€è§£æç­‰ï¼‰...")
        
        # 3.1 ä¿å­˜å›¾ç‰‡
        logger.info("[QuestionService] ğŸ’¾ ä¿å­˜å›¾ç‰‡...")
        image_file.seek(0)
        screenshot_path = self.save_image(image_file)
        logger.info(f"[QuestionService]    - å›¾ç‰‡è·¯å¾„: {screenshot_path}")
        
        # 3.2 æå–é¢˜ç›®å†…å®¹ï¼ˆæ”¯æŒå¤šç§æ–¹æ¡ˆï¼‰
        image_file.seek(0)
        # æ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹©æ–¹æ¡ˆï¼ˆç”¨äºæµ‹è¯•å¯¹æ¯”ï¼‰
        ocr_method = os.getenv('OCR_METHOD', 'auto')  # auto, vision, ocr_ai, ocr_rule
        
        if ocr_method == 'vision':
            # å¼ºåˆ¶ä½¿ç”¨Visionæ¨¡å‹
            ocr_result = self._extract_question_content_with_volcengine(image_file, screenshot_path, force_vision=True)
        elif ocr_method == 'ocr_ai':
            # å¼ºåˆ¶ä½¿ç”¨OCR API + æ–‡æœ¬AI
            ocr_result = self._extract_question_content_with_volcengine(image_file, screenshot_path, force_ocr_ai=True)
        elif ocr_method == 'ocr_rule':
            # å¼ºåˆ¶ä½¿ç”¨OCR API + è§„åˆ™è¿‡æ»¤
            ocr_result = self._extract_question_content_fast(image_file, screenshot_path)
        else:
            # è‡ªåŠ¨é€‰æ‹©ï¼ˆå½“å‰é»˜è®¤ï¼šVisionæ¨¡å‹ï¼‰
            ocr_result = self._extract_question_content_with_volcengine(image_file, screenshot_path)
        
        # 3.4 ä»OCRç»“æœä¸­æå–ä¿¡æ¯ï¼ˆOCRçš„ç»“æœä¼˜å…ˆäºå‰ç«¯æ•°æ®ï¼‰
        question_text = ocr_result.get('question_text', '') or frontend_question_text or ''
        options_list = ocr_result.get('options', []) or frontend_options or []
        ai_question_type = ocr_result.get('question_type', question_type)
        raw_text = ocr_result.get('raw_text', '') or frontend_raw_text or ''
        ocr_confidence = ocr_result.get('ocr_confidence', 0.95)
        extraction_method = ocr_result.get('extraction_method', 'volcengine_vision')  # æå–æ–¹æ³•
        
        logger.info(f"[QuestionService]    - AIæå–çš„é¢˜å¹²: {question_text[:100]}...")
        logger.info(f"[QuestionService]    - AIæå–çš„é€‰é¡¹æ•°: {len(options_list)}")
        logger.info(f"[QuestionService]    - AIåˆ¤æ–­çš„é¢˜ç›®ç±»å‹: {ai_question_type}")
        
        # 3.5 è®¡ç®—é¢˜ç›®å“ˆå¸Œå€¼ï¼ˆç”¨äºå»é‡ï¼‰
        question_hash = self.calculate_question_hash(question_text, options_list)
        logger.info(f"[QuestionService] ğŸ”‘ é¢˜ç›®å“ˆå¸Œå€¼: {question_hash}")
        
        # 3.6 å†æ¬¡æ£€æŸ¥æ•°æ®åº“ï¼ˆAIæå–åå¯èƒ½æ›´å‡†ç¡®ï¼‰
        if not force_reanalyze:
            logger.info("[QuestionService] ğŸ” å†æ¬¡æ£€æŸ¥æ•°æ®åº“ï¼ˆAIæå–åï¼‰...")
            existing_question = self.find_duplicate_question(question_hash)
            if existing_question:
                # æ£€æŸ¥å·²æœ‰é¢˜ç›®æ˜¯å¦æœ‰æœ‰æ•ˆçš„è§£æï¼ˆä¸æ˜¯å¤±è´¥è®°å½•ï¼‰
                has_valid_answer = (
                    existing_question.correct_answer and 
                    existing_question.explanation and 
                    not existing_question.explanation.startswith('AIè§£æå¤±è´¥')
                )
                
                logger.info(f"[QuestionService] âœ… æ‰¾åˆ°é‡å¤é¢˜ç›®ï¼ˆOCRæå–ååŒ¹é…ï¼‰ï¼Œè¿”å›æ•°æ®åº“ç»“æœ")
                logger.info(f"[QuestionService]    - é¢˜ç›®ID: {existing_question.id}")
                response = self._format_question_content_response(existing_question)
                response['from_cache'] = False  # æ¥è‡ªæ•°æ®åº“ï¼Œä¸æ˜¯ç¼“å­˜
                response['is_duplicate'] = True
                response['saved_to_db'] = False  # ä¸æ˜¯æ–°å­˜å…¥
                response['similarity_score'] = 1.0  # å®Œå…¨åŒ¹é…
                response['matched_question_id'] = str(existing_question.id)  # åŒ¹é…çš„é¢˜ç›®ID
                
                # å­˜å…¥å†…å­˜ç¼“å­˜
                cache_key = self._get_cache_key(question_hash=question_hash)
                if cache_key:
                    self._set_to_cache(cache_key, response)
                
                return response
        
        # 3.7 å¦‚æœforce_reanalyze=trueä¸”ä¹‹å‰æ‰¾åˆ°äº†é‡å¤é¢˜ï¼Œæ›´æ–°å·²æœ‰é¢˜ç›®ï¼ˆåªæ›´æ–°é¢˜ç›®å†…å®¹ï¼‰
        if force_reanalyze and existing_question:
            logger.info(f"[QuestionService] ğŸ”„ å¼ºåˆ¶é‡æ–°åˆ†æï¼Œæ›´æ–°å·²æœ‰é¢˜ç›®å†…å®¹: {existing_question.id}")
            
            # åªæ›´æ–°é¢˜ç›®å†…å®¹ï¼Œä¸æ›´æ–°ç­”æ¡ˆå’Œè§£æï¼ˆç­”æ¡ˆå’Œè§£æç”±detailæ¥å£æä¾›ï¼‰
            existing_question.screenshot = screenshot_path
            existing_question.raw_text = raw_text
            existing_question.question_text = question_text
            existing_question.question_type = ai_question_type
            existing_question.options = options_list
            existing_question.question_hash = question_hash
            existing_question.ocr_confidence = ocr_confidence
            existing_question.updated_at = datetime.utcnow()
            
            db.session.commit()
            logger.info(f"[QuestionService] âœ… é¢˜ç›®å†…å®¹å·²æ›´æ–°åˆ°æ•°æ®åº“")
            logger.info(f"[QuestionService]    - é¢˜ç›®ID: {existing_question.id}")
            
            # æ ¼å¼åŒ–å“åº”ï¼ˆåªè¿”å›é¢˜ç›®å†…å®¹ï¼‰
            response = self._format_question_content_response(existing_question)
            response['from_cache'] = False
            response['is_duplicate'] = True
            response['saved_to_db'] = True  # æ›´æ–°äº†æ•°æ®åº“
            response['similarity_score'] = similarity_score if similarity_score > 0 else 1.0
            response['matched_question_id'] = str(existing_question.id)
            
            # æ›´æ–°ç¼“å­˜
            cache_key = self._get_cache_key(question_hash=question_hash)
            if cache_key:
                self._set_to_cache(cache_key, response)
            
            return response
        
        # ========== ç¬¬å››æ­¥ï¼šæ–°é¢˜ç›®ï¼Œå­˜å…¥æ•°æ®åº“ ==========
        logger.info("[QuestionService] âœ¨ æ–°é¢˜ç›®ï¼Œä¿å­˜åˆ°æ•°æ®åº“")
        
        # 4.1 åˆ›å»ºé¢˜ç›®è®°å½•ï¼ˆåªä¿å­˜é¢˜ç›®å†…å®¹ï¼Œä¸ä¿å­˜ç­”æ¡ˆå’Œè§£æï¼‰
        question = Question(
            screenshot=screenshot_path,
            raw_text=raw_text,
            question_text=question_text,
            question_type=ai_question_type,  # ä½¿ç”¨OCRåˆ¤æ–­çš„ç±»å‹
            options=options_list,
            question_hash=question_hash,
            encountered_date=date.today(),
            ocr_confidence=ocr_confidence,
            tags=None,  # ä¸ä¿å­˜æ ‡ç­¾ï¼ˆç”±detailæ¥å£æä¾›ï¼‰
            knowledge_points=None,  # ä¸ä¿å­˜çŸ¥è¯†ç‚¹ï¼ˆç”±detailæ¥å£æä¾›ï¼‰
            difficulty=None,  # ä¸ä¿å­˜éš¾åº¦ï¼ˆç”±detailæ¥å£æä¾›ï¼‰
            priority='ä¸­',
            correct_answer=None,  # ä¸ä¿å­˜ç­”æ¡ˆï¼ˆç”±detailæ¥å£æä¾›ï¼‰
            explanation=None  # ä¸ä¿å­˜è§£æï¼ˆç”±detailæ¥å£æä¾›ï¼‰
        )
        db.session.add(question)
        db.session.flush()  # è·å–question.id
        
        # æ³¨æ„ï¼šä¸åˆ›å»ºç­”æ¡ˆç‰ˆæœ¬ï¼Œç­”æ¡ˆå’Œè§£æç”±detailæ¥å£æä¾›
        
        db.session.commit()
        logger.info(f"[QuestionService] âœ… é¢˜ç›®å†…å®¹å·²ä¿å­˜åˆ°æ•°æ®åº“")
        logger.info(f"[QuestionService]    - é¢˜ç›®ID: {question.id}")
        logger.info("[QuestionService] ======================================")
        logger.info("")
        
        # æ ¼å¼åŒ–å“åº”ï¼ˆåªè¿”å›é¢˜ç›®å†…å®¹ï¼Œä¸è¿”å›ç­”æ¡ˆå’Œè§£æï¼‰
        response = self._format_question_content_response(question)
        response['from_cache'] = False
        response['is_duplicate'] = False
        response['saved_to_db'] = True  # æ–°å­˜å…¥æ•°æ®åº“
        response['similarity_score'] = None
        response['matched_question_id'] = None  # æ–°é¢˜ï¼Œæ²¡æœ‰åŒ¹é…
        
        # å­˜å…¥å†…å­˜ç¼“å­˜
        cache_key = self._get_cache_key(question_hash=question_hash)
        if cache_key:
            self._set_to_cache(cache_key, response)
        
        return response
    
    def _extract_question_content_fast(self, image_file, image_path):
        """
        å¿«é€Ÿæå–é¢˜ç›®å†…å®¹ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰
        1. å…ˆç”¨å¿«é€ŸOCRï¼ˆPaddleOCR/Tesseractï¼‰è¯†åˆ«æ–‡å­—ï¼ˆ1-3ç§’ï¼‰
        2. ç”¨è§„åˆ™è¿‡æ»¤æå–é¢˜ç›®å†…å®¹ï¼ˆå»é™¤ç•Œé¢å…ƒç´ ï¼‰
        3. å¦‚æœè§„åˆ™è¿‡æ»¤å¤±è´¥æˆ–ç»“æœä¸å®Œæ•´ï¼Œfallbackåˆ°AIï¼ˆç«å±±å¼•æ“visionï¼‰
        
        Args:
            image_file: å›¾ç‰‡æ–‡ä»¶å¯¹è±¡
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: OCRç»“æœï¼ˆåŒ…å«é¢˜å¹²ã€é€‰é¡¹ã€raw_textç­‰ï¼‰
        """
        logger.info("[QuestionService]    - ä½¿ç”¨å¿«é€ŸOCR+è§„åˆ™è¿‡æ»¤æå–é¢˜ç›®å†…å®¹...")
        
        # ç¬¬ä¸€æ­¥ï¼šå°è¯•å¿«é€ŸOCRï¼ˆPaddleOCR/Tesseractï¼‰
        try:
            from ocr_service import get_ocr_service
            ocr_service = get_ocr_service()
            
            if ocr_service.ocr_engine:
                logger.info("[QuestionService]    - ä½¿ç”¨å¿«é€ŸOCRè¯†åˆ«æ–‡å­—...")
                
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºOCR
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                    image_file.seek(0)
                    tmp_file.write(image_file.read())
                    tmp_path = tmp_file.name
                
                try:
                    # ä½¿ç”¨OCRæå–æ–‡å­—
                    raw_text = ocr_service.extract_text(tmp_path)
                    
                    if raw_text and len(raw_text.strip()) > 10:  # é™ä½é˜ˆå€¼ï¼Œå°è¯•æ›´å¤šæƒ…å†µ
                        logger.info(f"[QuestionService]    - OCRè¯†åˆ«æˆåŠŸï¼Œæ–‡å­—é•¿åº¦: {len(raw_text)}")
                        
                        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨è§„åˆ™è¿‡æ»¤æå–é¢˜ç›®å†…å®¹
                        from fast_ocr_extractor import get_fast_extractor
                        extractor = get_fast_extractor()
                        result = extractor.extract_question_from_text(raw_text)
                        
                        # ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°ç»“æœï¼Œå†³å®šæ˜¯å¦ä½¿ç”¨AIï¼ˆé™ä½é˜ˆå€¼ï¼Œæé«˜å¿«é€ŸOCRä½¿ç”¨ç‡ï¼‰
                        if result['is_complete'] and result['confidence'] >= 0.5:  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
                            logger.info(f"[QuestionService]    - âœ… è§„åˆ™è¿‡æ»¤æˆåŠŸï¼Œç½®ä¿¡åº¦: {result['confidence']:.2f}")
                            logger.info(f"[QuestionService]    - é¢˜å¹²: {result['question_text'][:50]}...")
                            logger.info(f"[QuestionService]    - é€‰é¡¹æ•°: {len(result['options'])}")
                            
                            # æ ¼å¼åŒ–è¿”å›ç»“æœ
                            return {
                                'question_text': result['question_text'],
                                'options': result['options'],
                                'raw_text': result['raw_text'],
                                'question_type': 'TEXT',  # é»˜è®¤æ–‡å­—é¢˜
                                'ocr_confidence': result['confidence'],
                                'extraction_method': 'fast_ocr_rule'
                            }
                        else:
                            logger.info(f"[QuestionService]    - âš ï¸ è§„åˆ™è¿‡æ»¤ç»“æœä¸å®Œæ•´ï¼Œç½®ä¿¡åº¦: {result['confidence']:.2f}")
                            logger.info(f"[QuestionService]    - Fallbackåˆ°AIæå–...")
                    else:
                        logger.info("[QuestionService]    - OCRè¯†åˆ«æ–‡å­—å¤ªå°‘ï¼ŒFallbackåˆ°AIæå–...")
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        import os
                        os.unlink(tmp_path)
                    except:
                        pass
            else:
                logger.info("[QuestionService]    - å¿«é€ŸOCRä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨AIæå–...")
        except Exception as e:
            logger.warning(f"[QuestionService]    - å¿«é€ŸOCRå¤±è´¥: {e}ï¼ŒFallbackåˆ°AIæå–...")
        
        # Fallbackï¼šä½¿ç”¨AIæå–ï¼ˆç«å±±å¼•æ“visionï¼‰
        logger.info("[QuestionService]    - ä½¿ç”¨AIï¼ˆç«å±±å¼•æ“visionï¼‰æå–é¢˜ç›®å†…å®¹...")
        image_file.seek(0)
        return self._extract_question_content_with_volcengine(image_file, image_path)
    
    def _extract_question_content_with_volcengine(self, image_file, image_path):
        """
        ä½¿ç”¨ç«å±±å¼•æ“OCRæå–é¢˜ç›®å†…å®¹ï¼ˆåªæå–é¢˜å¹²å’Œé€‰é¡¹ï¼Œä¸åˆ†æç­”æ¡ˆï¼‰
        
        Args:
            image_file: å›¾ç‰‡æ–‡ä»¶å¯¹è±¡
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: OCRç»“æœï¼ˆåŒ…å«é¢˜å¹²ã€é€‰é¡¹ã€raw_textç­‰ï¼Œä¸åŒ…å«ç­”æ¡ˆå’Œè§£æï¼‰
        """
        # æ„å»ºæç¤ºè¯ï¼Œåªæå–é¢˜ç›®å†…å®¹ï¼ˆé¢˜å¹²å’Œé€‰é¡¹ï¼‰ï¼Œä¸åˆ†æç­”æ¡ˆ
        # æ˜ç¡®è¦æ±‚è¿”å›JSONæ ¼å¼ï¼Œä¸è¿”å›å…¶ä»–å†…å®¹
        prompt = """è¯·ä»å›¾ç‰‡ä¸­æå–é¢˜ç›®å†…å®¹ï¼Œåªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦è¿”å›å…¶ä»–æ–‡å­—è¯´æ˜ã€‚

è¦æ±‚ï¼š
1. æå–å®Œæ•´çš„é¢˜å¹²å†…å®¹
2. æå–æ‰€æœ‰é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
3. åªè¿”å›JSONæ ¼å¼ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

{
    "question_text": "å®Œæ•´çš„é¢˜å¹²å†…å®¹",
    "options": ["A. é€‰é¡¹Aå†…å®¹", "B. é€‰é¡¹Bå†…å®¹", "C. é€‰é¡¹Cå†…å®¹", "D. é€‰é¡¹Då†…å®¹"],
    "raw_text": "å›¾ç‰‡ä¸­çš„åŸå§‹æ–‡å­—å†…å®¹"
}

æ³¨æ„ï¼šåªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
        
        try:
            logger.info("[QuestionService]    - ä½¿ç”¨ç«å±±å¼•æ“OCRæå–é¢˜ç›®å†…å®¹...")
            
            from volcengine_ocr_service import VolcengineOCRService
            volcengine_ocr = VolcengineOCRService()
            
            if not volcengine_ocr.is_available:
                raise Exception("ç«å±±å¼•æ“OCRæœåŠ¡ä¸å¯ç”¨")
            
            # è·å–å›¾ç‰‡è·¯å¾„
            local_image_path = None
            if image_path and os.path.exists(image_path):
                local_image_path = image_path
            elif image_file:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºOCR
                import tempfile
                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
                    image_file.seek(0)
                    tmp_file.write(image_file.read())
                    local_image_path = tmp_file.name
            
            if not local_image_path:
                raise Exception("æ— æ³•è·å–å›¾ç‰‡è·¯å¾„")
            
            logger.info(f"[QuestionService]    - ä½¿ç”¨ç«å±±å¼•æ“OCRåˆ†æå›¾ç‰‡: {local_image_path}")
            
            # è°ƒç”¨ç«å±±å¼•æ“visionæ¨¡å‹
            image_data = volcengine_ocr._read_image(local_image_path)
            if not image_data:
                raise Exception("æ— æ³•è¯»å–å›¾ç‰‡æ•°æ®")
            
            vision_result = volcengine_ocr._call_vision_model(image_data, prompt)
            if not vision_result:
                raise Exception("ç«å±±å¼•æ“visionæ¨¡å‹è°ƒç”¨å¤±è´¥")
            
            # è§£ævisionæ¨¡å‹çš„è¿”å›ç»“æœ
            content = ''
            if 'output' in vision_result:
                output_data = vision_result['output']
                if isinstance(output_data, list) and len(output_data) > 0:
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªtype='message'çš„é¡¹
                    for item in reversed(output_data):
                        if isinstance(item, dict) and item.get('type') == 'message':
                            content_list = item.get('content', [])
                            if isinstance(content_list, list):
                                for content_item in content_list:
                                    if isinstance(content_item, dict) and content_item.get('type') == 'output_text':
                                        content = content_item.get('text', '')
                                        break
                            if content:
                                break
                    if not content:
                        last_item = output_data[-1]
                        if isinstance(last_item, str):
                            content = last_item
                        elif isinstance(last_item, dict):
                            content = last_item.get('text', '') or last_item.get('content', '')
            
            if not content:
                raise Exception("æ— æ³•ä»visionæ¨¡å‹å“åº”ä¸­æå–å†…å®¹")
            
            # è®°å½•åŸå§‹å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.debug(f"[QuestionService] visionæ¨¡å‹è¿”å›å†…å®¹é¢„è§ˆ: {content[:200]}...")
            
            # è§£æJSONï¼ˆå¢å¼ºï¼šæ”¯æŒå¤šè¡ŒJSONå’ŒåµŒå¥—JSONï¼‰
            import re
            parsed = None
            
            # å°è¯•1: ç›´æ¥æŸ¥æ‰¾JSONå—ï¼ˆæœ€å¤–å±‚çš„å¤§æ‹¬å·ï¼‰
            json_patterns = [
                r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',  # ç®€å•åµŒå¥—JSON
                r'\{[\s\S]*?\}',  # éè´ªå©ªåŒ¹é…
                r'\{.*\}',  # è´ªå©ªåŒ¹é…ï¼ˆæœ€åå°è¯•ï¼‰
            ]
            
            for pattern in json_patterns:
                json_match = re.search(pattern, content, re.DOTALL)
                if json_match:
                    try:
                        parsed = json.loads(json_match.group())
                        logger.info(f"[QuestionService] âœ… æˆåŠŸè§£æJSONï¼ˆä½¿ç”¨æ¨¡å¼: {pattern[:30]}...ï¼‰")
                        break
                    except json.JSONDecodeError as e:
                        logger.debug(f"[QuestionService] JSONè§£æå¤±è´¥ï¼ˆæ¨¡å¼: {pattern[:30]}ï¼‰: {e}")
                        continue
            
            # å°è¯•2: å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»reasoningä¸­æå–ï¼ˆé™çº§å¤„ç†ï¼‰
            if not parsed and 'output' in vision_result:
                output_data = vision_result['output']
                # æŸ¥æ‰¾reasoningä¸­çš„summary_text
                for item in output_data:
                    if isinstance(item, dict) and item.get('type') == 'reasoning':
                        summary_list = item.get('summary', [])
                        if summary_list:
                            for summary_item in summary_list:
                                if isinstance(summary_item, dict) and summary_item.get('type') == 'summary_text':
                                    reasoning_text = summary_item.get('text', '')
                                    # å°è¯•ä»æ¨ç†æ–‡æœ¬ä¸­æå–JSON
                                    for pattern in json_patterns:
                                        json_match = re.search(pattern, reasoning_text, re.DOTALL)
                                        if json_match:
                                            try:
                                                parsed = json.loads(json_match.group())
                                                logger.info(f"[QuestionService] âœ… ä»reasoningä¸­æˆåŠŸè§£æJSON")
                                                break
                                            except json.JSONDecodeError:
                                                continue
                                    if parsed:
                                        break
                        if parsed:
                            break
            
            # å°è¯•3: å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°JSONï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–é¢˜ç›®ä¿¡æ¯ï¼ˆé™çº§å¤„ç†ï¼‰
            if not parsed:
                logger.warning(f"[QuestionService] âš ï¸ æ— æ³•æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–é¢˜ç›®ä¿¡æ¯...")
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡æœ¬ä¸­æå–é¢˜å¹²å’Œé€‰é¡¹
                question_text_match = re.search(r'(?:é¢˜å¹²|é¢˜ç›®|é—®é¢˜)[:ï¼š]?\s*(.+?)(?:\n|é€‰é¡¹|$)', content, re.DOTALL)
                question_text = question_text_match.group(1).strip() if question_text_match else ''
                
                # æå–é€‰é¡¹
                options = []
                option_patterns = [
                    r'([A-Z])[\.ã€ã€‚:\s\uFF0E]+\s*([^A-Z\n]+?)(?=\n|$|[A-Z][\.ã€ã€‚:\s\uFF0E])',
                    r'é€‰é¡¹([A-Z])[:ï¼š]?\s*([^\n]+)',
                ]
                for pattern in option_patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        for match in matches:
                            if isinstance(match, tuple) and len(match) >= 2:
                                letter = match[0]
                                opt_text = match[1].strip()
                                if opt_text:
                                    options.append(f"{letter}. {opt_text}")
                        if options:
                            break
                
                if question_text or options:
                    parsed = {
                        'question_text': question_text or 'æ— æ³•æå–é¢˜å¹²',
                        'options': options or [],
                        'raw_text': content
                    }
                    logger.info(f"[QuestionService] âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆæå–é¢˜ç›®ä¿¡æ¯ï¼ˆé¢˜å¹²: {len(question_text)}å­—ç¬¦, é€‰é¡¹æ•°: {len(options)}ï¼‰")
            
            if not parsed:
                # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                logger.error(f"[QuestionService] âŒ æ— æ³•è§£ævisionæ¨¡å‹è¿”å›å†…å®¹")
                logger.error(f"[QuestionService] è¿”å›å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰: {content[:500]}")
                logger.error(f"[QuestionService] è¿”å›å†…å®¹é•¿åº¦: {len(content)}å­—ç¬¦")
                
                # å°è¯•ä»reasoningä¸­æå–åŸå§‹OCRæ–‡æœ¬ä½œä¸ºraw_text
                raw_text_fallback = ''
                if 'output' in vision_result:
                    output_data = vision_result['output']
                    for item in output_data:
                        if isinstance(item, dict) and item.get('type') == 'reasoning':
                            summary_list = item.get('summary', [])
                            if summary_list:
                                for summary_item in summary_list:
                                    if isinstance(summary_item, dict) and summary_item.get('type') == 'summary_text':
                                        raw_text_fallback = summary_item.get('text', '')[:1000]  # å–å‰1000å­—ç¬¦
                                        break
                
                raise Exception(f"visionæ¨¡å‹è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼ã€‚è¿”å›å†…å®¹ç±»å‹: {type(content).__name__}, å†…å®¹é•¿åº¦: {len(content)}å­—ç¬¦ã€‚å»ºè®®ï¼šä½¿ç”¨æœ¬åœ°OCR+DeepSeekæ–¹æ¡ˆï¼ˆ/api/questions/extract/batchæ¥å£ï¼‰")
            
            # æ ¼å¼åŒ–é€‰é¡¹
            options = parsed.get('options', [])
            formatted_options = []
            for i, opt in enumerate(options):
                opt_str = str(opt).strip()
                # å¤„ç†é‡å¤å‰ç¼€
                match = re.match(r'^([A-Z])[\.ã€ã€‚:\s\uFF0E]+([A-Z])[\.ã€ã€‚:\s\uFF0E]+(.+)', opt_str)
                if match:
                    letter = match.group(2)
                    content_part = match.group(3).strip()
                    formatted_options.append(f"{letter}. {content_part}")
                else:
                    match = re.match(r'^([A-Z])[\.ã€ã€‚:\s\uFF0E]+(.+)', opt_str)
                    if match:
                        letter = match.group(1)
                        content_part = match.group(2).strip()
                        content_match = re.match(r'^([A-Z])[\.ã€ã€‚:\s\uFF0E]+(.+)', content_part)
                        if content_match:
                            letter = content_match.group(1)
                            content_part = content_match.group(2).strip()
                        formatted_options.append(f"{letter}. {content_part}")
                    else:
                        option_label = chr(65 + i)
                        formatted_options.append(f"{option_label}. {opt_str}")
            
            # è¿”å›OCRç»“æœï¼ˆåªåŒ…å«é¢˜ç›®å†…å®¹ï¼Œä¸åŒ…å«ç­”æ¡ˆå’Œè§£æï¼‰
            result = {
                'raw_text': parsed.get('raw_text', content),
                'question_text': parsed.get('question_text', ''),
                'options': formatted_options,
                'question_type': parsed.get('question_type', 'TEXT'),
                'ocr_confidence': 0.95,  # ç«å±±å¼•æ“OCRç½®ä¿¡åº¦
                'extraction_method': 'volcengine_vision'  # æ ‡è®°ä½¿ç”¨AI OCR
            }
            
            logger.info(f"[QuestionService]    - âœ… ç«å±±å¼•æ“OCRè¯†åˆ«æˆåŠŸï¼")
            logger.info(f"[QuestionService]    - é¢˜å¹²: {result.get('question_text', '')[:100]}...")
            logger.info(f"[QuestionService]    - é€‰é¡¹æ•°: {len(result.get('options', []))}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if image_file and local_image_path != image_path:
                try:
                    os.unlink(local_image_path)
                except:
                    pass
            
            return result
            
        except ImportError:
            logger.error("[QuestionService]    - âŒ ç«å±±å¼•æ“OCRæœåŠ¡ä¸å¯ç”¨")
            raise Exception("ç«å±±å¼•æ“OCRæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")
        except Exception as e:
            logger.error(f"[QuestionService]    - âŒ ç«å±±å¼•æ“OCRå¤±è´¥: {e}")
            raise Exception(f"ç«å±±å¼•æ“OCRå¤±è´¥: {e}")
    
    def _format_question_response(self, question):
        """
        æ ¼å¼åŒ–é¢˜ç›®å“åº”æ•°æ®
        
        Args:
            question: Questionå¯¹è±¡
            
        Returns:
            dict: æ ¼å¼åŒ–çš„å“åº”æ•°æ®
        """
        # è·å–æ‰€æœ‰ç­”æ¡ˆç‰ˆæœ¬
        answer_versions_data = []
        for ans in question.answer_versions:
            answer_versions_data.append({
                'id': str(ans.id),
                'source_name': ans.source_name,
                'source_type': ans.source_type,
                'answer': ans.answer,
                'explanation': ans.explanation,
                'confidence': ans.confidence,
                'is_user_preferred': ans.is_user_preferred,
                'created_at': ans.created_at.strftime('%Y-%m-%d') if ans.created_at else None,
                'updated_at': ans.updated_at.strftime('%Y-%m-%d') if ans.updated_at else None
            })
        
        # å¦‚æœæ²¡æœ‰ç­”æ¡ˆç‰ˆæœ¬ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
        if not answer_versions_data:
            answer_versions_data.append({
                'id': f'ans_{question.id}',
                'source_name': 'AI',
                'source_type': 'AI',
                'answer': question.correct_answer or '',
                'explanation': question.explanation or '',
                'confidence': 0.7,
                'is_user_preferred': True,
                'created_at': question.created_at.strftime('%Y-%m-%d') if question.created_at else None,
                'updated_at': question.updated_at.strftime('%Y-%m-%d') if question.updated_at else None
            })
        
        # æ ¼å¼åŒ–æ—¥æœŸ
        created_at_str = question.created_at.strftime('%Y-%m-%d') if question.created_at else None
        updated_at_str = question.updated_at.strftime('%Y-%m-%d') if question.updated_at else None
        encountered_date_str = question.encountered_date.strftime('%Y-%m-%d') if question.encountered_date else None
        
        return {
            'id': str(question.id),
            'screenshot': question.screenshot,
            'raw_text': question.raw_text,
            'question_text': question.question_text,  # æ·»åŠ å®Œæ•´é¢˜å¹²å­—æ®µ
            'question_type': question.question_type,
            'options': question.options if isinstance(question.options, list) else json.loads(question.options) if isinstance(question.options, str) else [],
            'answer_versions': answer_versions_data,
            'correct_answer': question.correct_answer,
            'explanation': question.explanation,
            'tags': question.tags if isinstance(question.tags, list) else json.loads(question.tags) if isinstance(question.tags, str) else [],
            'knowledge_points': question.knowledge_points if isinstance(question.knowledge_points, list) else json.loads(question.knowledge_points) if isinstance(question.knowledge_points, str) else [],
            'source': question.source,
            'source_url': question.source_url,
            'encountered_date': encountered_date_str,
            'difficulty': question.difficulty,
            'priority': question.priority,
            'ocr_confidence': question.ocr_confidence,
            'similar_questions': question.similar_questions if isinstance(question.similar_questions, list) else json.loads(question.similar_questions) if isinstance(question.similar_questions, str) else [],
            'created_at': created_at_str,
            'updated_at': updated_at_str
        }
    
    def _format_question_content_response(self, question):
        """
        æ ¼å¼åŒ–é¢˜ç›®å†…å®¹å“åº”æ•°æ®ï¼ˆåªè¿”å›é¢˜ç›®å†…å®¹ï¼Œä¸è¿”å›ç­”æ¡ˆå’Œè§£æï¼‰
        ç”¨äº /api/questions/analyze æ¥å£
        
        Args:
            question: Questionå¯¹è±¡
            
        Returns:
            dict: æ ¼å¼åŒ–çš„å“åº”æ•°æ®ï¼ˆåªåŒ…å«é¢˜ç›®å†…å®¹ï¼‰
        """
        result = {
            'id': str(question.id),
            'screenshot': question.screenshot,
            'raw_text': question.raw_text or '',
            'question_text': question.question_text or '',
            'question_type': question.question_type or 'TEXT',
            'options': question.options if isinstance(question.options, list) else json.loads(question.options) if isinstance(question.options, str) else [],
            'ocr_confidence': question.ocr_confidence,
            'matched_question_id': None,  # é»˜è®¤æ–°é¢˜æ²¡æœ‰åŒ¹é…IDï¼Œé‡å¤é¢˜ä¼šåœ¨é€»è¾‘ä¸­è®¾ç½®
            'extraction_method': 'volcengine_vision'  # é»˜è®¤å€¼ï¼Œä¼šåœ¨è°ƒç”¨å¤„è¦†ç›–
        }
        return result
    
    def analyze_question_detail(self, question_id):
        """
        åˆ†æé¢˜ç›®è¯¦æƒ…ï¼ˆç­”æ¡ˆã€è§£æã€æ ‡ç­¾ç­‰ï¼‰
        ä½¿ç”¨DeepSeekè¿›è¡Œè¯¦ç»†åˆ†æ
        
        Args:
            question_id: é¢˜ç›®ID
            
        Returns:
            dict: åŒ…å«ç­”æ¡ˆã€è§£æã€æ ‡ç­¾ç­‰è¯¦ç»†ä¿¡æ¯
        """
        logger.info("")
        logger.info(f"[QuestionService] ========== å¼€å§‹åˆ†æé¢˜ç›®è¯¦æƒ…: {question_id} ==========")
        
        # ä»æ•°æ®åº“è·å–é¢˜ç›®
        question = Question.query.filter_by(id=question_id).first()
        if not question:
            raise Exception(f"é¢˜ç›®ä¸å­˜åœ¨: {question_id}")
        
        logger.info(f"[QuestionService]    - é¢˜ç›®ID: {question_id}")
        logger.info(f"[QuestionService]    - é¢˜å¹²: {question.question_text[:100] if question.question_text else 'None'}...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç­”æ¡ˆç‰ˆæœ¬
        existing_answers = AnswerVersion.query.filter_by(question_id=question_id).all()
        if existing_answers and len(existing_answers) > 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„AIç­”æ¡ˆ
            has_valid_ai_answer = any(
                ans.source_type == 'AI' and 
                ans.answer and 
                ans.explanation and 
                not ans.explanation.startswith('AIè§£æå¤±è´¥')
                for ans in existing_answers
            )
            
            if has_valid_ai_answer:
                logger.info(f"[QuestionService] âœ… é¢˜ç›®å·²æœ‰ç­”æ¡ˆï¼Œè¿”å›å·²æœ‰æ•°æ®")
                return self._format_question_detail_response(question)
        
        # ä½¿ç”¨DeepSeekè¿›è¡Œè¯¦ç»†åˆ†æ
        logger.info("[QuestionService] ğŸ¤– è°ƒç”¨DeepSeekè¿›è¡Œè¯¦ç»†åˆ†æ...")
        
        # æ„å»ºé¢˜ç›®æ–‡æœ¬
        question_text = question.question_text or ''
        options_text = ''
        if question.options:
            if isinstance(question.options, list):
                options_text = '\n'.join(question.options)
            elif isinstance(question.options, str):
                try:
                    options_list = json.loads(question.options)
                    options_text = '\n'.join(options_list)
                except:
                    options_text = question.options
        
        full_question_text = f"{question_text}\n\né€‰é¡¹:\n{options_text}"
        
        # è°ƒç”¨DeepSeekåˆ†æï¼ˆä¼˜åŒ–ï¼šç²¾ç®€promptï¼Œå‡å°‘tokenæ•°é‡ï¼ŒåŠ å¿«å“åº”é€Ÿåº¦ï¼‰
        analysis_prompt = f"""åˆ†æé¢˜ç›®ï¼Œç»™å‡ºç­”æ¡ˆå’Œè§£æã€‚

é¢˜ç›®ï¼š
{full_question_text}

æ ‡ç­¾ï¼šè¡Œæµ‹(è¨€è¯­:è¯­å¥è¡”æ¥/æ’åº/é€»è¾‘å¡«ç©º/é˜…è¯»ç†è§£;æ•°é‡:ç®—æ•°/æ¯”ä¾‹/å·¥ç¨‹/æ¦‚ç‡/æ’åˆ—;åˆ¤æ–­:é€»è¾‘/å›¾å½¢/å®šä¹‰;èµ„æ–™:è¡¨æ ¼/å›¾å½¢/é€Ÿç®—;å¸¸è¯†:æ”¿æ²»/ç»æµ/å†å²åœ°ç†ç§‘æŠ€æ³•å¾‹) ç”³è®º(é¢˜æ:ç”Ÿæ€/åŸå¸‚/æ•™è‚²/åŒ»ç–—/ä¹¡æ‘/ç»æµ;èƒ½åŠ›:ææ–™è§£è¯»/æç‚¼/å¯¹ç­–/è®ºè¯/å…¬æ–‡;é£æ ¼:ç®€æ˜/æ•°æ®/æ”¿ç­–;è¯„åˆ†:è§‚ç‚¹/é€»è¾‘/æ–¹æ¡ˆ/è¯­è¨€;é”™å› :è®ºç‚¹/å¯¹ç­–/è¡¨è¿°)

è¿”å›JSONï¼š
{{
    "correct_answer": "B",
    "explanation": "è¯¦ç»†è§£æ",
    "tags": ["è¡Œæµ‹-æ•°é‡å…³ç³»-æ¯”ä¾‹ä¸æ¯”ç‡"],
    "knowledge_points": ["æ¯”ç‡ä¸æ¯”ä¾‹"],
    "difficulty": 3,
    "answer_versions": [{{"source_name": "AI", "source_type": "AI", "answer": "B", "explanation": "è§£æ", "confidence": 0.8}}]
}}"""
        
        try:
            response = self.ai_service.client.chat.completions.create(
                model=self.ai_service.default_model,
                messages=[
                    {
                        "role": "user",
                        "content": analysis_prompt
                    }
                ],
                temperature=0.7,
                max_tokens=2000  # ä¼˜åŒ–ï¼šå‡å°‘max_tokensï¼ŒåŠ å¿«å“åº”é€Ÿåº¦ï¼ˆä»3000é™åˆ°2000ï¼‰
            )
            ai_response = response.choices[0].message.content
            
            # è§£æJSON
            import re
            json_match = re.search(r'\{[\s\S]*\}', ai_response, re.DOTALL)
            if json_match:
                analysis_dict = json.loads(json_match.group(0))
            else:
                raise Exception("AIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼")
            
            # æ›´æ–°é¢˜ç›®ä¿¡æ¯
            question.correct_answer = analysis_dict.get('correct_answer')
            question.explanation = analysis_dict.get('explanation')
            question.tags = analysis_dict.get('tags', [])
            question.knowledge_points = analysis_dict.get('knowledge_points', [])
            question.difficulty = analysis_dict.get('difficulty', 3)
            question.updated_at = datetime.utcnow()
            
            # åˆ›å»ºæˆ–æ›´æ–°ç­”æ¡ˆç‰ˆæœ¬
            answer_versions_data = analysis_dict.get('answer_versions', [])
            if not answer_versions_data:
                # å¦‚æœæ²¡æœ‰answer_versionsï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
                answer_versions_data = [{
                    'source_name': 'AI',
                    'source_type': 'AI',
                    'answer': analysis_dict.get('correct_answer', ''),
                    'explanation': analysis_dict.get('explanation', ''),
                    'confidence': 0.8,
                    'is_user_preferred': False
                }]
            
            # åˆ é™¤æ—§çš„AIç­”æ¡ˆç‰ˆæœ¬
            AnswerVersion.query.filter_by(
                question_id=question_id,
                source_type='AI'
            ).delete()
            
            # åˆ›å»ºæ–°çš„ç­”æ¡ˆç‰ˆæœ¬
            for ans_data in answer_versions_data:
                answer_version = AnswerVersion(
                    question_id=question.id,
                    source_name=ans_data.get('source_name', 'AI'),
                    source_type=ans_data.get('source_type', 'AI'),
                    answer=ans_data.get('answer'),
                    explanation=ans_data.get('explanation'),
                    confidence=ans_data.get('confidence', 0.8),
                    is_user_preferred=ans_data.get('is_user_preferred', False)
                )
                db.session.add(answer_version)
            
            db.session.commit()
            logger.info(f"[QuestionService] âœ… é¢˜ç›®è¯¦æƒ…å·²ä¿å­˜åˆ°æ•°æ®åº“")
            logger.info(f"[QuestionService]    - æ­£ç¡®ç­”æ¡ˆ: {question.correct_answer}")
            logger.info(f"[QuestionService]    - ç­”æ¡ˆç‰ˆæœ¬æ•°: {len(answer_versions_data)}")
            logger.info("[QuestionService] ======================================")
            logger.info("")
            
            return self._format_question_detail_response(question)
            
        except Exception as e:
            logger.error(f"[QuestionService] âŒ DeepSeekåˆ†æå¤±è´¥: {e}")
            raise Exception(f"DeepSeekåˆ†æå¤±è´¥: {e}")
    
    def _format_question_detail_response(self, question):
        """
        æ ¼å¼åŒ–é¢˜ç›®è¯¦æƒ…å“åº”æ•°æ®ï¼ˆåŒ…å«ç­”æ¡ˆã€è§£æã€æ ‡ç­¾ç­‰ï¼‰
        ç”¨äº /api/questions/{question_id}/detail æ¥å£
        
        Args:
            question: Questionå¯¹è±¡
            
        Returns:
            dict: æ ¼å¼åŒ–çš„å“åº”æ•°æ®ï¼ˆåŒ…å«å®Œæ•´è¯¦æƒ…ï¼‰
        """
        # è·å–æ‰€æœ‰ç­”æ¡ˆç‰ˆæœ¬
        answer_versions_data = []
        for ans in question.answer_versions:
            answer_versions_data.append({
                'id': str(ans.id),
                'source_name': ans.source_name,
                'source_type': ans.source_type,
                'answer': ans.answer,
                'explanation': ans.explanation,
                'confidence': ans.confidence,
                'is_user_preferred': ans.is_user_preferred,
                'created_at': ans.created_at.strftime('%Y-%m-%d') if ans.created_at else None,
                'updated_at': ans.updated_at.strftime('%Y-%m-%d') if ans.updated_at else None
            })
        
        # å¦‚æœæ²¡æœ‰ç­”æ¡ˆç‰ˆæœ¬ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
        if not answer_versions_data:
            answer_versions_data.append({
                'id': f'ans_{question.id}',
                'source_name': 'AI',
                'source_type': 'AI',
                'answer': question.correct_answer or '',
                'explanation': question.explanation or '',
                'confidence': 0.7,
                'is_user_preferred': True,
                'created_at': question.created_at.strftime('%Y-%m-%d') if question.created_at else None,
                'updated_at': question.updated_at.strftime('%Y-%m-%d') if question.updated_at else None
            })
        
        # æ ¼å¼åŒ–æ—¥æœŸ
        created_at_str = question.created_at.strftime('%Y-%m-%d') if question.created_at else None
        updated_at_str = question.updated_at.strftime('%Y-%m-%d') if question.updated_at else None
        encountered_date_str = question.encountered_date.strftime('%Y-%m-%d') if question.encountered_date else None
        
        return {
            'id': str(question.id),
            'question_id': str(question.id),
            'answer_versions': answer_versions_data,
            'correct_answer': question.correct_answer,
            'explanation': question.explanation,
            'tags': question.tags if isinstance(question.tags, list) else json.loads(question.tags) if isinstance(question.tags, str) else [],
            'knowledge_points': question.knowledge_points if isinstance(question.knowledge_points, list) else json.loads(question.knowledge_points) if isinstance(question.knowledge_points, str) else [],
            'source': question.source,
            'source_url': question.source_url,
            'similar_questions': question.similar_questions if isinstance(question.similar_questions, list) else json.loads(question.similar_questions) if isinstance(question.similar_questions, str) else [],
            'encountered_date': encountered_date_str,
            'difficulty': question.difficulty,
            'priority': question.priority,
            'created_at': created_at_str,
            'updated_at': updated_at_str
        }

