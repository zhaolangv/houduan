"""
Flaskåº”ç”¨ä¸»æ–‡ä»¶
"""
from flask import Flask, request, jsonify
from models_v2 import db, Question, AnswerVersion, UserSession, DailyActiveUser
from question_service_v2 import QuestionService
import os
import sys
from dotenv import load_dotenv
from werkzeug.utils import secure_filename
import uuid
import logging
import json
import base64

# é…ç½®æ—¥å¿—ï¼ˆåœ¨Flask appåˆ›å»ºå‰é…ç½®ï¼‰
logging.basicConfig(
    level=logging.DEBUG,
    format='[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¤„ç†ç¼–ç é”™è¯¯ï¼‰
env_loaded = False
try:
    load_dotenv()
    env_loaded = True
except UnicodeDecodeError as e:
    # å¦‚æœ.envæ–‡ä»¶ç¼–ç æœ‰é—®é¢˜ï¼Œå°è¯•ä½¿ç”¨latin-1ç¼–ç 
    logger.warning(f"åŠ è½½.envæ–‡ä»¶æ—¶å‡ºç°ç¼–ç é”™è¯¯: {e}ï¼Œå°è¯•ä¿®å¤...")
    import io
    try:
        with open('.env', 'r', encoding='latin-1') as f:
            content = f.read()
        # é‡æ–°å†™å…¥ä¸ºUTF-8
        with open('.env', 'w', encoding='utf-8') as f:
            f.write(content)
        load_dotenv()
        env_loaded = True
    except Exception as e2:
        logger.warning(f"æ— æ³•ä¿®å¤.envæ–‡ä»¶: {e2}ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼")
        # å¦‚æœä¿®å¤å¤±è´¥ï¼Œåˆ é™¤æœ‰é—®é¢˜çš„DATABASE_URL
        try:
            with open('.env', 'r', encoding='latin-1') as f:
                lines = f.readlines()
            # è¿‡æ»¤æ‰DATABASE_URLè¡Œ
            filtered_lines = [line for line in lines if not line.strip().startswith('DATABASE_URL')]
            with open('.env', 'w', encoding='utf-8') as f:
                f.writelines(filtered_lines)
            logger.info("å·²ä».envæ–‡ä»¶ä¸­ç§»é™¤æœ‰é—®é¢˜çš„DATABASE_URLè¡Œ")
        except:
            pass
except Exception as e:
    logger.warning(f"åŠ è½½.envæ–‡ä»¶æ—¶å‡ºé”™: {e}ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼")

app = Flask(__name__)

# é…ç½®Flaskçš„æ—¥å¿—
app.logger.setLevel(logging.DEBUG)
werkzeug_logger = logging.getLogger('werkzeug')
werkzeug_logger.setLevel(logging.INFO)  # Werkzeugæ—¥å¿—è®¾ä¸ºINFOï¼Œå‡å°‘å™ªéŸ³

# æ•°æ®åº“é…ç½® - æ”¯æŒå¤šçº§å›é€€ï¼šPostgreSQL -> SQLite -> MySQL
# å®‰å…¨åœ°è¯»å–DATABASE_URLï¼Œå¦‚æœå‡ºç°ç¼–ç é”™è¯¯åˆ™ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
database_url = None
database_type = None  # 'postgresql', 'sqlite', 'mysql'

try:
    database_url = os.getenv('DATABASE_URL')
    # å¦‚æœè¯»å–æˆåŠŸï¼Œå°è¯•éªŒè¯ç¼–ç 
    if database_url:
        # å®‰å…¨åœ°å¤„ç†å¯èƒ½çš„ç¼–ç é—®é¢˜
        try:
            # å¦‚æœdatabase_urlæ˜¯bytesç±»å‹ï¼Œå…ˆè§£ç 
            if isinstance(database_url, bytes):
                database_url = database_url.decode('utf-8', errors='ignore')
            
            # å°è¯•ç¼–ç ä¸ºUTF-8ï¼Œå¦‚æœå¤±è´¥è¯´æ˜æœ‰ç¼–ç é—®é¢˜
            database_url.encode('utf-8')
            
            # å¦‚æœæ˜¯PostgreSQL URLï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«éASCIIå­—ç¬¦
            if 'postgres' in database_url.lower():
                database_url.encode('ascii')  # PostgreSQL URLåº”è¯¥åªåŒ…å«ASCIIå­—ç¬¦
                database_type = 'postgresql'
            elif 'mysql' in database_url.lower():
                database_type = 'mysql'
            else:
                database_type = 'sqlite'
        except (UnicodeDecodeError, UnicodeEncodeError, AttributeError) as encoding_err:
            logger.warning(f"DATABASE_URLç¼–ç éªŒè¯å¤±è´¥: {encoding_err}ï¼Œå°†ä½¿ç”¨SQLite")
            database_url = None
except (UnicodeDecodeError, UnicodeEncodeError, AttributeError) as e:
    logger.warning(f"è¯»å–DATABASE_URLæ—¶å‡ºç°ç¼–ç é”™è¯¯: {e}ï¼Œå°†ä½¿ç”¨å¤‡é€‰æ•°æ®åº“")
    # åˆ é™¤æœ‰é—®é¢˜çš„ç¯å¢ƒå˜é‡
    if 'DATABASE_URL' in os.environ:
        del os.environ['DATABASE_URL']
    database_url = None
except Exception as e:
    logger.warning(f"è¯»å–DATABASE_URLæ—¶å‡ºç°å…¶ä»–é”™è¯¯: {e}ï¼Œå°†ä½¿ç”¨å¤‡é€‰æ•°æ®åº“")
    database_url = None

if not database_url:
    # å¦‚æœæ²¡æœ‰é…ç½®ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ï¼šSQLite -> MySQL
    # é¦–å…ˆå°è¯•SQLiteï¼ˆæœ€ç®€å•ï¼Œæ— éœ€é…ç½®ï¼‰
    database_url = 'sqlite:///gongkao_test.db'
    database_type = 'sqlite'
    print("âš ï¸ æœªé…ç½®DATABASE_URLï¼Œä½¿ç”¨SQLiteæµ‹è¯•æ•°æ®åº“: gongkao_test.db")
    print("   ç”Ÿäº§ç¯å¢ƒè¯·é…ç½®Supabaseæ•°æ®åº“æˆ–MySQLæ•°æ®åº“")
else:
    # æ£€æŸ¥å¹¶æ¸…ç†æ•°æ®åº“URLï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰
    original_url = database_url
    try:
        # å¦‚æœURLåŒ…å«æ— æ•ˆå­—ç¬¦ï¼Œå°è¯•ä¿®å¤
        if isinstance(database_url, bytes):
            database_url = database_url.decode('utf-8', errors='ignore')
        # ç§»é™¤å¯èƒ½çš„BOMæˆ–å…¶ä»–æ— æ•ˆå­—ç¬¦
        database_url = database_url.strip().strip('\ufeff')
        
        # æ£€æŸ¥URLæ˜¯å¦åŒ…å«æ— æ•ˆå­—ç¬¦ï¼ˆç¼–ç é”™è¯¯ï¼‰
        database_url.encode('utf-8')
        
        # å°è¯•æµ‹è¯•è¿æ¥ï¼ˆä¸å®é™…è¿æ¥ï¼Œåªæ£€æŸ¥URLæ ¼å¼ï¼‰
        if 'postgres' in database_url.lower():
            # å¯¹äºPostgreSQLï¼Œæ£€æŸ¥URLæ ¼å¼æ˜¯å¦æ­£ç¡®
            # å¦‚æœåŒ…å«éASCIIå­—ç¬¦ï¼Œå¯èƒ½æ˜¯ç¼–ç é—®é¢˜
            try:
                # å°è¯•è§£æURL
                database_url.encode('ascii')
            except UnicodeEncodeError:
                # åŒ…å«éASCIIå­—ç¬¦ï¼Œå¯èƒ½æ˜¯ç¼–ç é—®é¢˜
                raise UnicodeDecodeError('utf-8', original_url.encode('latin-1') if isinstance(original_url, str) else original_url, 0, 1, 'invalid start byte')
    except (UnicodeDecodeError, UnicodeEncodeError) as e:
        logger.warning(f"æ•°æ®åº“URLç¼–ç é”™è¯¯: {e}ï¼Œä½¿ç”¨SQLite")
        database_url = 'sqlite:///gongkao_test.db'
        use_sqlite = True
    except Exception as e:
        logger.warning(f"æ•°æ®åº“URLå¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨SQLite")
        database_url = 'sqlite:///gongkao_test.db'
        use_sqlite = True

# å¦‚æœSupabaseè¿æ¥å­—ç¬¦ä¸²æ˜¯postgres://å¼€å¤´ï¼Œéœ€è¦è½¬æ¢ä¸ºpostgresql://
if database_url and database_url.startswith('postgres://'):
    database_url = database_url.replace('postgres://', 'postgresql://', 1)

# æ ‡è®°æ˜¯å¦å·²ç»å›é€€åˆ°SQLite
_db_fallback_to_sqlite = False

# å®‰å…¨åœ°è®¾ç½®æ•°æ®åº“URLå¹¶åˆå§‹åŒ–
try:
    app.config['SQLALCHEMY_DATABASE_URI'] = database_url
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    
    # æ ¹æ®æ•°æ®åº“ç±»å‹é…ç½®è¿æ¥æ± ï¼ˆæ”¯æŒé«˜å¹¶å‘æ‰¹é‡å¤„ç†ï¼‰
    if 'sqlite' in database_url.lower():
        # SQLite è¿æ¥æ± é…ç½®ï¼ˆSQLite å¯¹å¹¶å‘æ”¯æŒæœ‰é™ï¼Œä½†å¯ä»¥å¢åŠ è¿æ¥æ•°ï¼‰
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 20,          # SQLite æ”¯æŒæ›´å¤šè¿æ¥
            'max_overflow': 30,       # æº¢å‡ºè¿æ¥æ•°
            'pool_timeout': 30,       # è¿æ¥è¶…æ—¶æ—¶é—´
            'connect_args': {
                'check_same_thread': False,  # å…è®¸å¤šçº¿ç¨‹è®¿é—®
                'timeout': 30                # SQLite è¿æ¥è¶…æ—¶
            }
        }
    else:
        # PostgreSQL/MySQL è¿æ¥æ± é…ç½®ï¼ˆæ”¯æŒé«˜å¹¶å‘ï¼‰
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,    # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
            'pool_recycle': 300,      # å›æ”¶è¿æ¥æ—¶é—´ï¼ˆç§’ï¼‰
            'pool_size': 20,          # è¿æ¥æ± å¤§å°ï¼ˆé»˜è®¤5ä¸å¤Ÿï¼Œå¢åŠ åˆ°20ï¼‰
            'max_overflow': 30,       # æœ€å¤§æº¢å‡ºè¿æ¥æ•°ï¼ˆé»˜è®¤10ä¸å¤Ÿï¼Œå¢åŠ åˆ°30ï¼‰
            'pool_timeout': 30,       # è·å–è¿æ¥çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        }
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db.init_app(app)
except Exception as init_error:
    # å¦‚æœåˆå§‹åŒ–æ—¶å‡ºç°ç¼–ç é”™è¯¯ï¼Œå›é€€åˆ°SQLite
    error_msg = str(init_error)
    if 'codec' in error_msg.lower() or 'decode' in error_msg.lower() or 'utf-8' in error_msg.lower():
        logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–æ—¶å‡ºç°ç¼–ç é”™è¯¯: {init_error}ï¼Œå›é€€åˆ°SQLite")
        database_url = 'sqlite:///gongkao_test.db'
        database_type = 'sqlite'
        app.config['SQLALCHEMY_DATABASE_URI'] = database_url
        # æ›´æ–°è¿æ¥æ± é…ç½®ä¸ºSQLiteé…ç½®
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 20,
            'max_overflow': 30,
            'pool_timeout': 30,
            'connect_args': {
                'check_same_thread': False,
                'timeout': 30
            }
        }
        db.init_app(app)
        _db_fallback_to_sqlite = True
    else:
        # å…¶ä»–é”™è¯¯ï¼Œé‡æ–°æŠ›å‡º
        raise

# æµ‹è¯•æ•°æ®åº“è¿æ¥ï¼ˆåœ¨app_contextä¸­ï¼‰
def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°SQLite"""
    try:
        with app.app_context():
            db.engine.connect()
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        return True
    except (UnicodeDecodeError, UnicodeEncodeError) as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥ç¼–ç é”™è¯¯ï¼š{e}")
        if not use_sqlite:
            logger.warning("âš ï¸ å›é€€åˆ°SQLiteæ•°æ®åº“")
            app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///gongkao_test.db'
            try:
                with app.app_context():
                    db.engine.connect()
                logger.info("âœ… SQLiteæ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                return True
            except Exception as e2:
                logger.error(f"âŒ SQLiteæ•°æ®åº“è¿æ¥ä¹Ÿå¤±è´¥ï¼š{e2}")
                return False
        return False
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
        if not use_sqlite:
            logger.warning("âš ï¸ å›é€€åˆ°SQLiteæ•°æ®åº“")
            app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///gongkao_test.db'
            try:
                with app.app_context():
                    db.engine.connect()
                logger.info("âœ… SQLiteæ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                return True
            except Exception as e2:
                logger.error(f"âŒ SQLiteæ•°æ®åº“è¿æ¥ä¹Ÿå¤±è´¥ï¼š{e2}")
                return False
        return False

# åœ¨å¯åŠ¨æ—¶æµ‹è¯•è¿æ¥ï¼ˆå»¶è¿Ÿåˆ°if __name__ == '__main__'ä¸­ï¼‰

# åˆå§‹åŒ–é¢˜ç›®æœåŠ¡
question_service = QuestionService()

# åˆå§‹åŒ–ç”¨æˆ·ç»Ÿè®¡æœåŠ¡
from user_statistics_service import get_user_statistics_service
user_statistics_service = get_user_statistics_service()

# æ–‡ä»¶ä¸Šä¼ é…ç½®
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# APKæ–‡ä»¶é…ç½®
APK_FOLDER = 'apk'
os.makedirs(APK_FOLDER, exist_ok=True)
APK_VERSION_FILE = os.path.join(APK_FOLDER, 'version.json')  # å­˜å‚¨APKç‰ˆæœ¬ä¿¡æ¯

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def _check_version_update(client_version, server_version):
    """
    æ£€æŸ¥å®¢æˆ·ç«¯ç‰ˆæœ¬æ˜¯å¦éœ€è¦æ›´æ–°
    
    Args:
        client_version: å®¢æˆ·ç«¯ç‰ˆæœ¬å·ï¼ˆå¦‚ "1.0.0"ï¼‰
        server_version: æœåŠ¡ç«¯ç‰ˆæœ¬å·ï¼ˆå¦‚ "2.0.0"ï¼‰
        
    Returns:
        dict: æ›´æ–°ä¿¡æ¯
    """
    import json
    
    # é»˜è®¤æ›´æ–°ä¿¡æ¯
    update_info = {
        'required': False,
        'latest_version': server_version,
        'download_url': '/api/apk/download',
        'release_notes': ''
    }
    
    # å¦‚æœæ²¡æœ‰æä¾›å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼Œä¸æ£€æŸ¥æ›´æ–°
    if not client_version:
        return update_info
    
    # è¯»å–APKç‰ˆæœ¬ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    apk_info = {}
    if os.path.exists(APK_VERSION_FILE):
        try:
            with open(APK_VERSION_FILE, 'r', encoding='utf-8') as f:
                apk_info = json.load(f)
                if 'version' in apk_info:
                    update_info['latest_version'] = apk_info['version']
                if 'release_notes' in apk_info:
                    update_info['release_notes'] = apk_info['release_notes']
        except Exception as e:
            logger.warning(f"[API] è¯»å–APKç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    # ç®€å•çš„ç‰ˆæœ¬æ¯”è¾ƒï¼ˆæ”¯æŒè¯­ä¹‰åŒ–ç‰ˆæœ¬å· x.y.zï¼‰
    try:
        client_parts = [int(x) for x in client_version.split('.')]
        server_parts = [int(x) for x in update_info['latest_version'].split('.')]
        
        # è¡¥é½ç‰ˆæœ¬å·é•¿åº¦
        max_len = max(len(client_parts), len(server_parts))
        client_parts.extend([0] * (max_len - len(client_parts)))
        server_parts.extend([0] * (max_len - len(server_parts)))
        
        # æ¯”è¾ƒç‰ˆæœ¬å·
        for i in range(max_len):
            if server_parts[i] > client_parts[i]:
                update_info['required'] = True
                break
            elif server_parts[i] < client_parts[i]:
                break
    except Exception as e:
        logger.warning(f"[API] ç‰ˆæœ¬å·æ¯”è¾ƒå¤±è´¥: {e}ï¼Œå‡è®¾éœ€è¦æ›´æ–°")
        # å¦‚æœç‰ˆæœ¬å·æ ¼å¼ä¸æ­£ç¡®ï¼Œå‡è®¾éœ€è¦æ›´æ–°
        if client_version != update_info['latest_version']:
            update_info['required'] = True
    
    return update_info


@app.route('/api/questions/analyze', methods=['POST'])
def analyze_question():
    """
    é¢˜ç›®å†…å®¹åˆ†ææ¥å£ï¼ˆåªè¿”å›é¢˜ç›®å†…å®¹ï¼Œä¸è¿”å›ç­”æ¡ˆå’Œè§£æï¼‰
    
    è¯·æ±‚æ ¼å¼ï¼šmultipart/form-data
    å‚æ•°ï¼š
    - image: å›¾ç‰‡æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
    - raw_text: å‰ç«¯OCRåŸå§‹æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
    - question_text: å‰ç«¯æå–çš„é¢˜å¹²ï¼ˆå¯é€‰ï¼Œå¯èƒ½ä¸å‡†ç¡®ï¼‰
    - options: å‰ç«¯æå–çš„é€‰é¡¹ï¼ˆå¯é€‰ï¼ŒJSONå­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰
    - question_type: é¢˜ç›®ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤"TEXT"ï¼‰
    - force_reanalyze: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ†æï¼ˆå¯é€‰ï¼Œé»˜è®¤falseï¼‰
    
    è¿”å›ï¼šåªåŒ…å«é¢˜ç›®å†…å®¹ï¼ˆé¢˜å¹²ã€é€‰é¡¹ï¼‰ï¼Œä¸åŒ…å«ç­”æ¡ˆå’Œè§£æ
    æµç¨‹ï¼š
    1. åˆ©ç”¨å‰ç«¯æä¾›çš„æ•°æ®è¿›è¡Œå¿«é€Ÿå»é‡æ£€æŸ¥ï¼ˆç¼“å­˜ï¼‰
    2. å¦‚æœæ‰¾åˆ°é‡å¤é¢˜ä¸”ä¸å¼ºåˆ¶é‡æ–°åˆ†æï¼Œç›´æ¥è¿”å›ç¼“å­˜
    3. å¦åˆ™ä½¿ç”¨ç«å±±å¼•æ“OCRæå–é¢˜ç›®å†…å®¹ï¼Œå­˜å…¥æ•°æ®åº“å¹¶è¿”å›
    """
    try:
        logger.info("=" * 60)
        logger.info("[API] ========== æ”¶åˆ°é¢˜ç›®åˆ†æè¯·æ±‚ ==========")
        
        # æ£€æŸ¥å¿…éœ€å‚æ•°
        if 'image' not in request.files:
            logger.warning("[API] âŒ ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶")
            return jsonify({'error': 'ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶', 'code': 400}), 400
        
        image_file = request.files['image']
        if image_file.filename == '':
            logger.warning("[API] âŒ å›¾ç‰‡æ–‡ä»¶ä¸ºç©º")
            return jsonify({'error': 'å›¾ç‰‡æ–‡ä»¶ä¸ºç©º', 'code': 400}), 400
        
        # è·å–å‰ç«¯OCRæ•°æ®
        raw_text = request.form.get('raw_text', '').strip()
        question_text = request.form.get('question_text', '').strip()
        options_str = request.form.get('options', '')
        question_type = request.form.get('question_type', 'TEXT').strip()
        force_reanalyze = request.form.get('force_reanalyze', 'false').lower() == 'true'
        
        # è§£æoptionsï¼ˆå¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²ï¼‰
        options = []
        if options_str:
            try:
                if isinstance(options_str, str):
                    options = json.loads(options_str) if options_str.startswith('[') else [options_str]
                else:
                    options = options_str if isinstance(options_str, list) else []
            except json.JSONDecodeError:
                logger.warning(f"[API] âš ï¸ æ— æ³•è§£æoptions JSON: {options_str}")
                options = []
        
        logger.info(f"[API] ğŸ“ è¯·æ±‚å‚æ•°:")
        logger.info(f"[API]    - å›¾ç‰‡æ–‡ä»¶å: {image_file.filename}")
        logger.info(f"[API]    - å›¾ç‰‡å¤§å°: {len(image_file.read())} bytes")
        image_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        
        if raw_text:
            logger.info(f"[API]    - å‰ç«¯OCRåŸå§‹æ–‡æœ¬: {raw_text[:100]}...")
        if question_text:
            logger.info(f"[API]    - å‰ç«¯æå–é¢˜å¹²: {question_text[:100]}...")
        if options:
            logger.info(f"[API]    - å‰ç«¯æå–é€‰é¡¹æ•°: {len(options)}")
        logger.info(f"[API]    - é¢˜ç›®ç±»å‹: {question_type}")
        logger.info(f"[API]    - å¼ºåˆ¶é‡æ–°åˆ†æ: {force_reanalyze}")
        
        logger.info(f"[API] ğŸ” å¼€å§‹åˆ†æé¢˜ç›®ï¼ˆä¼˜åŒ–æµç¨‹ï¼‰...")
        
        # è°ƒç”¨é¢˜ç›®æœåŠ¡
        result = question_service.analyze_question_from_image(
            image_file=image_file,
            frontend_raw_text=raw_text if raw_text else None,
            frontend_question_text=question_text if question_text else None,
            frontend_options=options if options else None,
            question_type=question_type,
            force_reanalyze=force_reanalyze
        )
        
        logger.info(f"[API] âœ… é¢˜ç›®å†…å®¹åˆ†æå®Œæˆ!")
        logger.info(f"[API]    - é¢˜ç›®ID: {result.get('id')}")
        logger.info(f"[API]    - é¢˜å¹²: {result.get('question_text', '')[:100]}...")
        logger.info(f"[API]    - é€‰é¡¹æ•°: {len(result.get('options', []))}")
        logger.info(f"[API]    - OCRç½®ä¿¡åº¦: {result.get('ocr_confidence')}")
        logger.info(f"[API]    - æ¥è‡ªç¼“å­˜: {result.get('from_cache', False)}")
        logger.info(f"[API]    - æ˜¯é‡å¤é¢˜: {result.get('is_duplicate', False)}")
        logger.info(f"[API]    - å­˜å…¥æ•°æ®åº“: {result.get('saved_to_db', False)}")
        if result.get('similarity_score'):
            logger.info(f"[API]    - ç›¸ä¼¼åº¦åˆ†æ•°: {result.get('similarity_score'):.3f}")
        if result.get('matched_question_id'):
            logger.info(f"[API]    - åŒ¹é…é¢˜ç›®ID: {result.get('matched_question_id')}")
        logger.info(f"[API] ==========================================")
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"[API] âŒ æ¥å£å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/questions/analyze/batch', methods=['POST'])
def analyze_questions_batch():
    """
    æ‰¹é‡é¢˜ç›®å†…å®¹åˆ†ææ¥å£
    
    æ”¯æŒä¸¤ç§è¯·æ±‚æ ¼å¼ï¼š
    1. multipart/form-dataï¼ˆæ¨èç”¨äºæ–‡ä»¶ä¸Šä¼ ï¼‰
    2. application/jsonï¼ˆæ¨èç”¨äºbase64ç¼–ç çš„å›¾ç‰‡ï¼‰
    
    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-dataï¼‰ï¼š
    - images[]: å¤šä¸ªå›¾ç‰‡æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
    - raw_texts[]: å¯¹åº”çš„åŸå§‹æ–‡æœ¬æ•°ç»„ï¼ˆJSONå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰
    - question_texts[]: å¯¹åº”çš„é¢˜å¹²æ•°ç»„ï¼ˆJSONå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰
    - options_array[]: å¯¹åº”çš„é€‰é¡¹æ•°ç»„ï¼ˆJSONå­—ç¬¦ä¸²æ•°ç»„çš„JSONå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰
    - question_types[]: å¯¹åº”çš„é¢˜ç›®ç±»å‹æ•°ç»„ï¼ˆJSONå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰
    - force_reanalyze: å¸ƒå°”å€¼ï¼Œç»Ÿä¸€åº”ç”¨åˆ°æ‰€æœ‰é¢˜ç›®ï¼ˆå¯é€‰ï¼Œé»˜è®¤falseï¼‰
    
    è¯·æ±‚å‚æ•°ï¼ˆapplication/jsonï¼‰ï¼š
    {
        "questions": [
            {
                "image": "base64ç¼–ç çš„å›¾ç‰‡æ•°æ®",
                "raw_text": "OCRåŸå§‹æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰",
                "question_text": "é¢˜å¹²ï¼ˆå¯é€‰ï¼‰",
                "options": ["A. ...", "B. ..."]ï¼ˆå¯é€‰ï¼‰,
                "question_type": "TEXT"ï¼ˆå¯é€‰ï¼‰,
                "force_reanalyze": falseï¼ˆå¯é€‰ï¼‰
            }
        ]
    }
    
    è¿”å›ï¼š
    {
        "results": [
            {
                "success": true,
                "question": {...},
                "error": null
            },
            {
                "success": false,
                "question": null,
                "error": {
                    "code": 400,
                    "message": "é”™è¯¯ä¿¡æ¯"
                }
            }
        ],
        "total": 2,
        "success_count": 1,
        "failed_count": 1
    }
    
    æ³¨æ„äº‹é¡¹ï¼š
    - å»ºè®®å•æ¬¡è¯·æ±‚ä¸è¶…è¿‡ 20 ä¸ªé¢˜ç›®
    - æ‰¹é‡å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º 60 ç§’
    - éƒ¨åˆ†é¢˜ç›®å¤±è´¥ä¸å½±å“å…¶ä»–é¢˜ç›®çš„å¤„ç†
    """
    try:
        logger.info("=" * 60)
        logger.info("[API] ========== æ”¶åˆ°æ‰¹é‡é¢˜ç›®åˆ†æè¯·æ±‚ ==========")
        
        # æ‰¹é‡å¤§å°é™åˆ¶
        MAX_BATCH_SIZE = 20
        
        # åˆ¤æ–­è¯·æ±‚æ ¼å¼
        content_type = request.content_type or ''
        is_json = 'application/json' in content_type
        
        results = []
        questions_data = []
        
        if is_json:
            # JSON æ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: application/json")
            data = request.get_json()
            
            if not data or 'questions' not in data:
                logger.warning("[API] âŒ JSONæ ¼å¼é”™è¯¯ï¼šç¼ºå°‘questionså­—æ®µ")
                return jsonify({
                    'error': 'è¯·æ±‚æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘questionså­—æ®µ',
                    'code': 400
                }), 400
            
            questions_list = data.get('questions', [])
            if not isinstance(questions_list, list) or len(questions_list) == 0:
                logger.warning("[API] âŒ questionså¿…é¡»æ˜¯éç©ºæ•°ç»„")
                return jsonify({
                    'error': 'questionså¿…é¡»æ˜¯éç©ºæ•°ç»„',
                    'code': 400
                }), 400
            
            if len(questions_list) > MAX_BATCH_SIZE:
                logger.warning(f"[API] âŒ æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶: {len(questions_list)} > {MAX_BATCH_SIZE}")
                return jsonify({
                    'error': f'æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ{MAX_BATCH_SIZE}ä¸ªé¢˜ç›®',
                    'code': 400
                }), 400
            
            logger.info(f"[API] ğŸ“Š æ‰¹é‡å¤§å°: {len(questions_list)}")
            
            # è§£æJSONæ ¼å¼çš„é¢˜ç›®æ•°æ®
            for idx, q_data in enumerate(questions_list):
                if 'image' not in q_data:
                    logger.warning(f"[API] âš ï¸ é¢˜ç›®{idx+1}ç¼ºå°‘imageå­—æ®µ")
                    results.append({
                        'success': False,
                        'question': None,
                        'error': {
                            'code': 400,
                            'message': f'é¢˜ç›®{idx+1}ç¼ºå°‘imageå­—æ®µ'
                        }
                    })
                    continue
                
                # è§£ç base64å›¾ç‰‡
                try:
                    image_base64 = q_data['image']
                    if not image_base64 or not isinstance(image_base64, str):
                        raise ValueError(f"å›¾ç‰‡æ•°æ®æ— æ•ˆ: type={type(image_base64)}")
                    
                    # ç§»é™¤data:image/xxx;base64,å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    if ',' in image_base64:
                        image_base64 = image_base64.split(',', 1)[1]
                    
                    logger.info(f"[API] ğŸ“· é¢˜ç›®{idx+1}å¼€å§‹è§£ç å›¾ç‰‡ï¼Œbase64é•¿åº¦: {len(image_base64)}")
                    image_data = base64.b64decode(image_base64)
                    logger.info(f"[API] âœ… é¢˜ç›®{idx+1}å›¾ç‰‡è§£ç æˆåŠŸï¼Œå›¾ç‰‡å¤§å°: {len(image_data)} bytes")
                    
                    # åˆ›å»ºæ–‡ä»¶å¯¹è±¡
                    from io import BytesIO
                    image_file = BytesIO(image_data)
                    image_file.name = f'question_{idx+1}.png'  # è®¾ç½®æ–‡ä»¶å
                    
                    questions_data.append({
                        'image_file': image_file,
                        'raw_text': q_data.get('raw_text', '').strip() or None,
                        'question_text': q_data.get('question_text', '').strip() or None,
                        'options': q_data.get('options', []),
                        'question_type': q_data.get('question_type', 'TEXT').strip(),
                        'force_reanalyze': q_data.get('force_reanalyze', False)
                    })
                    logger.info(f"[API] âœ… é¢˜ç›®{idx+1}å·²æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—")
                except Exception as e:
                    logger.error(f"[API] âŒ é¢˜ç›®{idx+1}å›¾ç‰‡è§£ç å¤±è´¥: {e}", exc_info=True)
                    results.append({
                        'success': False,
                        'question': None,
                        'error': {
                            'code': 400,
                            'message': f'å›¾ç‰‡è§£ç å¤±è´¥: {str(e)}'
                        }
                    })
            
            logger.info(f"[API] ğŸ“‹ æˆåŠŸè§£æ {len(questions_data)} ä¸ªé¢˜ç›®æ•°æ®ï¼Œå¤±è´¥ {len(results)} ä¸ª")
        
        else:
            # multipart/form-data æ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: multipart/form-data")
            
            # è·å–å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
            if 'images[]' in request.files:
                image_files = request.files.getlist('images[]')
            elif 'images' in request.files:
                image_files = [request.files['images']]
            else:
                logger.warning("[API] âŒ ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶")
                return jsonify({
                    'error': 'ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶ï¼ˆimages[]æˆ–imagesï¼‰',
                    'code': 400
                }), 400
            
            if len(image_files) == 0 or all(f.filename == '' for f in image_files):
                logger.warning("[API] âŒ å›¾ç‰‡æ–‡ä»¶ä¸ºç©º")
                return jsonify({
                    'error': 'å›¾ç‰‡æ–‡ä»¶ä¸ºç©º',
                    'code': 400
                }), 400
            
            if len(image_files) > MAX_BATCH_SIZE:
                logger.warning(f"[API] âŒ æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶: {len(image_files)} > {MAX_BATCH_SIZE}")
                return jsonify({
                    'error': f'æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ{MAX_BATCH_SIZE}ä¸ªé¢˜ç›®',
                    'code': 400
                }), 400
            
            logger.info(f"[API] ğŸ“Š æ‰¹é‡å¤§å°: {len(image_files)}")
            
            # è·å–å…¶ä»–å‚æ•°ï¼ˆæ•°ç»„æ ¼å¼ï¼‰
            raw_texts_str = request.form.get('raw_texts[]', '[]')
            question_texts_str = request.form.get('question_texts[]', '[]')
            options_array_str = request.form.get('options_array[]', '[]')
            question_types_str = request.form.get('question_types[]', '[]')
            force_reanalyze = request.form.get('force_reanalyze', 'false').lower() == 'true'
            
            # è§£æJSONæ•°ç»„
            try:
                raw_texts = json.loads(raw_texts_str) if raw_texts_str else []
                question_texts = json.loads(question_texts_str) if question_texts_str else []
                options_array = json.loads(options_array_str) if options_array_str else []
                question_types = json.loads(question_types_str) if question_types_str else []
            except json.JSONDecodeError as e:
                logger.warning(f"[API] âš ï¸ æ— æ³•è§£æå‚æ•°JSON: {e}")
                raw_texts = []
                question_texts = []
                options_array = []
                question_types = []
            
            # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            max_len = len(image_files)
            raw_texts = (raw_texts + [''] * max_len)[:max_len]
            question_texts = (question_texts + [''] * max_len)[:max_len]
            options_array = (options_array + [[]] * max_len)[:max_len]
            question_types = (question_types + ['TEXT'] * max_len)[:max_len]
            
            # æ„å»ºé¢˜ç›®æ•°æ®åˆ—è¡¨
            for idx, image_file in enumerate(image_files):
                if image_file.filename == '':
                    continue
                
                questions_data.append({
                    'image_file': image_file,
                    'raw_text': raw_texts[idx].strip() if raw_texts[idx] else None,
                    'question_text': question_texts[idx].strip() if question_texts[idx] else None,
                    'options': options_array[idx] if options_array[idx] else None,
                    'question_type': question_types[idx].strip() if question_types[idx] else 'TEXT',
                    'force_reanalyze': force_reanalyze
                })
        
        # æ‰¹é‡å¤„ç†é¢˜ç›®ï¼ˆå¹¶è¡Œå¤„ç†ä»¥æé«˜æ•ˆç‡ï¼‰
        MAX_WORKERS = 3  # æœ€å¤§å¹¶å‘æ•°ï¼Œé™ä½ä»¥æé«˜ç¨³å®šæ€§ï¼ˆ3ä¸ªå¹¶å‘å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§ï¼‰
        logger.info(f"[API] ğŸ” å¼€å§‹æ‰¹é‡å¤„ç† {len(questions_data)} ä¸ªé¢˜ç›®ï¼ˆå¹¶å‘æ•°: {MAX_WORKERS}ï¼‰...")
        
        def process_single_question(q_data, idx):
            """å¤„ç†å•ä¸ªé¢˜ç›®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
            try:
                logger.info(f"[API] ğŸ“ å¤„ç†é¢˜ç›® {idx+1}/{len(questions_data)}")
                
                # è°ƒç”¨é¢˜ç›®æœåŠ¡
                result = question_service.analyze_question_from_image(
                    image_file=q_data['image_file'],
                    frontend_raw_text=q_data['raw_text'],
                    frontend_question_text=q_data['question_text'],
                    frontend_options=q_data['options'],
                    question_type=q_data['question_type'],
                    force_reanalyze=q_data['force_reanalyze']
                )
                
                logger.info(f"[API] âœ… é¢˜ç›® {idx+1} å¤„ç†æˆåŠŸ")
                return {
                    'success': True,
                    'question': result,
                    'error': None,
                    'index': idx
                }
            except Exception as e:
                logger.error(f"[API] âŒ é¢˜ç›® {idx+1} å¤„ç†å¤±è´¥: {e}", exc_info=True)
                return {
                    'success': False,
                    'question': None,
                    'error': {
                        'code': 500,
                        'message': str(e)
                    },
                    'index': idx
                }
        
        # å¹¶è¡Œå¤„ç†ï¼ˆå¦‚æœåªæœ‰1å¼ å›¾ç‰‡ï¼Œç›´æ¥å¤„ç†ï¼Œé¿å…çº¿ç¨‹å¼€é”€ï¼‰
        if len(questions_data) == 1:
            result = process_single_question(questions_data[0], 0)
            results = [result]
        else:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            results = [None] * len(questions_data)
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_idx = {
                    executor.submit(process_single_question, q_data, idx): idx
                    for idx, q_data in enumerate(questions_data)
                }
                
                # æ”¶é›†ç»“æœï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
                for future in as_completed(future_to_idx):
                    result = future.result()
                    results[result['index']] = result
            
            # ç§»é™¤indexå­—æ®µï¼Œä¿æŒå“åº”æ ¼å¼ä¸€è‡´
            for r in results:
                if 'index' in r:
                    del r['index']
        
        # ç»Ÿè®¡ç»“æœ
        total = len(results)
        success_count = sum(1 for r in results if r['success'])
        failed_count = total - success_count
        
        logger.info(f"[API] âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
        logger.info(f"[API]    - æ€»æ•°: {total}")
        logger.info(f"[API]    - æˆåŠŸ: {success_count}")
        logger.info(f"[API]    - å¤±è´¥: {failed_count}")
        logger.info(f"[API] ==========================================")
        
        return jsonify({
            'results': results,
            'total': total,
            'success_count': success_count,
            'failed_count': failed_count
        })
    
    except Exception as e:
        logger.error(f"[API] âŒ æ‰¹é‡æ¥å£å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/questions/extract/batch', methods=['POST'])
def extract_questions_batch():
    """
    å¿«é€Ÿæ‰¹é‡æå–é¢˜ç›®å’Œé€‰é¡¹æ¥å£ï¼ˆä½¿ç”¨æœ¬åœ°OCR + DeepSeekï¼Œé«˜å¹¶å‘ï¼‰
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨æœ¬åœ°OCRï¼ˆå…è´¹ã€å¿«é€Ÿï¼‰
    - ä½¿ç”¨DeepSeekæå–ï¼ˆè´¹ç”¨æœ€ä½ Â¥0.000117/æ¬¡ï¼Œå‡†ç¡®ç‡1.00ï¼‰
    - é«˜å¹¶å‘å¤„ç†ï¼ˆé»˜è®¤10ä¸ªå¹¶å‘ï¼Œ50é¢˜çº¦2-3åˆ†é’Ÿï¼‰
    - æ¯é“é¢˜ç‹¬ç«‹è¯·æ±‚ï¼ˆé”™è¯¯éš”ç¦»å¥½ï¼‰
    
    è¯·æ±‚æ ¼å¼1ï¼ˆmultipart/form-dataï¼‰ï¼š
    - images[]: å¤šä¸ªå›¾ç‰‡æ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
    - max_workers: å¹¶å‘æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤10ï¼ŒèŒƒå›´3-20ï¼‰
    
    è¯·æ±‚æ ¼å¼2ï¼ˆapplication/jsonï¼‰ï¼š
    {
        "images": [
            {"filename": "image1.jpg", "data": "base64ç¼–ç çš„å›¾ç‰‡æ•°æ®"},
            ...
        ],
        "max_workers": 10  // å¯é€‰ï¼Œé»˜è®¤10
    }
    
    è¿”å›ï¼š
    {
        "success": true,
        "results": [
            {
                "success": true,
                "question_text": "å®Œæ•´çš„é¢˜å¹²å†…å®¹",
                "options": ["A. é€‰é¡¹A", "B. é€‰é¡¹B", "C. é€‰é¡¹C", "D. é€‰é¡¹D"],
                "raw_text": "OCRåŸå§‹æ–‡æœ¬",
                "ocr_time": 6.5,
                "ai_time": 7.2,
                "total_time": 13.7,
                "input_tokens": 345,
                "output_tokens": 197,
                "total_tokens": 542,
                "cost": 0.000117
            }
        ],
        "statistics": {
            "total": 50,
            "success_count": 48,
            "failed_count": 2,
            "total_time": 150.5,
            "avg_time_per_question": 3.14,
            "total_cost": 0.005616
        }
    }
    
    æ€§èƒ½ï¼š
    - å¹¶å‘10ï¼š50é¢˜çº¦2-3åˆ†é’Ÿ
    - å¹¶å‘20ï¼š50é¢˜çº¦1-2åˆ†é’Ÿ
    """
    try:
        logger.info("=" * 60)
        logger.info("[API] ========== æ”¶åˆ°æ‰¹é‡æå–è¯·æ±‚ï¼ˆæœ¬åœ°OCR+DeepSeekï¼‰==========")
        
        # å¯¼å…¥æ‰¹é‡å¤„ç†æœåŠ¡
        from batch_question_service import process_batch_concurrent
        
        # æ‰¹é‡å¤§å°é™åˆ¶
        MAX_BATCH_SIZE = 100
        MAX_WORKERS_DEFAULT = 10
        MAX_WORKERS_MAX = 20
        
        # åˆ¤æ–­è¯·æ±‚æ ¼å¼
        content_type = request.content_type or ''
        is_json = 'application/json' in content_type
        
        logger.info(f"[API] Content-Type: {content_type}")
        
        image_files = []
        
        if is_json:
            # JSONæ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: application/json")
            
            # è§£æJSONæ•°æ®ï¼Œå¤„ç†å¯èƒ½çš„è§£æé”™è¯¯
            try:
                data = request.get_json(force=True)  # force=Trueç¡®ä¿å³ä½¿Content-Typeä¸å¯¹ä¹Ÿå°è¯•è§£æ
                logger.info(f"[API] JSONè§£ææˆåŠŸï¼Œæ•°æ®keys: {list(data.keys()) if isinstance(data, dict) else 'not a dict'}")
            except Exception as e:
                logger.error(f"[API] âŒ JSONè§£æå¤±è´¥: {e}", exc_info=True)
                return jsonify({
                    'success': False,
                    'error': f'JSONæ ¼å¼é”™è¯¯: {str(e)}',
                    'code': 400
                }), 400
            
            if not data:
                logger.error("[API] âŒ è¯·æ±‚ä½“ä¸ºç©ºæˆ–æ— æ³•è§£æä¸ºJSON")
                logger.error(f"[API] è¯·æ±‚æ•°æ®: {request.data[:200] if request.data else 'None'}...")
                return jsonify({
                    'success': False,
                    'error': 'è¯·æ±‚ä½“ä¸ºç©ºæˆ–ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼',
                    'code': 400
                }), 400
            
            if 'images' not in data:
                logger.error(f"[API] âŒ ç¼ºå°‘imageså­—æ®µï¼Œè¯·æ±‚æ•°æ®keys: {list(data.keys()) if isinstance(data, dict) else 'not a dict'}")
                return jsonify({
                    'success': False,
                    'error': 'è¯·æ±‚æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘imageså­—æ®µ',
                    'code': 400
                }), 400
            
            images_data = data.get('images', [])
            
            # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
            logger.info(f"[API] ğŸ“Š images_dataç±»å‹: {type(images_data).__name__}")
            logger.info(f"[API] ğŸ“Š images_dataé•¿åº¦: {len(images_data) if isinstance(images_data, list) else 'N/A'}")
            if isinstance(images_data, list) and len(images_data) > 0:
                logger.info(f"[API] ğŸ“Š ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(images_data[0]).__name__}")
                logger.info(f"[API] ğŸ“Š ç¬¬ä¸€ä¸ªå…ƒç´ keys: {list(images_data[0].keys()) if isinstance(images_data[0], dict) else 'not a dict'}")
                if isinstance(images_data[0], dict):
                    logger.info(f"[API] ğŸ“Š ç¬¬ä¸€ä¸ªå…ƒç´ å†…å®¹é¢„è§ˆ: {str(images_data[0])[:200]}...")
            
            if not isinstance(images_data, list):
                logger.error(f"[API] âŒ imageså­—æ®µä¸æ˜¯æ•°ç»„ç±»å‹: {type(images_data).__name__}")
                return jsonify({
                    'success': False,
                    'error': 'imageså­—æ®µå¿…é¡»æ˜¯æ•°ç»„ç±»å‹',
                    'code': 400
                }), 400
            
            if len(images_data) == 0:
                logger.error("[API] âŒ imagesæ•°ç»„ä¸ºç©º")
                return jsonify({
                    'success': False,
                    'error': 'imagesæ•°ç»„ä¸èƒ½ä¸ºç©º',
                    'code': 400
                }), 400
            
            if len(images_data) > MAX_BATCH_SIZE:
                logger.error(f"[API] âŒ æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶: {len(images_data)} > {MAX_BATCH_SIZE}")
                return jsonify({
                    'success': False,
                    'error': f'æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ{MAX_BATCH_SIZE}ä¸ªé¢˜ç›®',
                    'code': 400
                }), 400
            
            # è§£ç base64å›¾ç‰‡ï¼Œå¹¶æå–å‰ç«¯OCRç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            from io import BytesIO
            frontend_ocr_texts = []  # å‰ç«¯æä¾›çš„OCRç»“æœåˆ—è¡¨
            
            decode_errors = []  # è®°å½•è§£ç é”™è¯¯
            
            for idx, img_data in enumerate(images_data):
                # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                logger.info(f"[API] ğŸ” å¤„ç†å›¾ç‰‡{idx+1}: ç±»å‹={type(img_data).__name__}")
                if isinstance(img_data, dict):
                    logger.info(f"[API] ğŸ” å›¾ç‰‡{idx+1} keys: {list(img_data.keys())}")
                else:
                    logger.warning(f"[API] âš ï¸ å›¾ç‰‡{idx+1}ä¸æ˜¯å­—å…¸ç±»å‹: {type(img_data).__name__}")
                
                if not isinstance(img_data, dict):
                    decode_errors.append(f"å›¾ç‰‡{idx+1}: ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œè€Œæ˜¯{type(img_data).__name__}")
                    continue
                
                if 'data' not in img_data:
                    logger.warning(f"[API] âš ï¸ å›¾ç‰‡{idx+1}ç¼ºå°‘dataå­—æ®µï¼Œç°æœ‰keys: {list(img_data.keys())}")
                    decode_errors.append(f"å›¾ç‰‡{idx+1}: ç¼ºå°‘dataå­—æ®µï¼Œç°æœ‰å­—æ®µ: {list(img_data.keys())}")
                    continue
                
                try:
                    image_base64 = img_data['data']
                    if ',' in image_base64:
                        image_base64 = image_base64.split(',', 1)[1]
                    
                    image_bytes = base64.b64decode(image_base64)
                    
                    # éªŒè¯è§£ç åçš„æ•°æ®æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡
                    if len(image_bytes) == 0:
                        decode_errors.append(f"å›¾ç‰‡{idx+1}: base64è§£ç åæ•°æ®ä¸ºç©º")
                        continue
                    
                    image_file = BytesIO(image_bytes)
                    image_file.name = img_data.get('filename', 'image.jpg')
                    image_files.append(image_file)
                    
                    # æå–å‰ç«¯OCRç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                    frontend_ocr_text = img_data.get('ocr_text', '').strip() if img_data.get('ocr_text') else None
                    frontend_ocr_texts.append(frontend_ocr_text)
                except Exception as e:
                    error_msg = f"å›¾ç‰‡{idx+1}: base64è§£ç å¤±è´¥ - {str(e)}"
                    decode_errors.append(error_msg)
                    logger.warning(f"[API] {error_msg}")
                    continue
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸè§£ç äº†è‡³å°‘ä¸€å¼ å›¾ç‰‡
            if len(image_files) == 0:
                error_detail = "æ‰€æœ‰å›¾ç‰‡è§£ç å¤±è´¥"
                if decode_errors:
                    error_detail += f": {', '.join(decode_errors[:3])}"  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                    if len(decode_errors) > 3:
                        error_detail += f" ç­‰å…±{len(decode_errors)}ä¸ªé”™è¯¯"
                
                logger.error(f"[API] âŒ {error_detail}")
                return jsonify({
                    'success': False,
                    'error': error_detail,
                    'code': 400,
                    'details': decode_errors[:5]  # è¿”å›å‰5ä¸ªé”™è¯¯è¯¦æƒ…
                }), 400
            
            # å¦‚æœæœ‰éƒ¨åˆ†å›¾ç‰‡è§£ç å¤±è´¥ï¼Œè®°å½•è­¦å‘Š
            if len(decode_errors) > 0:
                logger.warning(f"[API] âš ï¸ {len(decode_errors)}å¼ å›¾ç‰‡è§£ç å¤±è´¥ï¼ŒæˆåŠŸè§£ç {len(image_files)}å¼ ")
        
        else:
            # multipart/form-dataæ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: multipart/form-data")
            
            if 'images[]' in request.files:
                image_files = request.files.getlist('images[]')
            elif 'images' in request.files:
                image_files = [request.files['images']]
            else:
                return jsonify({
                    'success': False,
                    'error': 'ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶ï¼ˆimages[]æˆ–imagesï¼‰',
                    'code': 400
                }), 400
            
            # è¿‡æ»¤ç©ºæ–‡ä»¶
            image_files = [f for f in image_files if f.filename]
            
            if len(image_files) == 0:
                return jsonify({
                    'success': False,
                    'error': 'å›¾ç‰‡æ–‡ä»¶ä¸ºç©º',
                    'code': 400
                }), 400
            
            if len(image_files) > MAX_BATCH_SIZE:
                return jsonify({
                    'success': False,
                    'error': f'æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ{MAX_BATCH_SIZE}ä¸ªé¢˜ç›®',
                    'code': 400
                }), 400
            
            # æå–å‰ç«¯OCRç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            frontend_ocr_texts = []
            ocr_texts_str = request.form.get('ocr_texts[]', '[]')
            try:
                ocr_texts_list = json.loads(ocr_texts_str) if ocr_texts_str else []
                # ç¡®ä¿é•¿åº¦ä¸å›¾ç‰‡æ•°é‡ä¸€è‡´
                frontend_ocr_texts = (ocr_texts_list + [None] * len(image_files))[:len(image_files)]
            except:
                frontend_ocr_texts = [None] * len(image_files)
        
        # è·å–å¹¶å‘æ•°
        if is_json:
            max_workers = min(int(data.get('max_workers', MAX_WORKERS_DEFAULT)), MAX_WORKERS_MAX)
        else:
            max_workers_str = request.form.get('max_workers', str(MAX_WORKERS_DEFAULT))
            try:
                max_workers = min(int(max_workers_str), MAX_WORKERS_MAX)
            except:
                max_workers = MAX_WORKERS_DEFAULT
        
        max_workers = max(3, max_workers)  # æœ€å°‘3ä¸ªå¹¶å‘
        
        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿è‡³å°‘æœ‰ä¸€å¼ æœ‰æ•ˆçš„å›¾ç‰‡
        if len(image_files) == 0:
            logger.error("[API] âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ï¼ˆæ‰€æœ‰å›¾ç‰‡è§£ç /è¯»å–å¤±è´¥ï¼‰")
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼å’Œbase64ç¼–ç æ˜¯å¦æ­£ç¡®',
                'code': 400
            }), 400
        
        logger.info(f"[API] ğŸ“Š æ‰¹é‡å¤§å°: {len(image_files)}, å¹¶å‘æ•°: {max_workers}")
        
        # å¤„ç†å‰ç«¯OCRç»“æœåˆ—è¡¨ï¼ˆå¦‚æœJSONæ ¼å¼ï¼Œå·²åœ¨å‰é¢æå–ï¼›å¦‚æœæ˜¯multipartï¼Œä¹Ÿå·²æå–ï¼‰
        if is_json:
            # JSONæ ¼å¼å·²ç»åœ¨å‰é¢æå–äº†frontend_ocr_texts
            pass
        else:
            # multipartæ ¼å¼å·²ç»åœ¨å‰é¢æå–äº†frontend_ocr_texts
            pass
        
        # ç¡®ä¿frontend_ocr_textsä¸image_filesé•¿åº¦ä¸€è‡´
        if 'frontend_ocr_texts' not in locals():
            frontend_ocr_texts = [None] * len(image_files)
        elif len(frontend_ocr_texts) < len(image_files):
            frontend_ocr_texts = frontend_ocr_texts + [None] * (len(image_files) - len(frontend_ocr_texts))
        elif len(frontend_ocr_texts) > len(image_files):
            frontend_ocr_texts = frontend_ocr_texts[:len(image_files)]
        
        if any(ocr for ocr in frontend_ocr_texts if ocr):
            logger.info(f"[API] æ¥æ”¶åˆ° {sum(1 for ocr in frontend_ocr_texts if ocr)} é“é¢˜çš„å‰ç«¯OCRç»“æœ")
        
        # è°ƒç”¨æ‰¹é‡å¤„ç†æœåŠ¡ï¼ˆä¼ é€’ app å‚æ•°ï¼Œè®©æ¯ä¸ªçº¿ç¨‹éƒ½æœ‰è‡ªå·±çš„åº”ç”¨ä¸Šä¸‹æ–‡ï¼‰
        logger.info(f"[API] ğŸš€ å¼€å§‹è°ƒç”¨æ‰¹é‡å¤„ç†æœåŠ¡...")
        logger.info(f"[API]    - å›¾ç‰‡æ•°é‡: {len(image_files)}")
        logger.info(f"[API]    - å¹¶å‘æ•°: {max_workers}")
        logger.info(f"[API]    - appå¯¹è±¡: {app is not None}")
        
        batch_result = process_batch_concurrent(image_files, frontend_ocr_texts=frontend_ocr_texts, max_workers=max_workers, app=app)
        
        logger.info(f"[API] âœ… æ‰¹é‡å¤„ç†æœåŠ¡è°ƒç”¨å®Œæˆ")
        
        # æ ¼å¼åŒ–å“åº”
        logger.info(f"[API] âœ… æ‰¹é‡æå–å®Œæˆ!")
        logger.info(f"[API]    - æ€»æ•°: {batch_result['total']}")
        logger.info(f"[API]    - æˆåŠŸ: {batch_result['success_count']}")
        logger.info(f"[API]    - å¤±è´¥: {batch_result['failed_count']}")
        logger.info(f"[API]    - æ€»è€—æ—¶: {batch_result['total_time']:.1f}ç§’ ({batch_result['total_time']/60:.1f}åˆ†é’Ÿ)")
        logger.info(f"[API]    - æ€»è´¹ç”¨: Â¥{batch_result['total_cost']:.6f}")
        logger.info(f"[API] ==========================================")
        
        return jsonify({
            'success': True,
            'results': batch_result['results'],
            'statistics': {
                'total': batch_result['total'],
                'success_count': batch_result['success_count'],
                'failed_count': batch_result['failed_count'],
                'total_time': batch_result['total_time'],
                'avg_time_per_question': batch_result['avg_time_per_question'],
                'total_cost': batch_result['total_cost']
            }
        })
    
    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        logger.error(f"[API] âŒ æ‰¹é‡æå–æ¥å£å‡ºé”™: {e}")
        logger.error(f"[API] é”™è¯¯å †æ ˆ: {error_traceback}")
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500,
            'traceback': error_traceback if app.debug else None  # ä»…åœ¨debugæ¨¡å¼ä¸‹è¿”å›å †æ ˆä¿¡æ¯
        }), 500


@app.route('/api/questions/extract/batch/async', methods=['POST'])
def extract_questions_batch_async():
    """
    å¼‚æ­¥æ‰¹é‡æå–é¢˜ç›®å’Œé€‰é¡¹æ¥å£ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¤„ç†ï¼‰
    
    ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œé¿å…è¶…æ—¶
    å®¢æˆ·ç«¯éœ€è¦è½®è¯¢æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    
    è¯·æ±‚æ ¼å¼ï¼šä¸åŒæ­¥æ¥å£ç›¸åŒ
    
    è¿”å›ï¼š
    {
        "success": true,
        "task_id": "ä»»åŠ¡ID",
        "message": "ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨å¤„ç†ä¸­"
    }
    """
    try:
        from task_manager import get_task_manager, TaskStatus
        from threading import Thread
        
        logger.info("=" * 60)
        logger.info("[API] ========== æ”¶åˆ°å¼‚æ­¥æ‰¹é‡æå–è¯·æ±‚ ==========")
        
        # å¤ç”¨åŒæ­¥æ¥å£çš„è¯·æ±‚è§£æé€»è¾‘
        from batch_question_service import process_batch_concurrent
        
        # æ‰¹é‡å¤§å°é™åˆ¶
        MAX_BATCH_SIZE = 100
        MAX_WORKERS_DEFAULT = 10
        MAX_WORKERS_MAX = 20
        
        # åˆ¤æ–­è¯·æ±‚æ ¼å¼
        content_type = request.content_type or ''
        is_json = 'application/json' in content_type
        
        logger.info(f"[API] Content-Type: {content_type}")
        
        image_files = []
        
        if is_json:
            # JSONæ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: application/json")
            
            try:
                data = request.get_json(force=True)
                logger.info(f"[API] JSONè§£ææˆåŠŸï¼Œæ•°æ®keys: {list(data.keys()) if isinstance(data, dict) else 'not a dict'}")
            except Exception as e:
                logger.error(f"[API] âŒ JSONè§£æå¤±è´¥: {e}", exc_info=True)
                return jsonify({
                    'success': False,
                    'error': f'JSONæ ¼å¼é”™è¯¯: {str(e)}',
                    'code': 400
                }), 400
            
            if not data or 'images' not in data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æ±‚æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘imageså­—æ®µ',
                    'code': 400
                }), 400
            
            images_data = data.get('images', [])
            
            if not isinstance(images_data, list) or len(images_data) == 0:
                return jsonify({
                    'success': False,
                    'error': 'imagesæ•°ç»„ä¸èƒ½ä¸ºç©º',
                    'code': 400
                }), 400
            
            if len(images_data) > MAX_BATCH_SIZE:
                return jsonify({
                    'success': False,
                    'error': f'æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒ{MAX_BATCH_SIZE}ä¸ªé¢˜ç›®',
                    'code': 400
                }), 400
            
            # è§£ç base64å›¾ç‰‡
            from io import BytesIO
            frontend_ocr_texts = []
            decode_errors = []
            
            for idx, img_data in enumerate(images_data):
                if not isinstance(img_data, dict) or 'data' not in img_data:
                    decode_errors.append(f"å›¾ç‰‡{idx+1}: æ ¼å¼é”™è¯¯")
                    continue
                
                try:
                    image_base64 = img_data['data']
                    if ',' in image_base64:
                        image_base64 = image_base64.split(',', 1)[1]
                    
                    image_bytes = base64.b64decode(image_base64)
                    
                    if len(image_bytes) == 0:
                        decode_errors.append(f"å›¾ç‰‡{idx+1}: base64è§£ç åæ•°æ®ä¸ºç©º")
                        continue
                    
                    image_file = BytesIO(image_bytes)
                    image_file.name = img_data.get('filename', 'image.jpg')
                    image_files.append(image_file)
                    
                    frontend_ocr_text = img_data.get('ocr_text', '').strip() if img_data.get('ocr_text') else None
                    frontend_ocr_texts.append(frontend_ocr_text)
                except Exception as e:
                    decode_errors.append(f"å›¾ç‰‡{idx+1}: base64è§£ç å¤±è´¥ - {str(e)}")
                    continue
            
            if len(image_files) == 0:
                return jsonify({
                    'success': False,
                    'error': 'æ‰€æœ‰å›¾ç‰‡è§£ç å¤±è´¥',
                    'code': 400,
                    'details': decode_errors[:5]
                }), 400
            
            max_workers = min(int(data.get('max_workers', MAX_WORKERS_DEFAULT)), MAX_WORKERS_MAX)
        else:
            # multipart/form-dataæ ¼å¼
            logger.info("[API] ğŸ“¦ è¯·æ±‚æ ¼å¼: multipart/form-data")
            
            if 'images[]' in request.files:
                image_files = request.files.getlist('images[]')
            elif 'images' in request.files:
                image_files = [request.files['images']]
            else:
                return jsonify({
                    'success': False,
                    'error': 'ç¼ºå°‘å›¾ç‰‡æ–‡ä»¶',
                    'code': 400
                }), 400
            
            image_files = [f for f in image_files if f.filename]
            
            if len(image_files) == 0 or len(image_files) > MAX_BATCH_SIZE:
                return jsonify({
                    'success': False,
                    'error': f'å›¾ç‰‡æ•°é‡æ— æ•ˆï¼ˆ0-{MAX_BATCH_SIZE}ï¼‰',
                    'code': 400
                }), 400
            
            # æå–å‰ç«¯OCRç»“æœ
            frontend_ocr_texts = []
            ocr_texts_str = request.form.get('ocr_texts[]', '[]')
            try:
                ocr_texts_list = json.loads(ocr_texts_str) if ocr_texts_str else []
                frontend_ocr_texts = (ocr_texts_list + [None] * len(image_files))[:len(image_files)]
            except:
                frontend_ocr_texts = [None] * len(image_files)
            
            max_workers_str = request.form.get('max_workers', str(MAX_WORKERS_DEFAULT))
            try:
                max_workers = min(int(max_workers_str), MAX_WORKERS_MAX)
            except:
                max_workers = MAX_WORKERS_DEFAULT
        
        max_workers = max(3, max_workers)
        
        # ç¡®ä¿frontend_ocr_textsä¸image_filesé•¿åº¦ä¸€è‡´
        if 'frontend_ocr_texts' not in locals():
            frontend_ocr_texts = [None] * len(image_files)
        elif len(frontend_ocr_texts) < len(image_files):
            frontend_ocr_texts = frontend_ocr_texts + [None] * (len(image_files) - len(frontend_ocr_texts))
        elif len(frontend_ocr_texts) > len(image_files):
            frontend_ocr_texts = frontend_ocr_texts[:len(image_files)]
        
        # åˆ›å»ºä»»åŠ¡
        task_manager = get_task_manager()
        task_params = {
            'image_count': len(image_files),
            'max_workers': max_workers,
            'has_frontend_ocr': any(ocr for ocr in frontend_ocr_texts if ocr)
        }
        task_id = task_manager.create_task('batch_extract', task_params)
        
        # ä¿å­˜å›¾ç‰‡æ–‡ä»¶æ•°æ®åˆ°ä¸´æ—¶ä½ç½®ï¼ˆå› ä¸ºBytesIOå¯¹è±¡æ— æ³•åœ¨çº¿ç¨‹é—´ä¼ é€’ï¼‰
        import tempfile
        temp_files = []
        for idx, img_file in enumerate(image_files):
            img_file.seek(0)
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            temp_file.write(img_file.read())
            temp_file.close()
            temp_files.append(temp_file.name)
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†ä»»åŠ¡
        def process_task():
            import time
            task_start_time = time.time()
            
            try:
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸš€ åå°çº¿ç¨‹å¼€å§‹å¤„ç†ä»»åŠ¡")
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ“Š ä»»åŠ¡å‚æ•°: å›¾ç‰‡æ•°é‡={len(temp_files)}, å¹¶å‘æ•°={max_workers}, å‰ç«¯OCR={any(ocr for ocr in frontend_ocr_texts if ocr)}")
                
                task_manager.update_task_status(task_id, TaskStatus.PROCESSING)
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º PROCESSING")
                
                # é‡æ–°æ‰“å¼€ä¸´æ—¶æ–‡ä»¶
                file_prep_start = time.time()
                from io import BytesIO
                processed_image_files = []
                for idx, temp_path in enumerate(temp_files):
                    with open(temp_path, 'rb') as f:
                        img_data = f.read()
                    img_file = BytesIO(img_data)
                    img_file.name = os.path.basename(temp_path)
                    processed_image_files.append(img_file)
                    logger.debug(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ“„ å·²åŠ è½½å›¾ç‰‡ {idx+1}/{len(temp_files)}: {img_file.name}, å¤§å°={len(img_data)/1024:.1f}KB")
                
                file_prep_time = time.time() - file_prep_start
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] âœ… æ–‡ä»¶å‡†å¤‡å®Œæˆï¼Œè€—æ—¶={file_prep_time:.2f}ç§’")
                
                # æ›´æ–°ä»»åŠ¡è¿›åº¦
                task_manager.update_task_status(task_id, TaskStatus.PROCESSING, progress={
                    'total': len(processed_image_files),
                    'completed': 0,
                    'failed': 0,
                    'current_item': None
                })
                
                # æ‰§è¡Œæ‰¹é‡å¤„ç†
                batch_start_time = time.time()
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ”„ å¼€å§‹æ‰§è¡Œæ‰¹é‡å¤„ç†...")
                
                # å®šä¹‰è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°
                def update_progress(completed, total, failed):
                    try:
                        task_manager.update_task_status(task_id, TaskStatus.PROCESSING, progress={
                            'total': total,
                            'completed': completed,
                            'failed': failed,
                            'current_item': f"å¤„ç†ä¸­: {completed}/{total}"
                        })
                        progress_percent = int((completed / total * 100)) if total > 0 else 0
                        logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ“Š è¿›åº¦æ›´æ–°: {completed}/{total} ({progress_percent}%), å¤±è´¥={failed}")
                    except Exception as e:
                        logger.error(f"[ä»»åŠ¡-{task_id[:8]}] âŒ è¿›åº¦æ›´æ–°å¤±è´¥: {e}", exc_info=True)
                
                batch_result = process_batch_concurrent(
                    processed_image_files, 
                    frontend_ocr_texts=frontend_ocr_texts, 
                    max_workers=max_workers, 
                    app=app,
                    progress_callback=update_progress
                )
                batch_time = time.time() - batch_start_time
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼Œè€—æ—¶={batch_time:.2f}ç§’")
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ“Š å¤„ç†ç»“æœ: æ€»æ•°={batch_result.get('total', 0)}, æˆåŠŸ={batch_result.get('success_count', 0)}, å¤±è´¥={batch_result.get('failed_count', 0)}")
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] â±ï¸  ç»Ÿè®¡: æ€»è€—æ—¶={batch_result.get('total_time', 0):.2f}ç§’, å¹³å‡={batch_result.get('avg_time_per_question', 0):.2f}ç§’/é¢˜, è´¹ç”¨=Â¥{batch_result.get('total_cost', 0):.6f}")
                
                # æ›´æ–°ä»»åŠ¡ä¸ºå®Œæˆ
                task_manager.update_task_status(
                    task_id, 
                    TaskStatus.COMPLETED,
                    result=batch_result,
                    progress={
                        'total': batch_result['total'],
                        'completed': batch_result['success_count'],
                        'failed': batch_result['failed_count'],
                        'current_item': None
                    }
                )
                
                total_task_time = time.time() - task_start_time
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] âœ… å¼‚æ­¥ä»»åŠ¡å®Œæˆï¼Œæ€»è€—æ—¶={total_task_time:.2f}ç§’")
                
            except Exception as e:
                total_task_time = time.time() - task_start_time
                error_type = type(e).__name__
                error_msg = str(e)
                logger.error(f"[ä»»åŠ¡-{task_id[:8]}] âŒ å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {error_type}: {error_msg}, è€—æ—¶={total_task_time:.2f}ç§’", exc_info=True)
                task_manager.update_task_status(
                    task_id,
                    TaskStatus.FAILED,
                    error=str(e)
                )
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                cleanup_start = time.time()
                cleaned_count = 0
                for temp_path in temp_files:
                    try:
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)
                            cleaned_count += 1
                    except Exception as e:
                        logger.warning(f"[ä»»åŠ¡-{task_id[:8]}] âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {temp_path}, é”™è¯¯: {e}")
                
                cleanup_time = time.time() - cleanup_start
                logger.info(f"[ä»»åŠ¡-{task_id[:8]}] ğŸ§¹ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ: æ¸…ç†äº† {cleaned_count}/{len(temp_files)} ä¸ªæ–‡ä»¶, è€—æ—¶={cleanup_time:.2f}ç§’")
        
        # å¯åŠ¨åå°çº¿ç¨‹
        thread = Thread(target=process_task, daemon=True)
        thread.start()
        
        logger.info(f"[API] âœ… å¼‚æ­¥ä»»åŠ¡å·²åˆ›å»º: {task_id}, å›¾ç‰‡æ•°é‡: {len(image_files)}")
        
        return jsonify({
            'success': True,
            'task_id': task_id,
            'message': 'ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨å¤„ç†ä¸­',
            'status_url': f'/api/tasks/{task_id}/status',
            'result_url': f'/api/tasks/{task_id}/result'
        }), 202  # 202 Accepted
        
    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        logger.error(f"[API] âŒ å¼‚æ­¥æ‰¹é‡æå–æ¥å£å‡ºé”™: {e}")
        logger.error(f"[API] é”™è¯¯å †æ ˆ: {error_traceback}")
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/tasks/<task_id>/status', methods=['GET'])
def get_task_status(task_id):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    
    è¿”å›ï¼š
    {
        "success": true,
        "task": {
            "id": "ä»»åŠ¡ID",
            "status": "pending|processing|completed|failed",
            "progress": {
                "total": 10,
                "completed": 5,
                "failed": 0,
                "current_item": null
            },
            "created_at": "2025-12-07T...",
            "started_at": "2025-12-07T...",
            "completed_at": null,
            "total_time": null
        }
    }
    """
    try:
        from task_manager import get_task_manager
        
        task_manager = get_task_manager()
        task_summary = task_manager.get_task_summary(task_id)
        
        if not task_summary:
            logger.warning(f"[API] âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: ä»»åŠ¡ä¸å­˜åœ¨ - {task_id}")
            return jsonify({
                'success': False,
                'error': 'ä»»åŠ¡ä¸å­˜åœ¨',
                'code': 404
            }), 404
        
        # è®°å½•æŸ¥è¯¢æ—¥å¿—ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        progress = task_summary.get('progress', {})
        logger.debug(
            f"[API] ğŸ“Š æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: {task_id[:8]}, "
            f"çŠ¶æ€={task_summary.get('status')}, "
            f"è¿›åº¦={progress.get('completed', 0)}/{progress.get('total', 0)}, "
            f"å¤±è´¥={progress.get('failed', 0)}"
        )
        
        return jsonify({
            'success': True,
            'task': task_summary
        })
        
    except Exception as e:
        logger.error(f"[API] âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/tasks/<task_id>/result', methods=['GET'])
def get_task_result(task_id):
    """
    è·å–ä»»åŠ¡ç»“æœ
    
    è¿”å›ï¼š
    - å¦‚æœä»»åŠ¡å®Œæˆï¼šè¿”å›å®Œæ•´çš„å¤„ç†ç»“æœ
    - å¦‚æœä»»åŠ¡è¿›è¡Œä¸­ï¼šè¿”å›å½“å‰çŠ¶æ€
    - å¦‚æœä»»åŠ¡å¤±è´¥ï¼šè¿”å›é”™è¯¯ä¿¡æ¯
    """
    try:
        from task_manager import get_task_manager, TaskStatus
        
        task_manager = get_task_manager()
        task = task_manager.get_task(task_id)
        
        if not task:
            return jsonify({
                'success': False,
                'error': 'ä»»åŠ¡ä¸å­˜åœ¨',
                'code': 404
            }), 404
        
        if task['status'] == TaskStatus.COMPLETED.value:
            result_data = task['result']
            
            # è®°å½•è¿”å›ç»™å‰ç«¯çš„æ•°æ®ç»“æ„ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if result_data and 'results' in result_data:
                results_count = len(result_data.get('results', []))
                success_count = result_data.get('success_count', 0)
                logger.info(f"[API] ğŸ“¤ è¿”å›ä»»åŠ¡ç»“æœ: ä»»åŠ¡ID={task_id[:8]}, ç»“æœæ•°é‡={results_count}, æˆåŠŸ={success_count}")
                
                # æ£€æŸ¥æ¯é“é¢˜çš„å­—æ®µå®Œæ•´æ€§
                for idx, item in enumerate(result_data.get('results', [])):
                    has_question_text = 'question_text' in item and item.get('question_text')
                    has_options = 'options' in item and isinstance(item.get('options'), list) and len(item.get('options', [])) > 0
                    has_success = 'success' in item
                    
                    logger.debug(
                        f"[API]   é¢˜ç›®#{idx+1}: success={item.get('success', False)}, "
                        f"æœ‰é¢˜ç›®æ–‡æœ¬={has_question_text}, æœ‰é€‰é¡¹={has_options}, "
                        f"é¢˜ç›®ç±»å‹={item.get('question_type', 'N/A')}, "
                        f"åˆæ­¥ç­”æ¡ˆ={item.get('preliminary_answer', 'N/A')}"
                    )
                    
                    if not has_question_text:
                        logger.warning(f"[API] âš ï¸ é¢˜ç›®#{idx+1} ç¼ºå°‘é¢˜ç›®æ–‡æœ¬")
                    if not has_options:
                        logger.warning(f"[API] âš ï¸ é¢˜ç›®#{idx+1} ç¼ºå°‘é€‰é¡¹")
            
            response_data = {
                'success': True,
                'status': 'completed',
                'result': result_data
            }
            
            # è®°å½•è¿”å›æ•°æ®çš„ç®€è¦ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if result_data and 'results' in result_data:
                logger.info(f"[API] âœ… è¿”å›ä»»åŠ¡ç»“æœç»™å‰ç«¯: ä»»åŠ¡ID={task_id[:8]}, åŒ…å« {len(result_data.get('results', []))} é“é¢˜ç»“æœ")
            
            return jsonify(response_data)
        elif task['status'] == TaskStatus.FAILED.value:
            return jsonify({
                'success': False,
                'status': 'failed',
                'error': task.get('error', 'æœªçŸ¥é”™è¯¯'),
                'code': 500
            }), 500
        else:
            # pending æˆ– processing
            return jsonify({
                'success': True,
                'status': task['status'],
                'message': 'ä»»åŠ¡å°šæœªå®Œæˆï¼Œè¯·ç¨åå†è¯•',
                'progress': task['progress']
            }), 202  # 202 Accepted
        
    except Exception as e:
        logger.error(f"[API] âŒ è·å–ä»»åŠ¡ç»“æœå‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/questions/<question_id>/detail', methods=['GET'])
def get_question_detail(question_id):
    """
    è·å–é¢˜ç›®è¯¦æƒ…æ¥å£ï¼ˆè¿”å›ç­”æ¡ˆã€è§£æã€æ ‡ç­¾ç­‰ï¼‰
    
    è¯·æ±‚å‚æ•°ï¼š
    - question_id: é¢˜ç›®IDï¼ˆè·¯å¾„å‚æ•°ï¼‰
    
    è¿”å›ï¼šåŒ…å«ç­”æ¡ˆã€è§£æã€æ ‡ç­¾ç­‰å®Œæ•´è¯¦æƒ…
    """
    try:
        logger.info("=" * 60)
        logger.info(f"[API] ========== è·å–é¢˜ç›®è¯¦æƒ…: {question_id} ==========")
        
        # è°ƒç”¨é¢˜ç›®æœåŠ¡è·å–è¯¦æƒ…
        result = question_service.analyze_question_detail(question_id)
        
        logger.info(f"[API] âœ… é¢˜ç›®è¯¦æƒ…è·å–å®Œæˆ!")
        logger.info(f"[API]    - é¢˜ç›®ID: {result.get('id')}")
        logger.info(f"[API]    - æ­£ç¡®ç­”æ¡ˆ: {result.get('correct_answer')}")
        logger.info(f"[API]    - ç­”æ¡ˆç‰ˆæœ¬æ•°: {len(result.get('answer_versions', []))}")
        logger.info(f"[API]    - æ ‡ç­¾: {result.get('tags')}")
        logger.info(f"[API] ==========================================")
        
        return jsonify(result)
    
    except Exception as e:
        logger.error(f"[API] âŒ æ¥å£å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/upload', methods=['POST'])
def upload_image():
    """
    ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶æ¥å£
    
    è¿”å›ï¼š
    {
        "success": true,
        "data": {
            "image_url": "uploads/xxx.jpg",
            "filename": "xxx.jpg"
        }
    }
    """
    try:
        logger.info("[UPLOAD] æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚")
        app.logger.info("[UPLOAD] æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ è¯·æ±‚")  # åŒæ—¶è¾“å‡ºåˆ°Flaskæ—¥å¿—
        if 'file' not in request.files:
            logger.warning("[UPLOAD] è¯·æ±‚ä¸­æ²¡æœ‰æ–‡ä»¶")
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ–‡ä»¶'
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            logger.warning("[UPLOAD] æ–‡ä»¶åä¸ºç©º")
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åä¸ºç©º'
            }), 400
        
        logger.info(f"[UPLOAD] æ–‡ä»¶å: {file.filename}, å¤§å°: {len(file.read())} bytes")
        file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        
        if file and allowed_file(file.filename):
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            filename = secure_filename(file.filename)
            ext = filename.rsplit('.', 1)[1].lower()
            unique_filename = f"{uuid.uuid4().hex}.{ext}"
            filepath = os.path.join(UPLOAD_FOLDER, unique_filename)
            file.save(filepath)
            
            logger.info(f"[UPLOAD] æ–‡ä»¶ä¿å­˜æˆåŠŸ: {filepath}")
            
            # è¿”å›æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
            image_url = f"file://{os.path.abspath(filepath)}"
            
            return jsonify({
                'success': True,
                'data': {
                    'image_url': image_url,
                    'filename': unique_filename,
                    'path': filepath
                }
            })
        else:
            logger.warning(f"[UPLOAD] ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.filename}")
            return jsonify({
                'success': False,
                'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'
            }), 400
    
    except Exception as e:
        logger.error(f"[UPLOAD] ä¸Šä¼ å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/test', methods=['GET'])
def test_api():
    """
    æµ‹è¯•æ¥å£ - ç”¨äºéªŒè¯å†…ç½‘ç©¿é€æ˜¯å¦å¯ç”¨
    
    è¿”å›ç®€å•çš„JSONå“åº”ï¼ŒåŒ…å«æœåŠ¡çŠ¶æ€å’Œæ—¶é—´æˆ³
    ä¸éœ€è¦æ•°æ®åº“æŸ¥è¯¢ï¼Œå¿«é€Ÿå“åº”
    """
    from datetime import datetime, timedelta
    
    try:
        # è·å–å®¢æˆ·ç«¯IP
        client_ip = request.remote_addr
        if request.headers.get('X-Forwarded-For'):
            client_ip = request.headers.get('X-Forwarded-For').split(',')[0].strip()
        
        # è·å–è¯·æ±‚å¤´ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        user_agent = request.headers.get('User-Agent', 'Unknown')
        
        response_data = {
            'success': True,
            'message': 'æœåŠ¡è¿è¡Œæ­£å¸¸',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'server_time': datetime.now().isoformat(),
            'service': 'å…¬è€ƒé¢˜åº“åˆ†ææœåŠ¡',
            'version': '2.0',
            'status': 'online',
            'client_ip': client_ip,
            'endpoints': {
                'test': '/api/test',
                'version': '/api/version',
                'health': '/api/health',
                'stats': '/api/stats',
                'analyze': '/api/questions/analyze',
                'analyze_batch': '/api/questions/analyze/batch',
                'extract_batch': '/api/questions/extract/batch',
                'extract_batch_async': '/api/questions/extract/batch/async',
                'task_status': '/api/tasks/<task_id>/status',
                'task_result': '/api/tasks/<task_id>/result',
                'detail': '/api/questions/<question_id>/detail',
                'upload': '/api/upload',
                'apk_download': '/api/apk/download',
                'apk_upload': '/api/apk/upload',
                'apk_info': '/api/apk/info',
                'user_stats': '/api/users/stats',
                'user_retention': '/api/users/retention',
                'user_cohort': '/api/users/cohort'
            }
        }
        
        logger.info(f"[API] âœ… æµ‹è¯•æ¥å£è¢«è®¿é—® - å®¢æˆ·ç«¯IP: {client_ip}")
        
        return jsonify(response_data)
    
    except Exception as e:
        logger.error(f"[API] âŒ æµ‹è¯•æ¥å£å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/version', methods=['GET'])
def get_version():
    """
    è·å–åº”ç”¨ç‰ˆæœ¬ä¿¡æ¯æ¥å£
    
    è¿”å›åº”ç”¨ç‰ˆæœ¬ã€APIç‰ˆæœ¬ã€æ„å»ºä¿¡æ¯ç­‰
    ç”¨äºå‰ç«¯æ£€æŸ¥åç«¯ç‰ˆæœ¬å…¼å®¹æ€§
    
    è¯·æ±‚å‚æ•°ï¼ˆå¯é€‰ï¼‰ï¼š
    - client_version: å®¢æˆ·ç«¯ç‰ˆæœ¬å·ï¼ˆå¦‚ "1.0.0"ï¼‰
    
    è¿”å›ï¼š
    {
        "success": true,
        "version": {
            "app_version": "2.0.0",
            "api_version": "2.0",
            "build_time": "2025-01-07T12:00:00",
            "git_commit": "abc123..." (å¦‚æœæœ‰),
            "git_branch": "main" (å¦‚æœæœ‰),
            "python_version": "3.11.0",
            "flask_version": "3.0.0"
        },
        "update": {
            "required": true/false,  // æ˜¯å¦éœ€è¦æ›´æ–°
            "latest_version": "2.0.0",  // æœ€æ–°ç‰ˆæœ¬
            "download_url": "/api/apk/download",  // APKä¸‹è½½é“¾æ¥
            "release_notes": "æ›´æ–°è¯´æ˜"  // æ›´æ–°è¯´æ˜
        },
        "service": "å…¬è€ƒé¢˜åº“åˆ†ææœåŠ¡",
        "status": "online"
    }
    """
    import sys
    import platform
    from datetime import datetime, timedelta
    
    try:
        # è·å–åº”ç”¨ç‰ˆæœ¬
        app_version = "2.0.0"
        api_version = "2.0"
        
        # è·å–å®¢æˆ·ç«¯ç‰ˆæœ¬ï¼ˆå¦‚æœæä¾›ï¼‰
        client_version = request.args.get('client_version', '')
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        update_info = _check_version_update(client_version, app_version)
        
        # è·å–Pythonç‰ˆæœ¬
        python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        
        # è·å–Flaskç‰ˆæœ¬
        try:
            import flask
            flask_version = flask.__version__
        except:
            flask_version = "unknown"
        
        # è·å–Gitä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        git_info = {}
        try:
            import subprocess
            import os
            
            # æ£€æŸ¥æ˜¯å¦åœ¨Gitä»“åº“ä¸­
            if os.path.exists('.git'):
                try:
                    # è·å–Git commit hash
                    commit_hash = subprocess.check_output(
                        ['git', 'rev-parse', '--short', 'HEAD'],
                        stderr=subprocess.DEVNULL
                    ).decode('utf-8').strip()
                    git_info['commit'] = commit_hash
                except:
                    pass
                
                try:
                    # è·å–Gitåˆ†æ”¯
                    branch = subprocess.check_output(
                        ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],
                        stderr=subprocess.DEVNULL
                    ).decode('utf-8').strip()
                    git_info['branch'] = branch
                except:
                    pass
                
                try:
                    # è·å–æœ€åæäº¤æ—¶é—´
                    commit_time = subprocess.check_output(
                        ['git', 'log', '-1', '--format=%ci'],
                        stderr=subprocess.DEVNULL
                    ).decode('utf-8').strip()
                    git_info['last_commit_time'] = commit_time
                except:
                    pass
        except:
            pass
        
        # æ„å»ºç‰ˆæœ¬ä¿¡æ¯
        version_info = {
            'app_version': app_version,
            'api_version': api_version,
            'build_time': datetime.now().isoformat(),
            'python_version': python_version,
            'flask_version': flask_version,
            'platform': platform.system(),
            'platform_version': platform.version()
        }
        
        # æ·»åŠ Gitä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if git_info:
            version_info.update(git_info)
        
        response_data = {
            'success': True,
            'version': version_info,
            'update': update_info,
            'service': 'å…¬è€ƒé¢˜åº“åˆ†ææœåŠ¡',
            'status': 'online',
            'timestamp': datetime.now().isoformat()
        }
        
        if client_version:
            logger.info(f"[API] ğŸ“¦ ç‰ˆæœ¬æ£€æŸ¥ - å®¢æˆ·ç«¯: {client_version}, æœåŠ¡ç«¯: {app_version}, éœ€è¦æ›´æ–°: {update_info['required']}")
        else:
            logger.info(f"[API] ğŸ“¦ ç‰ˆæœ¬ä¿¡æ¯æŸ¥è¯¢ - ç‰ˆæœ¬: {app_version}, API: {api_version}")
        
        # è‡ªåŠ¨è¿½è¸ªç”¨æˆ·æ´»åŠ¨ï¼ˆä»…åœ¨ç‰ˆæœ¬éªŒè¯æ—¶è®°å½•ï¼‰
        try:
            device_id = request.headers.get('X-Device-ID') or request.args.get('device_id')
            app_version_param = request.headers.get('X-App-Version') or request.args.get('app_version') or client_version
            
            if device_id:
                device_id = user_statistics_service.get_or_create_device_id(device_id)
                
                # è·å–è®¾å¤‡ä¿¡æ¯
                device_info = {
                    'user_agent': request.headers.get('User-Agent', ''),
                    'ip': request.remote_addr,
                    'platform': platform.system()
                }
                
                # è®°å½•ç”¨æˆ·æ´»åŠ¨ï¼ˆç‰ˆæœ¬æ£€æŸ¥é€šå¸¸è¡¨ç¤ºç”¨æˆ·æ‰“å¼€åº”ç”¨ï¼‰
                user_statistics_service.track_user_activity(
                    device_id=device_id,
                    device_info=device_info,
                    app_version=app_version_param,
                    question_count=0  # ç‰ˆæœ¬æ£€æŸ¥ä¸æ¶‰åŠé¢˜ç›®åˆ†æ
                )
                logger.info(f"[API] ğŸ“Š ç”¨æˆ·æ´»åŠ¨å·²è®°å½•: {device_id}")
        except Exception as e:
            logger.warning(f"[API] ç”¨æˆ·æ´»åŠ¨è¿½è¸ªå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        
        return jsonify(response_data)
    
    except Exception as e:
        logger.error(f"[API] âŒ è·å–ç‰ˆæœ¬ä¿¡æ¯å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'version': {
                'app_version': '2.0.0',
                'api_version': '2.0',
                'status': 'error'
            },
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/apk/download', methods=['GET'])
def download_apk():
    """
    APKä¸‹è½½æ¥å£
    
    è¿”å›æœ€æ–°çš„APKæ–‡ä»¶
    
    è¿”å›ï¼š
    - å¦‚æœAPKå­˜åœ¨ï¼šè¿”å›APKæ–‡ä»¶
    - å¦‚æœAPKä¸å­˜åœ¨ï¼šè¿”å›404é”™è¯¯
    """
    import json
    from flask import send_file, abort
    
    try:
        # è¯»å–APKç‰ˆæœ¬ä¿¡æ¯
        apk_info = {}
        apk_filename = None
        
        if os.path.exists(APK_VERSION_FILE):
            try:
                with open(APK_VERSION_FILE, 'r', encoding='utf-8') as f:
                    apk_info = json.load(f)
                    apk_filename = apk_info.get('filename')
            except Exception as e:
                logger.error(f"[API] âŒ è¯»å–APKç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œå°è¯•æŸ¥æ‰¾apkæ–‡ä»¶å¤¹ä¸­çš„ç¬¬ä¸€ä¸ª.apkæ–‡ä»¶
        if not apk_filename:
            apk_files = [f for f in os.listdir(APK_FOLDER) if f.endswith('.apk')]
            if apk_files:
                apk_filename = apk_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„APKæ–‡ä»¶
                logger.info(f"[API] è‡ªåŠ¨æ‰¾åˆ°APKæ–‡ä»¶: {apk_filename}")
        
        if not apk_filename:
            logger.warning("[API] âŒ æœªæ‰¾åˆ°APKæ–‡ä»¶")
            return jsonify({
                'success': False,
                'error': 'APKæ–‡ä»¶ä¸å­˜åœ¨',
                'code': 404
            }), 404
        
        apk_path = os.path.join(APK_FOLDER, apk_filename)
        
        if not os.path.exists(apk_path):
            logger.warning(f"[API] âŒ APKæ–‡ä»¶ä¸å­˜åœ¨: {apk_path}")
            return jsonify({
                'success': False,
                'error': 'APKæ–‡ä»¶ä¸å­˜åœ¨',
                'code': 404
            }), 404
        
        logger.info(f"[API] ğŸ“¥ APKä¸‹è½½è¯·æ±‚: {apk_filename}")
        
        # è¿”å›APKæ–‡ä»¶
        return send_file(
            apk_path,
            mimetype='application/vnd.android.package-archive',
            as_attachment=True,
            download_name=apk_filename
        )
    
    except Exception as e:
        logger.error(f"[API] âŒ APKä¸‹è½½å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/apk/upload', methods=['POST'])
def upload_apk():
    """
    APKä¸Šä¼ æ¥å£ï¼ˆç®¡ç†å‘˜ç”¨ï¼‰
    
    ä¸Šä¼ æ–°çš„APKæ–‡ä»¶å¹¶æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
    
    è¯·æ±‚å‚æ•°ï¼ˆmultipart/form-dataï¼‰ï¼š
    - file: APKæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
    - version: ç‰ˆæœ¬å·ï¼ˆå¦‚ "2.0.0"ï¼‰ï¼ˆå¿…éœ€ï¼‰
    - release_notes: æ›´æ–°è¯´æ˜ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›ï¼š
    {
        "success": true,
        "message": "APKä¸Šä¼ æˆåŠŸ",
        "version": "2.0.0",
        "filename": "app-v2.0.0.apk"
    }
    """
    import json
    from datetime import datetime, timedelta
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ–‡ä»¶',
                'code': 400
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åä¸ºç©º',
                'code': 400
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if not file.filename.lower().endswith('.apk'):
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶å¿…é¡»æ˜¯APKæ ¼å¼',
                'code': 400
            }), 400
        
        # è·å–ç‰ˆæœ¬å·å’Œæ›´æ–°è¯´æ˜
        version = request.form.get('version', '').strip()
        if not version:
            return jsonify({
                'success': False,
                'error': 'ç‰ˆæœ¬å·ä¸èƒ½ä¸ºç©º',
                'code': 400
            }), 400
        
        release_notes = request.form.get('release_notes', '').strip()
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_filename = secure_filename(file.filename)
        # å¦‚æœæ–‡ä»¶åä¸åŒ…å«ç‰ˆæœ¬å·ï¼Œæ·»åŠ ç‰ˆæœ¬å·
        if version not in safe_filename:
            name, ext = os.path.splitext(safe_filename)
            safe_filename = f"{name}-v{version}{ext}"
        
        apk_path = os.path.join(APK_FOLDER, safe_filename)
        
        # ä¿å­˜APKæ–‡ä»¶
        file.save(apk_path)
        logger.info(f"[API] âœ… APKæ–‡ä»¶å·²ä¿å­˜: {apk_path}")
        
        # æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯æ–‡ä»¶
        apk_info = {
            'version': version,
            'filename': safe_filename,
            'release_notes': release_notes,
            'upload_time': datetime.now().isoformat(),
            'file_size': os.path.getsize(apk_path)
        }
        
        with open(APK_VERSION_FILE, 'w', encoding='utf-8') as f:
            json.dump(apk_info, f, indent=2, ensure_ascii=False)
        
        logger.info(f"[API] âœ… APKç‰ˆæœ¬ä¿¡æ¯å·²æ›´æ–°: {version}")
        
        return jsonify({
            'success': True,
            'message': 'APKä¸Šä¼ æˆåŠŸ',
            'version': version,
            'filename': safe_filename,
            'file_size': apk_info['file_size']
        })
    
    except Exception as e:
        logger.error(f"[API] âŒ APKä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/apk/info', methods=['GET'])
def get_apk_info():
    """
    è·å–APKä¿¡æ¯æ¥å£
    
    è¿”å›å½“å‰APKçš„ç‰ˆæœ¬ä¿¡æ¯å’Œä¸‹è½½é“¾æ¥
    
    è¿”å›ï¼š
    {
        "success": true,
        "apk": {
            "version": "2.0.0",
            "filename": "app-v2.0.0.apk",
            "release_notes": "æ›´æ–°è¯´æ˜",
            "upload_time": "2025-01-07T12:00:00",
            "file_size": 12345678,
            "download_url": "/api/apk/download"
        }
    }
    """
    import json
    
    try:
        apk_info = {}
        
        if os.path.exists(APK_VERSION_FILE):
            try:
                with open(APK_VERSION_FILE, 'r', encoding='utf-8') as f:
                    apk_info = json.load(f)
            except Exception as e:
                logger.error(f"[API] âŒ è¯»å–APKä¿¡æ¯å¤±è´¥: {e}")
        
        if not apk_info:
            return jsonify({
                'success': False,
                'error': 'APKä¿¡æ¯ä¸å­˜åœ¨',
                'code': 404
            }), 404
        
        # æ·»åŠ ä¸‹è½½é“¾æ¥
        apk_info['download_url'] = '/api/apk/download'
        
        return jsonify({
            'success': True,
            'apk': apk_info
        })
    
    except Exception as e:
        logger.error(f"[API] âŒ è·å–APKä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e),
            'code': 500
        }), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£ - ç”¨äºç›‘æ§æœåŠ¡çŠ¶æ€
    
    è¿”å›æœåŠ¡å¥åº·çŠ¶æ€ï¼ŒåŒ…æ‹¬æ•°æ®åº“è¿æ¥çŠ¶æ€
    """
    from datetime import datetime, timedelta
    
    try:
        health_status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'service': 'å…¬è€ƒé¢˜åº“åˆ†ææœåŠ¡',
            'checks': {}
        }
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        try:
            with app.app_context():
                # é¦–å…ˆæ£€æŸ¥å½“å‰é…ç½®çš„æ•°æ®åº“URL
                current_db_url = app.config.get('SQLALCHEMY_DATABASE_URI', '')
                current_db_type = 'unknown'
                if 'sqlite' in current_db_url.lower():
                    current_db_type = 'sqlite'
                elif 'postgres' in current_db_url.lower():
                    current_db_type = 'postgresql'
                elif 'mysql' in current_db_url.lower():
                    current_db_type = 'mysql'
                
                # å¦‚æœå½“å‰é…ç½®æ˜¯SQLiteï¼Œç›´æ¥å°è¯•SQLiteè¿æ¥ï¼ˆç»•è¿‡å¯èƒ½æœ‰é—®é¢˜çš„engineï¼‰
                if 'sqlite' in current_db_url.lower():
                    try:
                        sqlite_url = 'sqlite:///gongkao_test.db'
                        from sqlalchemy import create_engine
                        test_engine = create_engine(sqlite_url, echo=False)
                        with test_engine.connect() as conn:
                            pass
                        health_status['checks']['database'] = {
                            'status': 'connected',
                            'type': 'sqlite'
                        }
                    except Exception as sqlite_error:
                        health_status['checks']['database'] = {
                            'status': 'disconnected',
                            'error': f'SQLiteè¿æ¥å¤±è´¥: {str(sqlite_error)[:100]}',
                            'type': 'sqlite'
                        }
                        health_status['status'] = 'degraded'
                else:
                    # å¯¹äºéSQLiteæ•°æ®åº“ï¼Œå°è¯•ä½¿ç”¨db.engineè¿æ¥
                    try:
                        db.engine.connect()
                        health_status['checks']['database'] = {
                            'status': 'connected',
                            'type': current_db_type or database_type or 'unknown'
                        }
                    except Exception as db_error:
                        # æ‰€æœ‰æ•°æ®åº“è¿æ¥é”™è¯¯
                        error_msg = str(db_error)
                        error_type = type(db_error).__name__
                        
                        # æ£€æµ‹æ˜¯å¦æ˜¯ç¼–ç é”™è¯¯
                        is_encoding_error = (
                            isinstance(db_error, (UnicodeDecodeError, UnicodeEncodeError)) or
                            'codec' in error_msg.lower() or 
                            'decode' in error_msg.lower() or 
                            'utf-8' in error_msg.lower() or
                            'invalid start byte' in error_msg.lower()
                        )
                        
                        if is_encoding_error:
                            # ç¼–ç é”™è¯¯ï¼Œå°è¯•SQLiteè¿æ¥
                            logger.warning(f"[API] æ•°æ®åº“è¿æ¥ç¼–ç é”™è¯¯: {error_type}ï¼Œå°è¯•SQLite")
                            try:
                                sqlite_url = 'sqlite:///gongkao_test.db'
                                from sqlalchemy import create_engine
                                test_engine = create_engine(sqlite_url, echo=False)
                                with test_engine.connect() as conn:
                                    pass
                                health_status['checks']['database'] = {
                                    'status': 'degraded',
                                    'type': 'sqlite',
                                    'note': 'ä¸»æ•°æ®åº“é…ç½®æœ‰ç¼–ç é”™è¯¯ï¼Œå·²å›é€€åˆ°SQLite'
                                }
                            except Exception:
                                health_status['checks']['database'] = {
                                    'status': 'disconnected',
                                    'error': 'æ•°æ®åº“é…ç½®ç¼–ç é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„DATABASE_URLé…ç½®æˆ–åˆ é™¤è¯¥é…ç½®ä½¿ç”¨SQLite',
                                    'type': current_db_type or database_type or 'unknown'
                                }
                        else:
                            # å…¶ä»–æ•°æ®åº“è¿æ¥é”™è¯¯
                            health_status['checks']['database'] = {
                                'status': 'disconnected',
                                'error': error_msg[:150] if len(error_msg) > 150 else error_msg,
                                'type': current_db_type or database_type or 'unknown'
                            }
                        health_status['status'] = 'degraded'
        except Exception as outer_error:
            # å¤–å±‚å¼‚å¸¸ï¼ˆå¯èƒ½æ˜¯ç¼–ç é”™è¯¯å‘ç”Ÿåœ¨engineåˆ›å»ºæ—¶ï¼‰
            error_msg = str(outer_error)
            is_encoding_error = (
                isinstance(outer_error, (UnicodeDecodeError, UnicodeEncodeError)) or
                'codec' in error_msg.lower() or 
                'decode' in error_msg.lower() or 
                'utf-8' in error_msg.lower()
            )
            
            if is_encoding_error:
                logger.warning(f"[API] æ•°æ®åº“åˆå§‹åŒ–ç¼–ç é”™è¯¯: {type(outer_error).__name__}")
                health_status['checks']['database'] = {
                    'status': 'disconnected',
                    'error': 'æ•°æ®åº“é…ç½®ç¼–ç é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„DATABASE_URLé…ç½®',
                    'type': database_type or 'unknown'
                }
            else:
                health_status['checks']['database'] = {
                    'status': 'disconnected',
                    'error': 'æ•°æ®åº“è¿æ¥å¼‚å¸¸',
                    'type': database_type or 'unknown'
                }
            health_status['status'] = 'degraded'
        
        # æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ ç›®å½•
        try:
            if os.path.exists(UPLOAD_FOLDER) and os.path.isdir(UPLOAD_FOLDER):
                health_status['checks']['upload_folder'] = {
                    'status': 'available',
                    'path': UPLOAD_FOLDER
                }
            else:
                health_status['checks']['upload_folder'] = {
                    'status': 'missing',
                    'path': UPLOAD_FOLDER
                }
                health_status['status'] = 'degraded'
        except Exception as folder_error:
            health_status['checks']['upload_folder'] = {
                'status': 'error',
                'error': str(folder_error)
            }
        
        # æ£€æŸ¥OCRæœåŠ¡çŠ¶æ€
        try:
            from ocr_service import get_ocr_service
            ocr_service = get_ocr_service()
            
            if ocr_service and ocr_service.ocr_engine:
                engine_name = "æœªçŸ¥"
                if hasattr(ocr_service.ocr_engine, 'ocr'):
                    engine_name = "PaddleOCR"
                elif ocr_service.ocr_engine == 'tesseract':
                    engine_name = "Tesseract"
                
                health_status['checks']['ocr_service'] = {
                    'status': 'loaded',
                    'engine': engine_name,
                    'note': 'OCRæœåŠ¡å·²åŠ è½½ï¼Œå¯ä»¥ç«‹å³ä½¿ç”¨'
                }
            else:
                health_status['checks']['ocr_service'] = {
                    'status': 'not_loaded',
                    'note': 'OCRæœåŠ¡æœªåŠ è½½ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åˆå§‹åŒ–'
                }
                health_status['status'] = 'degraded'
        except Exception as ocr_error:
            health_status['checks']['ocr_service'] = {
                'status': 'error',
                'error': str(ocr_error)[:100]
            }
        
        logger.info(f"[API] ğŸ¥ å¥åº·æ£€æŸ¥ - çŠ¶æ€: {health_status['status']}")
        
        # å¦‚æœæ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼Œè¿”å›200ï¼Œå¦åˆ™è¿”å›503
        status_code = 200 if health_status['status'] == 'healthy' else 503
        
        return jsonify(health_status), status_code
    
    except Exception as e:
        logger.error(f"[API] âŒ å¥åº·æ£€æŸ¥å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/stats', methods=['GET'])
def get_stats():
    """
    è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆé¢˜ç›®å’Œç­”æ¡ˆç‰ˆæœ¬ï¼‰
    """
    try:
        logger.info("[API] ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯...")
        question_count = Question.query.count()
        answer_version_count = AnswerVersion.query.count()
        
        logger.info(f"[API]    - é¢˜ç›®æ•°: {question_count}")
        logger.info(f"[API]    - ç­”æ¡ˆç‰ˆæœ¬æ•°: {answer_version_count}")
        
        return jsonify({
            'success': True,
            'data': {
                'questions': question_count,
                'answer_versions': answer_version_count
            }
        })
    except Exception as e:
        logger.error(f"[API] âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/users/stats', methods=['GET'])
def get_user_statistics():
    """
    è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ®ï¼ˆç•™å­˜ç‡ã€DAUç­‰ï¼‰
    
    è¯·æ±‚å‚æ•°ï¼ˆå¯é€‰ï¼‰:
    - days: ç»Ÿè®¡æœ€è¿‘å¤šå°‘å¤©ï¼ˆé»˜è®¤30å¤©ï¼‰
    
    è¿”å›ï¼š
    {
        "success": true,
        "data": {
            "total_users": 1000,
            "active_users": 500,
            "new_users": 50,
            "avg_dau": 200.5,
            "daily_active_users": [...]
        }
    }
    """
    try:
        days = int(request.args.get('days', 30))
        days = max(1, min(days, 365))  # é™åˆ¶åœ¨1-365å¤©ä¹‹é—´
        
        logger.info(f"[API] ğŸ“Š è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")
        
        stats = user_statistics_service.get_user_statistics(days=days)
        
        if 'error' in stats:
            return jsonify({
                'success': False,
                'error': stats['error']
            }), 500
        
        logger.info(f"[API]    - æ€»ç”¨æˆ·æ•°: {stats.get('total_users', 0)}")
        logger.info(f"[API]    - æ´»è·ƒç”¨æˆ·æ•°: {stats.get('active_users', 0)}")
        logger.info(f"[API]    - æ–°å¢ç”¨æˆ·æ•°: {stats.get('new_users', 0)}")
        
        return jsonify({
            'success': True,
            'data': stats
        })
    except Exception as e:
        logger.error(f"[API] âŒ è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ®å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/users/retention', methods=['GET'])
def get_retention_rate():
    """
    è·å–ç•™å­˜ç‡æ•°æ®
    
    è¯·æ±‚å‚æ•°ï¼ˆå¯é€‰ï¼‰:
    - start_date: èµ·å§‹æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤ï¼š7å¤©å‰ï¼‰
    - days: è®¡ç®—å¤šå°‘å¤©çš„ç•™å­˜ç‡ï¼ˆé»˜è®¤7å¤©ï¼‰
    
    è¿”å›ï¼š
    {
        "success": true,
        "data": {
            "start_date": "2025-01-01",
            "new_users": 100,
            "retention_data": [
                {
                    "day": 0,
                    "date": "2025-01-01",
                    "retained_users": 100,
                    "retention_rate": 100.0
                },
                ...
            ]
        }
    }
    """
    try:
        from datetime import datetime as dt, date, timedelta
        
        start_date_str = request.args.get('start_date')
        if start_date_str:
            start_date = dt.strptime(start_date_str, '%Y-%m-%d').date()
        else:
            days = int(request.args.get('days', 7))
            start_date = date.today() - timedelta(days=days)
        
        days = int(request.args.get('days', 7))
        days = max(1, min(days, 90))  # é™åˆ¶åœ¨1-90å¤©ä¹‹é—´
        
        logger.info(f"[API] ğŸ“Š è®¡ç®—ç•™å­˜ç‡ï¼ˆèµ·å§‹æ—¥æœŸ: {start_date}, è¿½è¸ª{days}å¤©ï¼‰...")
        
        retention_data = user_statistics_service.calculate_retention_rate(
            start_date=start_date,
            days=days
        )
        
        if 'error' in retention_data:
            return jsonify({
                'success': False,
                'error': retention_data['error']
            }), 500
        
        logger.info(f"[API]    - æ–°å¢ç”¨æˆ·æ•°: {retention_data.get('new_users', 0)}")
        
        return jsonify({
            'success': True,
            'data': retention_data
        })
    except ValueError as e:
        logger.error(f"[API] âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'error': f'æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼: {str(e)}'
        }), 400
    except Exception as e:
        logger.error(f"[API] âŒ è®¡ç®—ç•™å­˜ç‡å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/users/cohort', methods=['GET'])
def get_cohort_retention():
    """
    è·å–Cohortç•™å­˜ç‡ï¼ˆæŒ‰é¦–æ¬¡ä½¿ç”¨æ—¥æœŸåˆ†ç»„ï¼‰
    
    è¯·æ±‚å‚æ•°ï¼ˆå¯é€‰ï¼‰:
    - cohort_days: è®¡ç®—å¤šå°‘å¤©çš„cohortï¼ˆé»˜è®¤7å¤©ï¼‰
    - retention_days: è¿½è¸ªå¤šå°‘å¤©çš„ç•™å­˜ï¼ˆé»˜è®¤30å¤©ï¼‰
    
    è¿”å›ï¼š
    {
        "success": true,
        "data": {
            "cohorts": [
                {
                    "cohort_date": "2025-01-01",
                    "new_users": 100,
                    "retention_data": [...]
                },
                ...
            ]
        }
    }
    """
    try:
        cohort_days = int(request.args.get('cohort_days', 7))
        retention_days = int(request.args.get('retention_days', 30))
        
        cohort_days = max(1, min(cohort_days, 30))  # é™åˆ¶åœ¨1-30å¤©
        retention_days = max(1, min(retention_days, 90))  # é™åˆ¶åœ¨1-90å¤©
        
        logger.info(f"[API] ğŸ“Š è®¡ç®—Cohortç•™å­˜ç‡ï¼ˆcohort_days: {cohort_days}, retention_days: {retention_days}ï¼‰...")
        
        cohort_data = user_statistics_service.get_cohort_retention(
            cohort_days=cohort_days,
            retention_days=retention_days
        )
        
        if 'error' in cohort_data:
            return jsonify({
                'success': False,
                'error': cohort_data['error']
            }), 500
        
        logger.info(f"[API]    - Cohortæ•°é‡: {len(cohort_data.get('cohorts', []))}")
        
        return jsonify({
            'success': True,
            'data': cohort_data
        })
    except Exception as e:
        logger.error(f"[API] âŒ è®¡ç®—Cohortç•™å­˜ç‡å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/clear', methods=['POST'])
def clear_database():
    """
    æ¸…ç†æ•°æ®åº“æ¥å£ï¼ˆå±é™©æ“ä½œï¼Œå»ºè®®æ·»åŠ è®¤è¯ï¼‰
    
    è¯·æ±‚ä½“ï¼ˆå¯é€‰ï¼‰:
    {
        "clear_type": "all"  // "all"æ¸…ç©ºæ‰€æœ‰, "answers"åªæ¸…ç©ºç­”æ¡ˆç‰ˆæœ¬
    }
    """
    try:
        data = request.get_json() or {}
        clear_type = data.get('clear_type', 'all')
        
        if clear_type == 'answers':
            # åªæ¸…ç©ºç­”æ¡ˆç‰ˆæœ¬
            count = AnswerVersion.query.count()
            AnswerVersion.query.delete()
            db.session.commit()
            logger.warning(f"[API] æ¸…ç©ºç­”æ¡ˆç‰ˆæœ¬è®°å½•: {count} æ¡")
            return jsonify({
                'success': True,
                'message': f'å·²æ¸…ç©º {count} æ¡ç­”æ¡ˆç‰ˆæœ¬è®°å½•',
                'cleared': count
            })
        else:
            # æ¸…ç©ºæ‰€æœ‰ï¼ˆç­”æ¡ˆç‰ˆæœ¬ä¼šè‡ªåŠ¨çº§è”åˆ é™¤ï¼‰
            answer_count = AnswerVersion.query.count()
            question_count = Question.query.count()
            AnswerVersion.query.delete()
            Question.query.delete()
            db.session.commit()
            logger.warning(f"[API] æ¸…ç©ºæ‰€æœ‰æ•°æ®: é¢˜ç›® {question_count} æ¡, ç­”æ¡ˆç‰ˆæœ¬ {answer_count} æ¡")
            return jsonify({
                'success': True,
                'message': f'å·²æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ˆé¢˜ç›® {question_count} æ¡, ç­”æ¡ˆç‰ˆæœ¬ {answer_count} æ¡ï¼‰',
                'cleared': {
                    'questions': question_count,
                    'answer_versions': answer_count
                }
            })
    
    except Exception as e:
        db.session.rollback()
        logger.error(f"[API] æ¸…ç†æ•°æ®åº“å‡ºé”™: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


if __name__ == '__main__':
    with app.app_context():
        try:
            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            db.engine.connect()
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
            
            # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            db.create_all()
            logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ªï¼")
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            from sqlalchemy import inspect
            inspector = inspect(db.engine)
            tables = inspector.get_table_names()
            logger.info(f"ğŸ“Š æ•°æ®åº“è¡¨: {', '.join(tables)}")
            
        except (UnicodeDecodeError, UnicodeEncodeError) as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥ç¼–ç é”™è¯¯ï¼š{e}")
            # å¦‚æœæ˜¯ç¼–ç é”™è¯¯ï¼Œå®Œå…¨æ¸…é™¤æœ‰é—®é¢˜çš„ç¯å¢ƒå˜é‡
            if 'DATABASE_URL' in os.environ:
                del os.environ['DATABASE_URL']
                logger.info("å·²æ¸…é™¤æœ‰é—®é¢˜çš„DATABASE_URLç¯å¢ƒå˜é‡")
            
            # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå°è¯•SQLite
            logger.warning("âš ï¸ æ£€æµ‹åˆ°ç¼–ç é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨SQLiteæ•°æ®åº“...")
            sqlite_success = False
            try:
                sqlite_url = 'sqlite:///gongkao_test.db'
                app.config['SQLALCHEMY_DATABASE_URI'] = sqlite_url
                
                # é‡æ–°åˆ›å»ºengineï¼ˆå®Œå…¨æ¸…é™¤æ—§çš„ï¼Œä½¿ç”¨æ–°çš„URLå’Œè¿æ¥æ± é…ç½®ï¼‰
                from sqlalchemy import create_engine
                from sqlalchemy.orm import scoped_session, sessionmaker
                # ç¡®ä¿URLæ˜¯çº¯ASCII
                sqlite_url_clean = str(sqlite_url).encode('ascii', errors='ignore').decode('ascii')
                # ä½¿ç”¨SQLiteè¿æ¥æ± é…ç½®
                engine_options = {
                    'pool_pre_ping': True,
                    'pool_recycle': 300,
                    'pool_size': 20,
                    'max_overflow': 30,
                    'pool_timeout': 30,
                    'connect_args': {
                        'check_same_thread': False,
                        'timeout': 30
                    }
                }
                engine = create_engine(sqlite_url_clean, echo=False, **engine_options)
                
                # ç›´æ¥æ›¿æ¢dbçš„å†…éƒ¨engineå±æ€§
                db.get_engine = lambda bind=None: engine
                db.session = scoped_session(sessionmaker(bind=engine))
                
                # æµ‹è¯•SQLiteè¿æ¥ï¼ˆç›´æ¥ä½¿ç”¨engineï¼Œä¸ä½¿ç”¨db.engineï¼‰
                with engine.connect() as conn:
                    pass  # æµ‹è¯•è¿æ¥
                
                # ä½¿ç”¨æ–°çš„engineåˆ›å»ºè¡¨
                from models_v2 import Question, AnswerVersion
                Question.metadata.create_all(engine)
                AnswerVersion.metadata.create_all(engine)
                
                logger.info("âœ… SQLiteæ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ªï¼")
                
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                from sqlalchemy import inspect
                inspector = inspect(engine)
                tables = inspector.get_table_names()
                logger.info(f"ğŸ“Š æ•°æ®åº“è¡¨: {', '.join(tables)}")
                sqlite_success = True
                database_type = 'sqlite'  # æ›´æ–°æ•°æ®åº“ç±»å‹
            except Exception as e2:
                logger.warning(f"âš ï¸ SQLiteæ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e2}")
                import traceback
                logger.debug(f"SQLiteé”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
            # å¦‚æœSQLiteå¤±è´¥ï¼Œå°è¯•MySQL
            if not sqlite_success:
                logger.warning("âš ï¸ å°è¯•ä½¿ç”¨MySQLæ•°æ®åº“ä½œä¸ºæœ€åå¤‡é€‰...")
                try:
                    # ä»ç¯å¢ƒå˜é‡è¯»å–MySQLé…ç½®ï¼ˆç¡®ä¿ä½¿ç”¨ASCIIå­—ç¬¦ï¼‰
                    mysql_host = str(os.getenv('MYSQL_HOST', 'localhost'))
                    mysql_port = str(os.getenv('MYSQL_PORT', '3306'))
                    mysql_user = str(os.getenv('MYSQL_USER', 'root'))
                    mysql_password = str(os.getenv('MYSQL_PASSWORD', ''))
                    mysql_database = str(os.getenv('MYSQL_DATABASE', 'gongkao_test'))
                    
                    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯ASCIIç¼–ç 
                    mysql_host = mysql_host.encode('ascii', errors='ignore').decode('ascii')
                    mysql_user = mysql_user.encode('ascii', errors='ignore').decode('ascii')
                    mysql_password = mysql_password.encode('ascii', errors='ignore').decode('ascii')
                    mysql_database = mysql_database.encode('ascii', errors='ignore').decode('ascii')
                    
                    mysql_url = f'mysql+pymysql://{mysql_user}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}?charset=utf8mb4'
                    app.config['SQLALCHEMY_DATABASE_URI'] = mysql_url
                    
                    # é‡æ–°åˆ›å»ºengineï¼ˆä½¿ç”¨è¿æ¥æ± é…ç½®ï¼‰
                    from sqlalchemy import create_engine
                    from sqlalchemy.orm import scoped_session, sessionmaker
                    engine_options = {
                        'pool_pre_ping': True,
                        'pool_recycle': 300,
                        'pool_size': 20,
                        'max_overflow': 30,
                        'pool_timeout': 30,
                    }
                    engine = create_engine(mysql_url, echo=False, **engine_options)
                    db.get_engine = lambda bind=None: engine
                    db.session = scoped_session(sessionmaker(bind=engine))
                    
                    # æµ‹è¯•MySQLè¿æ¥
                    conn = engine.connect()
                    conn.close()
                    db.create_all()
                    logger.info("âœ… MySQLæ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                    logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ªï¼")
                    
                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    from sqlalchemy import inspect
                    inspector = inspect(engine)
                    tables = inspector.get_table_names()
                    logger.info(f"ğŸ“Š æ•°æ®åº“è¡¨: {', '.join(tables)}")
                except ImportError:
                    logger.error("âŒ MySQLé©±åŠ¨æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install pymysql")
                    print("\nè¯·æ£€æŸ¥ï¼š")
                    print("1. DATABASE_URL ç¯å¢ƒå˜é‡ç¼–ç æ˜¯å¦æ­£ç¡®ï¼ˆå»ºè®®åˆ é™¤.envä¸­çš„DATABASE_URLï¼‰")
                    print("2. SQLiteæ•°æ®åº“æ–‡ä»¶æƒé™")
                    print("3. MySQLé…ç½®ï¼ˆMYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DATABASEï¼‰")
                    print("4. å¦‚æœä½¿ç”¨MySQLï¼Œè¯·å®‰è£…é©±åŠ¨: pip install pymysql")
                    print("5. å¯ä»¥æ‰‹åŠ¨åˆ é™¤.envæ–‡ä»¶ä¸­çš„DATABASE_URLè¡Œï¼Œç„¶åé‡æ–°è¿è¡Œ")
                    exit(1)
                except Exception as e3:
                    logger.error(f"âŒ MySQLæ•°æ®åº“è¿æ¥ä¹Ÿå¤±è´¥ï¼š{e3}")
                    print("\nè¯·æ£€æŸ¥ï¼š")
                    print("1. DATABASE_URL ç¯å¢ƒå˜é‡ç¼–ç æ˜¯å¦æ­£ç¡®ï¼ˆå»ºè®®åˆ é™¤.envä¸­çš„DATABASE_URLï¼‰")
                    print("2. SQLiteæ•°æ®åº“æ–‡ä»¶æƒé™")
                    print("3. MySQLé…ç½®ï¼ˆMYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DATABASEï¼‰")
                    print("4. MySQLæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
                    print("5. å¦‚æœä½¿ç”¨MySQLï¼Œè¯·å®‰è£…é©±åŠ¨: pip install pymysql")
                    print("6. å¯ä»¥æ‰‹åŠ¨åˆ é™¤.envæ–‡ä»¶ä¸­çš„DATABASE_URLè¡Œï¼Œç„¶åé‡æ–°è¿è¡Œ")
                    exit(1)
        except Exception as e:
            error_msg = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼–ç é”™è¯¯
            is_encoding_error = (
                isinstance(e, (UnicodeDecodeError, UnicodeEncodeError)) or
                'codec' in error_msg.lower() or 
                'decode' in error_msg.lower() or 
                'utf-8' in error_msg.lower() or
                'invalid start byte' in error_msg.lower()
            )
            
            if is_encoding_error:
                logger.error(f"âŒ æ•°æ®åº“è¿æ¥ç¼–ç é”™è¯¯ï¼š{e}")
                # æ¸…é™¤æœ‰é—®é¢˜çš„ç¯å¢ƒå˜é‡å¹¶å›é€€åˆ°SQLite
                if 'DATABASE_URL' in os.environ:
                    del os.environ['DATABASE_URL']
                    logger.info("å·²æ¸…é™¤æœ‰é—®é¢˜çš„DATABASE_URLç¯å¢ƒå˜é‡")
                
                logger.warning("âš ï¸ è‡ªåŠ¨å›é€€åˆ°SQLiteæ•°æ®åº“...")
                try:
                    sqlite_url = 'sqlite:///gongkao_test.db'
                    app.config['SQLALCHEMY_DATABASE_URI'] = sqlite_url
                    
                    from sqlalchemy import create_engine
                    from sqlalchemy.orm import scoped_session, sessionmaker
                    sqlite_url_clean = str(sqlite_url).encode('ascii', errors='ignore').decode('ascii')
                    # ä½¿ç”¨SQLiteè¿æ¥æ± é…ç½®
                    engine_options = {
                        'pool_pre_ping': True,
                        'pool_recycle': 300,
                        'pool_size': 20,
                        'max_overflow': 30,
                        'pool_timeout': 30,
                        'connect_args': {
                            'check_same_thread': False,
                            'timeout': 30
                        }
                    }
                    engine = create_engine(sqlite_url_clean, echo=False, **engine_options)
                    
                    db.get_engine = lambda bind=None: engine
                    db.session = scoped_session(sessionmaker(bind=engine))
                    
                    with engine.connect() as conn:
                        pass
                    
                    from models_v2 import Question, AnswerVersion
                    Question.metadata.create_all(engine)
                    AnswerVersion.metadata.create_all(engine)
                    
                    logger.info("âœ… SQLiteæ•°æ®åº“è¿æ¥æˆåŠŸï¼")
                    logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ªï¼")
                    database_type = 'sqlite'
                    
                    from sqlalchemy import inspect
                    inspector = inspect(engine)
                    tables = inspector.get_table_names()
                    logger.info(f"ğŸ“Š æ•°æ®åº“è¡¨: {', '.join(tables)}")
                except Exception as e2:
                    logger.error(f"âŒ SQLiteæ•°æ®åº“è¿æ¥ä¹Ÿå¤±è´¥ï¼š{e2}")
                    print("\nè¯·æ£€æŸ¥ï¼š")
                    print("1. SQLiteæ•°æ®åº“æ–‡ä»¶æƒé™")
                    print("2. å¯ä»¥æ‰‹åŠ¨åˆ é™¤.envæ–‡ä»¶ä¸­çš„DATABASE_URLè¡Œï¼Œç„¶åé‡æ–°è¿è¡Œ")
                    exit(1)
            else:
                logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
                print("\nè¯·æ£€æŸ¥ï¼š")
                print("1. DATABASE_URL ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®é…ç½®")
                print("2. Supabaseæ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸")
                print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
                print("4. å¦‚æœé‡åˆ°ç¼–ç é”™è¯¯ï¼Œå¯ä»¥åˆ é™¤.envæ–‡ä»¶ä¸­çš„DATABASE_URLï¼Œä½¿ç”¨SQLiteæµ‹è¯•")
                exit(1)
    
    # é¢„åŠ è½½OCRæœåŠ¡ï¼ˆåœ¨å¯åŠ¨æ—¶åŠ è½½ï¼Œé¿å…é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿï¼‰
    # å¯é€šè¿‡ç¯å¢ƒå˜é‡ PRELOAD_OCR=true/false æ§åˆ¶æ˜¯å¦é¢„åŠ è½½ï¼ˆé»˜è®¤trueï¼‰
    preload_ocr = os.getenv('PRELOAD_OCR', 'true').lower() in ('true', '1', 'yes')
    
    if preload_ocr:
        print("\n" + "=" * 60)
        print("æ­£åœ¨é¢„åŠ è½½OCRæœåŠ¡ï¼ˆPaddleOCRï¼‰...")
        print("=" * 60)
        
        try:
            from ocr_service import get_ocr_service
            import time
            
            start_time = time.time()
            logger.info("[å¯åŠ¨] å¼€å§‹é¢„åŠ è½½OCRæœåŠ¡...")
            print("ğŸ“¦ æ­£åœ¨åˆå§‹åŒ–PaddleOCRæ¨¡å‹...")
            print("   æç¤º: é¦–æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¯·è€å¿ƒç­‰å¾…")
            
            # è·å–OCRæœåŠ¡å®ä¾‹ï¼ˆè¿™ä¼šè§¦å‘PaddleOCRåˆå§‹åŒ–ï¼‰
            ocr_service = get_ocr_service()
            
            elapsed_init = time.time() - start_time
            
            if ocr_service and ocr_service.ocr_engine:
                # åˆ¤æ–­ä½¿ç”¨çš„OCRå¼•æ“
                engine_name = "æœªçŸ¥"
                if hasattr(ocr_service.ocr_engine, 'ocr'):
                    engine_name = "PaddleOCR"
                elif ocr_service.ocr_engine == 'tesseract':
                    engine_name = "Tesseract"
                
                logger.info(f"[å¯åŠ¨] OCRæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨å¼•æ“: {engine_name}")
                print(f"âœ… OCRæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼è€—æ—¶: {elapsed_init:.1f}ç§’")
                print(f"   ğŸ“ ä½¿ç”¨çš„å¼•æ“: {engine_name}")
                
                # å¯é€‰ï¼šè¿›è¡Œä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯†åˆ«ï¼Œç¡®ä¿æ¨¡å‹å®Œå…¨åŠ è½½
                # å¯é€šè¿‡ç¯å¢ƒå˜é‡ PRELOAD_OCR_TEST=true/false æ§åˆ¶ï¼ˆé»˜è®¤falseï¼Œé¿å…é¢å¤–å»¶è¿Ÿï¼‰
                test_ocr = os.getenv('PRELOAD_OCR_TEST', 'false').lower() in ('true', '1', 'yes')
                
                if test_ocr:
                    logger.info("[å¯åŠ¨] å¼€å§‹OCRæµ‹è¯•è¯†åˆ«...")
                    print("ğŸ” è¿›è¡Œæµ‹è¯•è¯†åˆ«ä»¥ç¡®ä¿æ¨¡å‹å·²å®Œå…¨åŠ è½½...")
                    
                    try:
                        from PIL import Image
                        import tempfile
                        
                        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
                        test_img = Image.new('RGB', (100, 30), color='white')
                        test_file = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)
                        test_img.save(test_file.name, 'JPEG')
                        test_file.close()
                        
                        # è¿›è¡Œä¸€æ¬¡æµ‹è¯•è¯†åˆ«
                        test_start = time.time()
                        test_result = ocr_service.extract_text(test_file.name, use_preprocess=False)
                        test_elapsed = time.time() - test_start
                        
                        logger.info(f"[å¯åŠ¨] âœ… OCRæµ‹è¯•è¯†åˆ«æˆåŠŸï¼Œè€—æ—¶: {test_elapsed:.1f}ç§’")
                        print(f"âœ… OCRæµ‹è¯•è¯†åˆ«æˆåŠŸï¼æµ‹è¯•è€—æ—¶: {test_elapsed:.1f}ç§’")
                        
                        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                        try:
                            os.unlink(test_file.name)
                        except:
                            pass
                    except Exception as test_error:
                        logger.warning(f"[å¯åŠ¨] OCRæµ‹è¯•è¯†åˆ«å¤±è´¥ï¼Œä½†æœåŠ¡å·²åˆå§‹åŒ–: {test_error}")
                        print(f"âš ï¸ OCRæµ‹è¯•è¯†åˆ«å¤±è´¥ï¼Œä½†æœåŠ¡å·²åˆå§‹åŒ–ï¼ˆå¯èƒ½ä¸å½±å“ä½¿ç”¨ï¼‰")
                else:
                    print("   ğŸ’¡ æç¤º: å·²è·³è¿‡æµ‹è¯•è¯†åˆ«ï¼ˆè®¾ç½® PRELOAD_OCR_TEST=true å¯å¯ç”¨æµ‹è¯•ï¼‰")
            else:
                logger.warning(f"[å¯åŠ¨] âš ï¸ OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥æˆ–æœªæ‰¾åˆ°OCRå¼•æ“")
                print(f"âš ï¸ OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥æˆ–æœªæ‰¾åˆ°OCRå¼•æ“ï¼ˆè€—æ—¶: {elapsed_init:.1f}ç§’ï¼‰")
                print("   æç¤º: é¦–æ¬¡è¯·æ±‚æ—¶å¯èƒ½ä¼šè‡ªåŠ¨é‡è¯•")
                
        except Exception as e:
            logger.warning(f"[å¯åŠ¨] OCRæœåŠ¡é¢„åŠ è½½å¤±è´¥: {e}")
            print(f"âš ï¸ OCRæœåŠ¡é¢„åŠ è½½å¤±è´¥: {e}")
            print("   æç¤º: å°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶å°è¯•åˆå§‹åŒ–")
            import traceback
            logger.debug(f"OCRé¢„åŠ è½½é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    else:
        logger.info("[å¯åŠ¨] è·³è¿‡OCRæœåŠ¡é¢„åŠ è½½ï¼ˆPRELOAD_OCR=falseï¼‰")
        print("\n" + "=" * 60)
        print("â­ï¸  è·³è¿‡OCRæœåŠ¡é¢„åŠ è½½ï¼ˆPRELOAD_OCR=falseï¼‰")
        print("=" * 60)
        print("   æç¤º: OCRæœåŠ¡å°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åˆå§‹åŒ–")
    
    print("\n" + "=" * 60)
    print("FlaskæœåŠ¡å¯åŠ¨ä¸­...")
    print("=" * 60)
    print("APIåœ°å€: http://localhost:5000")
    print("æµ‹è¯•æ¥å£: GET http://localhost:5000/api/test")
    print("å¥åº·æ£€æŸ¥: GET http://localhost:5000/api/health")
    print("ç»Ÿè®¡æ¥å£: GET http://localhost:5000/api/stats")
    print("åˆ†ææ¥å£: POST http://localhost:5000/api/questions/analyze")
    print("æµ‹è¯•è„šæœ¬: python test_api_v2.py")
    print("=" * 60)
    print("\næç¤º: æœåŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…è¯·æ±‚...")
    print("   å‘é€è¯·æ±‚åæ‰ä¼šçœ‹åˆ°è¯¦ç»†æ—¥å¿—\n")
    
    app.run(debug=True, port=5000)

